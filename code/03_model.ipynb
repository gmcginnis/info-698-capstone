{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "68a3c4a0",
      "metadata": {
        "id": "68a3c4a0"
      },
      "source": [
        "# Data Splitting and Modelling\n",
        "\n",
        "Author: Gillian A. McGinnis, final-semester M.S. Information Science - Machine Learning  \n",
        "The University of Arizona College of Information  \n",
        "INFO 698 - Capstone  \n",
        "Start date: 21 October 2025  \n",
        "Last updated: 25 November 2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6d80b978",
      "metadata": {
        "id": "6d80b978",
        "outputId": "ee97d0f8-2f28-401c-fae3-fb75d256dd43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nModule providing code for test/train split and sliding window creation. Relies on 01_clean.ipynb completion.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "Module providing code for test/train split and sliding window creation. Relies on 01_clean.ipynb completion.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de84a462",
      "metadata": {
        "id": "de84a462"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33ab0f88",
      "metadata": {
        "id": "33ab0f88"
      },
      "outputs": [],
      "source": [
        "var_of_interest = \"obstruction_ro\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7208265e",
      "metadata": {
        "id": "7208265e"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU Setup\n",
        "%load_ext cudf.pandas\n",
        "import pandas as pd\n",
        "import cudf\n",
        "import cupy as cp"
      ],
      "metadata": {
        "id": "-2FCjcFbVrfq"
      },
      "id": "-2FCjcFbVrfq",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import userdata\n",
        "gh_pat = userdata.get('gh_pat')\n",
        "gh_repo = userdata.get('gh_repo')\n",
        "repo_url = f'https://{gh_pat}@github.com/{gh_repo}'\n",
        "!git clone {repo_url}"
      ],
      "metadata": {
        "id": "RHYanMjnWKQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba01be7-4105-49f1-e1f3-69e08cdbf469"
      },
      "id": "RHYanMjnWKQb",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'info-698-capstone' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.getcwd() == '/content':\n",
        "    print(\"Changing wd...\")\n",
        "    os.chdir('info-698-capstone/code')\n",
        "\n",
        "# # Verify the current working directory\n",
        "print(f\"Current working directory is: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuqM0JgLV-5J",
        "outputId": "aa84b670-f3e8-4bee-fb8c-b4b9ba410395"
      },
      "id": "OuqM0JgLV-5J",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changing wd...\n",
            "Current working directory is: /content/info-698-capstone/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0bb557fb",
      "metadata": {
        "id": "0bb557fb"
      },
      "outputs": [],
      "source": [
        "# General packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.model_selection import TimeSeriesSplit, train_test_split, RandomizedSearchCV, TunedThresholdClassifierCV\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, precision_recall_curve, make_scorer\n",
        "\n",
        "# For saving models\n",
        "import joblib\n",
        "\n",
        "# For data importing and exporting\n",
        "from helper_utils import get_path, model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dcb5d8f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dcb5d8f6",
        "outputId": "9b275158-4e85-40be-ef68-8d628d3e1be9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<details>\n",
              "<summary>Click to view session information</summary>\n",
              "<pre>\n",
              "-----\n",
              "cudf                25.10.00\n",
              "cupy                13.6.0\n",
              "google              NA\n",
              "helper_utils        NA\n",
              "joblib              1.5.2\n",
              "numpy               2.0.2\n",
              "pandas              2.2.2\n",
              "scipy               1.16.3\n",
              "session_info        v1.0.1\n",
              "sklearn             1.6.1\n",
              "xgboost             3.1.2\n",
              "-----\n",
              "IPython             7.34.0\n",
              "jupyter_client      7.4.9\n",
              "jupyter_core        5.9.1\n",
              "notebook            6.5.7\n",
              "-----\n",
              "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
              "Linux-6.6.105+-x86_64-with-glibc2.35\n",
              "-----\n",
              "Session information updated at 2025-11-26 03:29\n",
              "</pre>\n",
              "</details>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "## (Optional chunk)\n",
        "# Current session information\n",
        "\n",
        "# From StackOverflow,\n",
        "# https://stackoverflow.com/a/62128239/23486987\n",
        "try:\n",
        "    import session_info\n",
        "except:\n",
        "    !pip install session_info\n",
        "    import session_info\n",
        "# !pip install session_info\n",
        "# import session_info\n",
        "session_info.show(dependencies=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9c40baf7",
      "metadata": {
        "id": "9c40baf7"
      },
      "outputs": [],
      "source": [
        "# To make it easier to tell when processes have completed -- can delete later\n",
        "# From StackOverflow,\n",
        "# https://stackoverflow.com/a/62128239/23486987\n",
        "try:\n",
        "    from playsound3 import playsound\n",
        "except:\n",
        "    !pip install playsound3\n",
        "    from playsound3 import playsound"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "1e7c4847",
      "metadata": {
        "id": "1e7c4847"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "np.random.seed(42)\n",
        "cp.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure GPU active\n",
        "# !nvidia-smi\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Warning: GPU not found!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t3ZBgBzJqaU",
        "outputId": "d5f50990-18c1-451f-849b-c4cd0962fde9"
      },
      "id": "1t3ZBgBzJqaU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ef4832",
      "metadata": {
        "id": "30ef4832"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cd2e4fca",
      "metadata": {
        "id": "cd2e4fca"
      },
      "outputs": [],
      "source": [
        "# united_water = pd.read_parquet('data/clean/water_nocal.parquet')\n",
        "# data_cal = pd.read_parquet('data/clean/calibration.parquet')\n",
        "# data_cal = data_cal.rename(columns={'weir_level':'weir_level_cal'})\n",
        "\n",
        "# united_soil = pd.read_parquet('data/clean/soil.parquet')\n",
        "\n",
        "united_water = pd.read_parquet(get_path('clean/water_nocal.parquet'))\n",
        "united_soil = pd.read_parquet(get_path('clean/soil.parquet'))\n",
        "\n",
        "# united_water = pd.read_parquet('data/clean/water_nocal.parquet')\n",
        "data_cal = pd.read_parquet(get_path('clean/calibration.parquet'))\n",
        "data_cal = data_cal.rename(columns={'weir_level':'weir_level_cal'})\n",
        "\n",
        "# united_soil = pd.read_parquet('data/clean/soil.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cal.info()"
      ],
      "metadata": {
        "id": "9QEIHj-wNiBd",
        "outputId": "28849b4a-f62b-4694-b5b2-49bf58b270f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9QEIHj-wNiBd",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'cudf.core.dataframe.DataFrame'>\n",
            "DatetimeIndex: 6136 entries, 1994-01-03 08:46:00 to 2025-08-01 09:10:00\n",
            "Data columns (total 1 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   weir_level_cal  6136 non-null   int8\n",
            "dtypes: int8(1)\n",
            "memory usage: 53.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d98f94e4",
      "metadata": {
        "id": "d98f94e4"
      },
      "source": [
        "### Cleanup\n",
        "\n",
        "Small amount of data wrangling for memory improvements (some as a consequence of importing)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebf48710",
      "metadata": {
        "id": "ebf48710"
      },
      "source": [
        "#### Memory improvements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "689c32ff",
      "metadata": {
        "id": "689c32ff"
      },
      "outputs": [],
      "source": [
        "# Select columns of interest\n",
        "data_water = united_water.drop(columns=['raw_rain', 'chk_note_rain', 'chk_fail_rain', 'chk_note_ro', 'chk_fail_ro', 'comment_ro', 'source_ro'])\n",
        "\n",
        "# Cleanup\n",
        "del united_water\n",
        "\n",
        "# Remove duplicate entries\n",
        "data_water = data_water.reset_index().drop_duplicates(keep='first').set_index('datetime')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "357e91e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "357e91e4",
        "outputId": "e17d190a-2456-4d65-bbca-d24a073af5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'cudf.core.dataframe.DataFrame'>\n",
            "DatetimeIndex: 3581782 entries, 1989-06-21 13:00:00 to 2025-08-01 13:00:00\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Dtype\n",
            "---  ------          -----\n",
            " 0   ra_rain         float32\n",
            " 1   raw_ro          float32\n",
            " 2   obstruction_ro  bool\n",
            "dtypes: bool(1), float32(2)\n",
            "memory usage: 59.4 MB\n"
          ]
        }
      ],
      "source": [
        "water_drops = ['level_ro', 'obstruction_ro', 'gap_fill_ro', 'weir_cleaning_ro', 'spike_ro', 'calibration_ro']\n",
        "water_drops.remove(var_of_interest)\n",
        "\n",
        "data_water = data_water.drop(water_drops, axis=1)\n",
        "\n",
        "del water_drops\n",
        "\n",
        "data_water.info(memory_usage=\"deep\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1706a0d9",
      "metadata": {
        "id": "1706a0d9"
      },
      "outputs": [],
      "source": [
        "united_soil['sample'] = united_soil['sample'].astype('category')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "168e27bd",
      "metadata": {
        "id": "168e27bd"
      },
      "source": [
        "## Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "aa5776e5",
      "metadata": {
        "id": "aa5776e5"
      },
      "outputs": [],
      "source": [
        "### Note ###\n",
        "# REMOVE this later -- just a smaller subset for feature engineering testing!!!\n",
        "# temp_subset_start = '2000-01-01 00:00:00'\n",
        "temp_subset_start = '2001-02-01 00:00:00'\n",
        "temp_subset_end = '2011-12-31 23:59:59'\n",
        "# data_water = data_water['2015-01-01 00:00:00':'2016-12-31 23:59:59']\n",
        "data_water = data_water[temp_subset_start:temp_subset_end]\n",
        "######"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecb9dc61",
      "metadata": {
        "id": "ecb9dc61"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afa843b0",
      "metadata": {
        "id": "afa843b0"
      },
      "source": [
        "### Distance from Event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "24851c9b",
      "metadata": {
        "id": "24851c9b"
      },
      "outputs": [],
      "source": [
        "def timesince_feat(input_df, input_col, input_unit):\n",
        "    # output_df = input_df.copy()#[input_col].to_frame()\n",
        "    output_df = input_df\n",
        "    instances = output_df[input_col].notna()\n",
        "    # Create groupings based on most recent instance\n",
        "    group_id = instances.cumsum()\n",
        "    # Exclude the first grouping\n",
        "    # otherwise it assumes there was an event just prior to the first entry\n",
        "    group_id = group_id.replace(0, np.nan)\n",
        "    # Create new column to count the distance in days since the point\n",
        "    # which resets to 0 at each new point\n",
        "    output_df['timestamp'] = pd.to_datetime(output_df.index)\n",
        "    # Get start timestamp of the group\n",
        "    output_df['ts_start'] = output_df.groupby(group_id)['timestamp'].transform('min')\n",
        "    # Calculate the distance\n",
        "    if input_unit == \"minutes\":\n",
        "        # output_df[f\"minsince_{input_col}\"] = (output_df['timestamp'] - output_df['ts_start']).dt.total_seconds().div(60).astype('Int32')\n",
        "        output_df[f\"minsince_{input_col}\"] = (output_df['timestamp'] - output_df['ts_start']).dt.total_seconds().div(60).astype(np.float32)\n",
        "        # output_df[f\"minsince_{input_col}\"] = output_df[f\"minsince_{input_col}\"].astype(np.float32)\n",
        "    elif input_unit == \"days\":\n",
        "        # output_df[f\"daysince_{input_col}\"] = (output_df['timestamp'] - output_df['ts_start']).dt.days.astype('Int32')\n",
        "        output_df[f\"daysince_{input_col}\"] = (output_df['timestamp'] - output_df['ts_start']).dt.days.astype(np.float32)\n",
        "        # output_df[f\"minsince_{input_col}\"] = output_df[f\"minsince_{input_col}\"].astype(np.float32)\n",
        "        # output_df[f\"daysince_{input_col}\"] = output_df[f\"daysince_{input_col}\"].astype('Int32')\n",
        "    # Remove extra cols\n",
        "    output_df = output_df.drop(columns=['timestamp', 'ts_start'])\n",
        "    return output_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "830a5cbc",
      "metadata": {
        "id": "830a5cbc"
      },
      "source": [
        "#### Rain\n",
        "Create feature which tracks how recent a rain event occurred."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e0a3b363",
      "metadata": {
        "id": "e0a3b363"
      },
      "outputs": [],
      "source": [
        "data_water = timesince_feat(data_water, 'ra_rain', \"minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e786a7e9",
      "metadata": {
        "id": "e786a7e9"
      },
      "source": [
        "### Rain event\n",
        "\n",
        "Keep track of cumulative rainfall during a specific event."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "59b7c231",
      "metadata": {
        "id": "59b7c231"
      },
      "outputs": [],
      "source": [
        "# Create index of instances where there is a data point\n",
        "# rain_event = data_water['ra_rain'].isnull()\n",
        "# rain_event = (data_water['ra_rain'].isnull() & ((data_water['minsince_ra_rain'] >= 5.0) & (data_water['minsince_ra_rain'] != 0)))\n",
        "rain_event = (data_water['ra_rain'].isnull() & ((data_water['minsince_ra_rain'] >= 5.0) & (data_water['minsince_ra_rain'] != 0)))\n",
        "# Create groupings based on most recent instance\n",
        "rain_event_id = rain_event.cumsum()\n",
        "# Create new column to count number of records since the point\n",
        "# which resets to 0 at each new point\n",
        "# del group_id, instances\n",
        "# water_mini\n",
        "# group_id = group_id.replace(0, np.nan)\n",
        "# water_mini['since_ra_rain2'] = water_mini.groupby(group_id).cumcount()\n",
        "# water_mini\n",
        "# water_mini.info()\n",
        "data_water['eventsum_ra_rain'] = data_water.groupby(rain_event_id)['ra_rain'].cumsum()\n",
        "\n",
        "del rain_event, rain_event_id"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a81ae4",
      "metadata": {
        "id": "96a81ae4"
      },
      "source": [
        "### Decay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "46f01638",
      "metadata": {
        "id": "46f01638"
      },
      "outputs": [],
      "source": [
        "def decay_feat(input_df, input_col, input_dec_rate = -0.1):\n",
        "    output_df = input_df#.copy()\n",
        "    # output_df = since_feat(input_df = output_df, input_col = input_col)\n",
        "    if f\"minsince_{input_col}\" not in output_df.columns:\n",
        "        # output_df = minsince_feat(input_df = output_df, input_col = input_col)\n",
        "        output_df = timesince_feat(input_df = output_df, input_col = input_col, input_unit = \"minutes\")\n",
        "    # Update for GPU for overflow fix\n",
        "    output_df[f\"minsince_{input_col}\"] = output_df[f\"minsince_{input_col}\"].astype(np.float64)\n",
        "\n",
        "    output_df[f\"decayrate{input_dec_rate}_{input_col}\"] = np.exp(input_dec_rate * output_df[f\"minsince_{input_col}\"]).astype(np.float32)\n",
        "    output_df[f\"ffill_{input_col}\"] = output_df[input_col].ffill()\n",
        "    output_df[f\"decay{input_dec_rate}_{input_col}\"] = (output_df[f\"ffill_{input_col}\"] * output_df[f\"decayrate{input_dec_rate}_{input_col}\"])\n",
        "\n",
        "    return output_df\n",
        "\n",
        "# water_m = united_water[['raw_ro', 'level_ro', 'ra_rain', 'obstruction_ro']]\n",
        "\n",
        "# null_mask = water_m['ra_rain'].isnull()\n",
        "# g_id_event = null_mask.cumsum()\n",
        "# water_m['r_event_sum'] = water_m.groupby(g_id_event)['ra_rain'].cumsum()\n",
        "\n",
        "# is_rain = water_m['ra_rain'].notna()\n",
        "# g_id = is_rain.cumsum()\n",
        "# # g_id\n",
        "# water_m['since_rain'] = water_m.groupby(g_id).cumcount()\n",
        "# water_m['dec'] = np.exp(-0.1*water_m['since_rain'])\n",
        "# water_m['rain_fill'] = water_m['r_event_sum'].ffill()\n",
        "# # data_u['1_shallow_f'] = data_u['1_shallow'].ffill()\n",
        "# water_m['rain_dec'] = (water_m['rain_fill']*water_m['dec'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "947bae8b",
      "metadata": {
        "id": "947bae8b"
      },
      "outputs": [],
      "source": [
        "# Replace NAs in rain with 0\n",
        "data_water['ra_rain'] = data_water['ra_rain'].fillna(0)\n",
        "\n",
        "# Apply decay function\n",
        "data_water = decay_feat(data_water, 'eventsum_ra_rain')\n",
        "\n",
        "# Drop extra column\n",
        "# minutes since rain event will be the same as minutes since most recent rain\n",
        "data_water = data_water.drop('minsince_eventsum_ra_rain', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6154e3b7",
      "metadata": {
        "id": "6154e3b7"
      },
      "source": [
        "### Lag features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5d3c7b",
      "metadata": {
        "id": "8c5d3c7b"
      },
      "source": [
        "#### Consistent cols\n",
        "\n",
        "Modify the rows to prevent inappropriate data shifts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a0e75eb6",
      "metadata": {
        "id": "a0e75eb6"
      },
      "outputs": [],
      "source": [
        "original_indices = data_water.index.copy()\n",
        "\n",
        "new_index = pd.date_range(start = data_water.index.min(),\n",
        "                          end = data_water.index.max(),\n",
        "                          freq = '5min')\n",
        "\n",
        "# Reindex\n",
        "data_water = data_water.reindex(new_index)\n",
        "\n",
        "# Cleanup\n",
        "del new_index\n",
        "\n",
        "# # Return\n",
        "# data_water = data_water.loc[original_indices]\n",
        "# del original_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62d8945f",
      "metadata": {
        "id": "62d8945f"
      },
      "source": [
        "Get values from other recent time stamps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "09c4b606",
      "metadata": {
        "id": "09c4b606"
      },
      "outputs": [],
      "source": [
        "def lag_feats(input_df, input_cols, input_lags):\n",
        "    output_df = input_df#.copy()\n",
        "    for col in input_cols:\n",
        "        for lag in input_lags:\n",
        "            output_df[f\"{col}_lag{lag}\"] = output_df[col].shift(lag)\n",
        "    return output_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "797920ef",
      "metadata": {
        "id": "797920ef"
      },
      "outputs": [],
      "source": [
        "# lag_feats(data_water, ['raw_ro'], [1, 2, 3, 24]).dropna(subset='raw_ro')[['raw_ro', 'raw_ro_lag1', 'raw_ro_lag2']]\n",
        "# lag_feats(data_water, ['raw_ro'], [1, 2, 3, 24]).dropna(subset='raw_ro')[['raw_ro', 'raw_ro_lag1', 'raw_ro_lag24']]\n",
        "\n",
        "# Columns to get temporal stats on\n",
        "cols_to_shift = ['raw_ro', 'ra_rain']\n",
        "# # data at 5-min increments -- lag to record values at 5m, 10m, 15m, 30m, 1h, and 2h prior\n",
        "# lags_of_interest = [1, 2, 3, 6, 12, 24]\n",
        "# data at 5-min increments -- lag to record values at 5m, 10m, 15m, 20m, 25m, 30m, 1h, 2h, 3h prior\n",
        "lags_of_interest = [1, 2, 3, 4, 5, 6, 12, 24, 36]\n",
        "\n",
        "data_water = lag_feats(data_water, cols_to_shift, lags_of_interest)\n",
        "\n",
        "# data_water.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ddce5f3",
      "metadata": {
        "id": "0ddce5f3"
      },
      "source": [
        "### Rolling stats\n",
        "\n",
        "Get stat values from range of recent time stamps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "eb010731",
      "metadata": {
        "id": "eb010731"
      },
      "outputs": [],
      "source": [
        "def rolling_feats(input_df, input_cols, input_windows, input_mtype = \"mean\"):\n",
        "    output_df = input_df#.copy()\n",
        "\n",
        "    # Create a dummy series of index values (0, 1, 2, ... N) once\n",
        "    # 'x' represents the position within the dataframe for the regression calculation\n",
        "    x_series = pd.Series(np.arange(len(output_df)), index=output_df.index)\n",
        "\n",
        "    for col in input_cols:\n",
        "        for window in input_windows:\n",
        "            # 1. Calculate mean and std\n",
        "            if input_mtype == \"mean\":\n",
        "                output_df[f\"{col}_rollmean_{window}\"] = output_df[col].rolling(window).mean().astype(np.float32)\n",
        "            elif input_mtype == \"sum\":\n",
        "                output_df[f\"{col}_rollsum_{window}\"] = output_df[col].rolling(window).sum().astype(np.float32)\n",
        "            elif input_mtype == \"both\":\n",
        "                output_df[f\"{col}_rollmean_{window}\"] = output_df[col].rolling(window).mean().astype(np.float32)\n",
        "                output_df[f\"{col}_rollsum_{window}\"] = output_df[col].rolling(window).sum().astype(np.float32)\n",
        "            output_df[f\"{col}_rollstd_{window}\"] = output_df[col].rolling(window).std().astype(np.float32)\n",
        "\n",
        "            # 2. Calculate Slope using vectorized operations\n",
        "            # Calculate Covariance of Y (data) vs X (index position)\n",
        "            rolling_cov = output_df[col].rolling(window).cov(x_series)\n",
        "            # Calculate Variance of X (index position)\n",
        "            rolling_var_x = x_series.rolling(window).var()\n",
        "            # Slope = Cov(Y, X) / Var(X)\n",
        "            output_df[f\"{col}_rollslope_{window}\"] = (rolling_cov / rolling_var_x).astype(np.float32)\n",
        "\n",
        "            # Note on edge cases:\n",
        "            # The initial 'window-1' values for rolling_var_x will be NaN/incorrect.\n",
        "            # Pandas automatically handles alignment, so the division result will also be NaN where appropriate.\n",
        "            # This method works very well for standard time series analysis.\n",
        "    return output_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cf7eaaaf",
      "metadata": {
        "id": "cf7eaaaf"
      },
      "outputs": [],
      "source": [
        "# Inclusive of current point--\n",
        "# 10m, 15m, 20m, 25m, 30m, 1h, 3h, 6h, 12h, 24h\n",
        "windows_of_interest = [2, 3, 4, 5, 6, 12, 36, 72, 144, 288]\n",
        "\n",
        "# data_water = rolling_feats(data_water, ['raw_ro'], windows_of_interest, \"mean\")\n",
        "data_water = rolling_feats(data_water, ['raw_ro'], windows_of_interest, \"both\")\n",
        "data_water = rolling_feats(data_water, ['ra_rain'], windows_of_interest, \"sum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "596fa05d",
      "metadata": {
        "id": "596fa05d"
      },
      "source": [
        "Change since last value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ccb6f5c9",
      "metadata": {
        "id": "ccb6f5c9"
      },
      "outputs": [],
      "source": [
        "data_water['raw_ro_change'] = data_water['raw_ro'].diff()\n",
        "\n",
        "# cal_na_mask = data_water['weir_level_cal'].notna() & data_water['raw_ro'].notna()\n",
        "# # cal_na_mask\n",
        "# (data_water['weir_level_cal'] - data_water['raw_ro']).dropna()\n",
        "# del cal_na_mask\n",
        "# data_water['diff_ro_cal'] = (data_water['weir_level_cal'] - data_water['raw_ro'])\n",
        "# data_water['rain_diff']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b0d8524e",
      "metadata": {
        "id": "b0d8524e"
      },
      "outputs": [],
      "source": [
        "# Return\n",
        "data_water = data_water.loc[original_indices]\n",
        "\n",
        "del original_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4794b582",
      "metadata": {
        "id": "4794b582"
      },
      "source": [
        "## Soil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f8e3f87",
      "metadata": {
        "id": "5f8e3f87"
      },
      "source": [
        "Pivot the soil data such that each sample has its own columns, and separated by depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fd40d185",
      "metadata": {
        "id": "fd40d185"
      },
      "outputs": [],
      "source": [
        "# Drop irrelevant column\n",
        "data_soil_shallow = united_soil.copy().drop('h2o_by_wet_deep', axis=1)\n",
        "data_soil_shallow['sample'] = data_soil_shallow['sample'].astype('float32')\n",
        "# Pivot wider\n",
        "data_soil_shallow = data_soil_shallow.pivot(columns='sample', values='h2o_by_wet_shallow')\n",
        "\n",
        "# Drop irrelevant column\n",
        "data_soil_deep = united_soil.copy().drop('h2o_by_wet_shallow', axis=1)\n",
        "\n",
        "data_soil_deep['sample'] = data_soil_deep['sample'].astype('float32')\n",
        "# Pivot wider\n",
        "data_soil_deep = data_soil_deep.pivot(columns='sample', values='h2o_by_wet_deep')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "21b91e64",
      "metadata": {
        "id": "21b91e64"
      },
      "outputs": [],
      "source": [
        "data_soil = pd.merge(\n",
        "    data_soil_shallow,\n",
        "    data_soil_deep,\n",
        "    left_index = True,\n",
        "    right_index = True,\n",
        "    suffixes = (\"_shallow\", \"_deep\"),\n",
        "    how = \"outer\"\n",
        ")\n",
        "\n",
        "del data_soil_shallow, data_soil_deep\n",
        "del united_soil"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47024efe",
      "metadata": {
        "id": "47024efe"
      },
      "source": [
        "## Unite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a80c556f",
      "metadata": {
        "id": "a80c556f"
      },
      "outputs": [],
      "source": [
        "data_united = pd.merge(\n",
        "    data_water,\n",
        "    # REMOVE LATER\n",
        "    data_cal[temp_subset_start:temp_subset_end],\n",
        "    #\n",
        "    left_index = True,\n",
        "    right_index = True,\n",
        "    how = 'outer'\n",
        ")\n",
        "\n",
        "data_united = pd.merge(\n",
        "    data_united,\n",
        "    # REMOVE LATER\n",
        "    data_soil[temp_subset_start:temp_subset_end],\n",
        "    #\n",
        "    left_index = True,\n",
        "    right_index = True,\n",
        "    how = 'outer'\n",
        ")\n",
        "\n",
        "# data_united['diff_ro_cal'] = (data_united['weir_level_cal'] - data_united['raw_ro'])\n",
        "# data_united = minsince_feat(data_united, 'weir_level_cal')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f814e925",
      "metadata": {
        "id": "f814e925"
      },
      "source": [
        "### United features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "90f96840",
      "metadata": {
        "id": "90f96840"
      },
      "outputs": [],
      "source": [
        "data_united['diff_ro_cal'] = (data_united['weir_level_cal'] - data_united['raw_ro'])\n",
        "data_united['diff_ro_cal'] = data_united['diff_ro_cal'].astype(np.float32)\n",
        "data_united = timesince_feat(data_united, 'weir_level_cal', \"minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1621fcb7",
      "metadata": {
        "id": "1621fcb7"
      },
      "source": [
        "### Temporal features\n",
        "Modify temporal features to be based on sine and cosine transformations, which allows for the model to be based on the cyclical patterns of time rather than abrupt distances\n",
        "\n",
        "(e.g., the raw values Day 365 of the year is 'far' from Day 001, but in reality they are very near)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "dfbcf31a",
      "metadata": {
        "id": "dfbcf31a"
      },
      "outputs": [],
      "source": [
        "def temporal_feat(input_df, input_unit):\n",
        "    output_df = input_df\n",
        "    if input_unit=='day':\n",
        "        cycle_length = 365.25\n",
        "        value = output_df.index.dayofyear\n",
        "    elif input_unit=='month':\n",
        "        cycle_length = 12\n",
        "        value = output_df.index.month\n",
        "    elif input_unit=='hour':\n",
        "        cycle_length = 24\n",
        "        value = output_df.index.hour\n",
        "    elif input_unit=='minute':\n",
        "        cycle_length = 60\n",
        "        value = output_df.index.minute\n",
        "\n",
        "    output_df[f'{input_unit}_sin'] = np.sin(2 * np.pi * value / cycle_length).astype(np.float32)\n",
        "    output_df[f'{input_unit}_cos'] = np.cos(2 * np.pi * value / cycle_length).astype(np.float32)\n",
        "\n",
        "    return output_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "72593493",
      "metadata": {
        "id": "72593493"
      },
      "outputs": [],
      "source": [
        "data_united = temporal_feat(data_united, 'minute')\n",
        "data_united = temporal_feat(data_united, 'hour')\n",
        "data_united = temporal_feat(data_united, 'day')\n",
        "data_united = temporal_feat(data_united, 'month')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4b5605",
      "metadata": {
        "id": "9b4b5605"
      },
      "outputs": [],
      "source": [
        "# # Create feature to track soil value staleness\n",
        "# cols_soil = [col for col in data_united.columns if (col.endswith('shallow') | col.endswith('deep'))]\n",
        "# soil_instances = data_united[cols_soil].notna()\n",
        "# soil_group_id = soil_instances.cumsum().max(axis=1)\n",
        "# data_united[\"since_soil\"] = data_united.groupby(soil_group_id).cumcount()\n",
        "\n",
        "# del soil_instances, soil_group_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "0a4e0dc4",
      "metadata": {
        "id": "0a4e0dc4"
      },
      "outputs": [],
      "source": [
        "# create features to track soil value staleness\n",
        "cols_soil = [col for col in data_united.columns if (col.endswith('shallow') | col.endswith('deep'))]\n",
        "\n",
        "for col in cols_soil:\n",
        "# for col in data_united.columns:\n",
        "    # if (col.endswith('shallow') | col.endswith('deep')):\n",
        "    # data_united = minsince_feat(data_united, col)\n",
        "    data_united = timesince_feat(data_united, col, \"days\")\n",
        "\n",
        "# Extend soil vals\n",
        "data_united[cols_soil] = data_united[cols_soil].ffill()\n",
        "\n",
        "# Cutoff\n",
        "# cols_soil_days = [col for col in data_united.columns if (col.startswith('daysince_') & (col.endswith('_shallow') | col.endswith('_deep')))]\n",
        "# data_united['daysince_soil'] = data_united[cols_soil_days].min(axis=1)\n",
        "\n",
        "\n",
        "del col, cols_soil\n",
        "# data_united.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd20a0d9",
      "metadata": {
        "id": "bd20a0d9"
      },
      "source": [
        "## Train/Test split\n",
        "\n",
        "80/20 initial split, with expanding sliding window for training/validation for hyperparameters, model stability, and feature selection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "1741c777",
      "metadata": {
        "id": "1741c777"
      },
      "outputs": [],
      "source": [
        "# REMOVE NAs\n",
        "data_united = data_united.dropna(subset=[var_of_interest])\n",
        "\n",
        "X_all = data_united.drop(var_of_interest, axis=1).copy()\n",
        "y_all = data_united[var_of_interest].copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix for inferred later\n",
        "# y_all = y_all.astype(bool)\n",
        "y_all = y_all.astype(np.float32)\n",
        "\n",
        "for col in X_all.columns:\n",
        "  if str(X_all[col].dtype) == ('Int32'):\n",
        "    X_all[col] = X_all[col].astype(np.float32)\n",
        "\n",
        "y_all.info()\n",
        "X_all.info()"
      ],
      "metadata": {
        "id": "X67HeQIcaYxM",
        "outputId": "58750d37-a1db-45cb-ba1d-938f28ade934",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "X67HeQIcaYxM",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "DatetimeIndex: 1134443 entries, 2001-02-01 00:00:00 to 2011-12-31 23:55:00\n",
            "Series name: obstruction_ro\n",
            "Non-Null Count    Dtype  \n",
            "--------------    -----  \n",
            "1134443 non-null  float32\n",
            "dtypes: float32(1)\n",
            "memory usage: 13.0 MB\n",
            "<class 'cudf.core.dataframe.DataFrame'>\n",
            "DatetimeIndex: 1134443 entries, 2001-02-01 00:00:00 to 2011-12-31 23:55:00\n",
            "Columns: 147 entries, ra_rain to daysince_10.0_deep\n",
            "dtypes: float32(146), float64(1)\n",
            "memory usage: 649.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "df5ab1ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df5ab1ce",
        "outputId": "97b65f93-1823-40ea-82a0-df5c8339af82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1134443\n",
            "1134443\n",
            "Train:\t80p of 1134443 is 907554\n",
            "Test:\t20p of 1134443 is 226889\n"
          ]
        }
      ],
      "source": [
        "y_len = len(y_all)\n",
        "\n",
        "print(\n",
        "    y_len, \"\\n\",\n",
        "    (round(.2*y_len) + round(.8*y_len)),\n",
        "    \"\\nTrain:\\t80p of \", y_len, \" is \", round(.8*y_len),\n",
        "    \"\\nTest:\\t20p of \", y_len, \" is \", round(.2*y_len),\n",
        "    sep=\"\"\n",
        ")\n",
        "\n",
        "del y_len"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7daf36fd",
      "metadata": {
        "id": "7daf36fd"
      },
      "source": [
        "Unlike the typical approach for train/test splits, temporal data in this context must _not_ be randomly split as it would lead to severe leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7e023cfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e023cfb",
        "outputId": "92dd34b1-5b49-403d-ea1b-a1f4dbd98c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\t 907554 \t 2001-02-01 00:00:00 thru 2009-10-26 18:05:00 \n",
            "Test:\t 226889 \t 2009-10-26 18:10:00 thru 2011-12-31 23:55:00\n"
          ]
        }
      ],
      "source": [
        "# Conduct the split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, shuffle=False)\n",
        "# Conduct an inner split for tuning\n",
        "X_train_inner, X_test_inner, y_train_inner, y_test_inner = train_test_split(X_train, y_train, test_size = 0.2, shuffle=False)\n",
        "\n",
        "# Cleanup\n",
        "del X_all, y_all\n",
        "\n",
        "print(\n",
        "    \"Train:\\t\", len(X_train), \"\\t\", X_train.index[0], \"thru\", X_train.index[-1],\n",
        "    \"\\nTest:\\t\", len(X_test), \"\\t\", X_test.index[0], \"thru\", X_test.index[-1]\n",
        "    # len(x_train), len(x_test), \"\\n\",\n",
        "    # x_train.index[-1]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11921d04",
      "metadata": {
        "id": "11921d04"
      },
      "source": [
        "### Sliding Window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "661eeac5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "661eeac5",
        "outputId": "9b9962f4-1d91-4165-e41e-1dd4239013c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0:\n",
            "  Train: index=[     0      1      2 ... 181510 181511 181512]\n",
            "  Test:  index=[181513 181514 181515 ... 363020 363021 363022]\n",
            "------------------------------------------------------------\n",
            "Fold 1:\n",
            "  Train: index=[     0      1      2 ... 363020 363021 363022]\n",
            "  Test:  index=[363023 363024 363025 ... 544530 544531 544532]\n",
            "------------------------------------------------------------\n",
            "Fold 2:\n",
            "  Train: index=[     0      1      2 ... 544530 544531 544532]\n",
            "  Test:  index=[544533 544534 544535 ... 726040 726041 726042]\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Initialize the split function\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "# print(tscv)\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(tscv.split(X_train_inner)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    print(f\"  Train: index={train_index}\")\n",
        "    print(f\"  Test:  index={val_index}\")\n",
        "    # print(\"  Train: index=\", mini_x.index[train_index])\n",
        "    # print(f\"  Test:  index={val_index}\")\n",
        "    print(\"------------------------------------------------------------\")\n",
        "\n",
        "del i, train_index, val_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c343fa3",
      "metadata": {
        "id": "9c343fa3"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a8a3293",
      "metadata": {
        "id": "0a8a3293"
      },
      "source": [
        "As per XGBoosting documentation/tutorials, early stopping with random search for hyperparameter tuning must be iterated upon manually, as `RandomizedSearchCV` does not support using a separate validation set within each CV fold.\n",
        "\n",
        "Source: https://xgboosting.com/xgboost-early-stopping-with-random-search/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "351db094",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "351db094",
        "outputId": "01ac592f-53f9-47fe-fbce-7f410c9857b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': np.float64(0.03731143088741836), 'max_depth': np.int64(6), 'subsample': np.float64(0.987811175818378), 'colsample_bytree': np.float64(0.8566838211942118)}\n",
            "Best CV Average F1: 0.053235295735828574\n",
            "Best Avg Rounds: 86\n"
          ]
        }
      ],
      "source": [
        "# Code modified from\n",
        "# https://xgboosting.com/xgboost-early-stopping-with-random-search/\n",
        "\n",
        "# Define hyperparameter distributions for random search\n",
        "param_distributions = {\n",
        "    'learning_rate': ('uniform', 0.01, 0.3),\n",
        "    'max_depth': ('choice', [3, 6, 9, 12]),\n",
        "    'subsample': ('uniform', 0.5, 1.0),\n",
        "    'colsample_bytree': ('uniform', 0.4, 1.0)\n",
        "}\n",
        "\n",
        "# # Function to sample parameters based on their distribution type\n",
        "# def sample_param(distribution):\n",
        "#     if distribution[0] == 'uniform':\n",
        "#         return uniform(distribution[1], distribution[2] - distribution[1]).rvs()\n",
        "#     elif distribution[0] == 'choice':\n",
        "#         return np.random.choice(distribution[1])\n",
        "#     else:\n",
        "#         raise ValueError(f\"Unsupported distribution type: {distribution[0]}\")\n",
        "\n",
        "\n",
        "# Define a global seed or a seeded generator object once at the start of your script\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "# Function to sample parameters based on their distribution type\n",
        "def sample_param(distribution):\n",
        "    if distribution[0] == 'uniform':\n",
        "        # Use the seeded generator to create the scipy distribution\n",
        "        return uniform(loc=distribution[1], scale=distribution[2] - distribution[1]).rvs(random_state=rng)\n",
        "    elif distribution[0] == 'choice':\n",
        "        # Use the seeded generator's choice method\n",
        "        return rng.choice(distribution[1])\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported distribution type: {distribution[0]}\")\n",
        "\n",
        "# Configure cross-validation and early stopping\n",
        "n_splits = 5\n",
        "early_stopping_rounds = 10\n",
        "\n",
        "# Perform random search with early stopping\n",
        "n_iterations = 3\n",
        "best_params = None\n",
        "best_score = 0\n",
        "best_avg_rounds = 0\n",
        "\n",
        "for _ in range(n_iterations):\n",
        "    test_scores = []\n",
        "    best_rounds = []\n",
        "    optimal_rounds_list = []\n",
        "    params = {k: sample_param(v) for k, v in param_distributions.items()}\n",
        "\n",
        "    for train_index, test_index in tscv.split(X_train_inner):\n",
        "        X_train_fold, X_test_fold = X_train_inner.iloc[train_index], X_train_inner.iloc[test_index]\n",
        "        y_train_fold, y_test_fold = y_train_inner.iloc[train_index], y_train_inner.iloc[test_index]\n",
        "\n",
        "        # Split train set into train and validation\n",
        "        X_train_fold, X_val, y_train_fold, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.2, shuffle=False)\n",
        "\n",
        "        # Prep hyperparam\n",
        "        neg_count_fold = (y_train_fold == 0).sum()\n",
        "        pos_count_fold = (y_train_fold == 1).sum()\n",
        "\n",
        "        # Prepare the model\n",
        "        model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=params['learning_rate'],\n",
        "            max_depth=int(params['max_depth']),  # max_depth should be an int\n",
        "            subsample=params['subsample'],\n",
        "            colsample_bytree=params['colsample_bytree'],\n",
        "            objective='binary:logistic',\n",
        "            random_state=42,\n",
        "            ## SETTINGS FOR GPU\n",
        "            seed_per_iteration = True,\n",
        "            tree_method='hist',\n",
        "            device='cuda',\n",
        "            scale_pos_weight= neg_count_fold/pos_count_fold,\n",
        "            ##\n",
        "            n_jobs=-1,\n",
        "            early_stopping_rounds=early_stopping_rounds # fixed early stopping\n",
        "        )\n",
        "\n",
        "        # Fit model on train fold and use validation for early stopping\n",
        "        model.fit(X_train_fold, y_train_fold, eval_set=[(X_val, y_val)], verbose=False)\n",
        "\n",
        "        # Find optimal number of iterations\n",
        "        optimal_rounds_list.append(model.best_iteration)\n",
        "\n",
        "        # Predict on test set\n",
        "        y_pred_test = model.predict(X_test_fold)\n",
        "        # test_score = accuracy_score(y_test_fold, y_pred_test)\n",
        "        test_score = f1_score(y_test_fold, y_pred_test)\n",
        "        test_scores.append(test_score)\n",
        "\n",
        "    # Compute average score across all folds\n",
        "    average_score = np.mean(test_scores)\n",
        "    average_optimal_rounds = np.mean(optimal_rounds_list)\n",
        "\n",
        "    if average_score > best_score:\n",
        "        best_score = average_score\n",
        "        best_params = params\n",
        "        best_avg_rounds = int(round(average_optimal_rounds)) # Store the integer average\n",
        "        ## Maybe??\n",
        "        # best_model = model\n",
        "\n",
        "del X_train_fold, X_val, y_train_fold, y_val\n",
        "del y_pred_test, test_score\n",
        "del n_splits, early_stopping_rounds, n_iterations, test_scores, best_rounds, optimal_rounds_list\n",
        "del neg_count_fold, pos_count_fold\n",
        "del average_score, average_optimal_rounds\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "# print(f\"Best CV Average Accuracy: {best_score}\")\n",
        "print(f\"Best CV Average F1: {best_score}\")\n",
        "print(f\"Best Avg Rounds: {best_avg_rounds}\")\n",
        "#\n",
        "# print(f\"Best model: {best_model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "e5f41280",
      "metadata": {
        "id": "e5f41280"
      },
      "outputs": [],
      "source": [
        "_ = playsound(get_path('completed.mp3', 'code'), block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8e29ff",
      "metadata": {
        "id": "5e8e29ff"
      },
      "outputs": [],
      "source": [
        "# model_name = \"random_search_mini_xgboosting\"\n",
        "\n",
        "# if os.path.exists(model_path(model_name)) == False:\n",
        "#     print(\"Saving model\")\n",
        "#     # model.fit(\n",
        "#     #     X_train_two, y_train_two,\n",
        "#     #     # early_stopping_rounds=50, # Stop if validation metric doesn't improve for 50 rounds\n",
        "#     #     eval_set=eval_set,\n",
        "#     #     verbose=False # Set to True if you want to watch the early stopping logs\n",
        "#     # )\n",
        "#     # random_search.fit(X_train_inner, y_train_inner)\n",
        "\n",
        "#     # Save\n",
        "#     joblib.dump(best_model, model_path(model_name))\n",
        "# else:\n",
        "#     print(\"Importing model from saved files...\")\n",
        "#     best_model = joblib.load(model_path(model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "e4cd5517",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4cd5517",
        "outputId": "4f8eedf1-5bb6-4d6e-f0d2-d21534db83b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importing model from saved files...\n"
          ]
        }
      ],
      "source": [
        "model_name = \"rs_xgb_cpu\"\n",
        "\n",
        "if os.path.exists(model_path(model_name)) == False:\n",
        "    print(\"Fitting final model...\")\n",
        "\n",
        "    # XGBoost requires int for certain params\n",
        "    best_params['max_depth'] = int(best_params['max_depth'])\n",
        "\n",
        "    # Prep hyperparam\n",
        "    neg_count_it = (y_train_inner == 0).sum()\n",
        "    pos_count_it = (y_train_inner == 1).sum()\n",
        "\n",
        "    final_model = xgb.XGBClassifier(\n",
        "        n_estimators=best_avg_rounds,\n",
        "        # n_estimators=100, # avg optimal n_estimators if known, or reasonable default\n",
        "        learning_rate=best_params['learning_rate'],\n",
        "        max_depth=best_params['max_depth'],\n",
        "        subsample=best_params['subsample'],\n",
        "        colsample_bytree=best_params['colsample_bytree'],\n",
        "        objective='binary:logistic',\n",
        "        random_state=42,\n",
        "        ## SETTINGS FOR GPU\n",
        "        seed_per_iteration = True,\n",
        "        tree_method='hist',\n",
        "        device='cuda',\n",
        "        scale_pos_weight= neg_count_it/pos_count_it,\n",
        "        ##\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    final_model.fit(X_train_inner, y_train_inner)\n",
        "    joblib.dump(final_model, model_path(model_name))\n",
        "\n",
        "    del neg_count_it, pos_count_it\n",
        "\n",
        "    # Local download\n",
        "    from google.colab import files\n",
        "    files.download(model_path(model_name))\n",
        "\n",
        "else:\n",
        "    print(\"Importing model from saved files...\")\n",
        "    final_model = joblib.load(model_path(model_name))\n",
        "\n",
        "# print(\"Final model has been fitted on the entire dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresholds\n",
        "X_itest_train, X_itest_test, y_itest_train, y_itest_test = train_test_split(X_test_inner, y_test_inner, test_size=0.2, shuffle=False)\n",
        "\n",
        "threshold = 0.5\n",
        "y_proba = final_model.predict_proba(X_itest_train)[:,1]\n",
        "y_bin = (y_proba >= threshold).astype(np.int32)\n",
        "best_f1 = f1_score(y_itest_train, y_bin)\n",
        "print(f\"F1 at default 0.5 threshold: {best_f1:.4f}\")\n",
        "\n",
        "best_threshold = 0\n",
        "thresholds = np.linspace(0.01, 0.99, 100)\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_bin = (y_proba >= threshold).astype(np.int32)\n",
        "    current_f1 = f1_score(y_itest_train, y_bin)\n",
        "\n",
        "    if current_f1 > best_f1:\n",
        "        best_f1 = current_f1\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"Optimal Threshold Found: {best_threshold:.4f}\")\n",
        "print(f\"Best F1 Score at this threshold: {best_f1:.4f}\")\n",
        "\n",
        "y_proba_test = final_model.predict_proba(X_itest_test)[:,1]\n",
        "final_predictions = (y_proba_test >= best_threshold).astype(np.int32)\n",
        "\n",
        "print(\"\\n--- Final Metrics on Holdout Set (using optimal threshold) ---\")\n",
        "print(f\"F1 Score: {f1_score(y_itest_test, final_predictions)}\")\n",
        "print(f\"Accuracy Score: {accuracy_score(y_itest_test, final_predictions)}\")\n",
        "print(f\"Precision Score: {precision_score(y_itest_test, final_predictions)}\")\n",
        "print(f\"Recall Score: {recall_score(y_itest_test, final_predictions)}\")\n",
        "\n",
        "del y_proba, threshold, thresholds, best_f1\n",
        "del X_itest_train, y_itest_train\n",
        "# del X_itest_train, X_itest_test, y_itest_train, y_itest_test"
      ],
      "metadata": {
        "id": "GZXN5p8gg1RN",
        "outputId": "298336bf-ab56-47a7-b405-62d5d4431d96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GZXN5p8gg1RN",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 at default 0.5 threshold: 0.5923\n",
            "Optimal Threshold Found: 0.5148\n",
            "Best F1 Score at this threshold: 0.5932\n",
            "\n",
            "--- Final Metrics on Holdout Set (using optimal threshold) ---\n",
            "F1 Score: 0.5917732457656412\n",
            "Accuracy Score: 0.8048095198743905\n",
            "Precision Score: 0.5156626506024097\n",
            "Recall Score: 0.6942416869424168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "701b4a53",
      "metadata": {
        "id": "701b4a53"
      },
      "outputs": [],
      "source": [
        "# Does not work with GPUs :<\n",
        "\n",
        "# X_itest_mini, X_holdout, y_itest_mini, y_holdout = train_test_split(X_test_inner, y_test_inner, test_size=0.2, random_state=42, shuffle=False)\n",
        "\n",
        "# t_tuner = TunedThresholdClassifierCV(\n",
        "#     estimator=final_model,\n",
        "#     scoring=make_scorer(f1_score),\n",
        "#     cv=\"prefit\",\n",
        "#     thresholds=100,\n",
        "#     refit=False,\n",
        "#     n_jobs=-1\n",
        "# )\n",
        "\n",
        "# t_tuner.fit(X_itest_mini, y_itest_mini)\n",
        "\n",
        "# print(\n",
        "#     \"Threshold:\", t_tuner.best_threshold_,\n",
        "#     \"F1:\", t_tuner.best_score_\n",
        "# )\n",
        "\n",
        "# t_x_pred = t_tuner.predict(X_holdout)\n",
        "\n",
        "# print(\n",
        "#     f1_score(y_holdout, t_x_pred),\n",
        "#     accuracy_score(y_holdout, t_x_pred),\n",
        "#     precision_score(y_holdout, t_x_pred),\n",
        "#     recall_score(y_holdout, t_x_pred),\n",
        "#     sep=\"\\n\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e734f9b6",
      "metadata": {
        "id": "e734f9b6"
      },
      "source": [
        "## Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will run on CPU."
      ],
      "metadata": {
        "id": "kGoWSrififBU"
      },
      "id": "kGoWSrififBU"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "b82de6d5",
      "metadata": {
        "id": "b82de6d5"
      },
      "outputs": [],
      "source": [
        "def apply_smoothing(predictions_array, window_size=5):\n",
        "    predictions_series = pd.Series(predictions_array)\n",
        "    smoothed = predictions_series.rolling(\n",
        "        window=window_size,\n",
        "        center=True,\n",
        "        min_periods=1\n",
        "    ).apply(lambda x: np.bincount(x.astype(int)).argmax(), raw=False).astype(int)\n",
        "    return smoothed.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "079ec9bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "079ec9bc",
        "outputId": "de8758af-5bc2-4b5c-f6de-ff89c4bac21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No window F1:\t 0.5917732457656412\n",
            "Window 3 F1:\t 0.5917132484296663\n",
            "Window 5 F1:\t 0.5925285368384642\n",
            "Window 7 F1:\t 0.5923236514522822\n",
            "Window 9 F1:\t 0.5935498759591531\n",
            "Window 11 F1:\t 0.5938582313553452\n",
            "Window 13 F1:\t 0.5939141982793463\n",
            "Optimal window size: 13\n",
            "Best F1: 0.5939141982793463\n"
          ]
        }
      ],
      "source": [
        "# Smallest window size\n",
        "window_min = 3\n",
        "# Largest window size\n",
        "window_max = 13\n",
        "\n",
        "# Start w no smoothing\n",
        "best_window_size = 1\n",
        "# best_smoothing_f1 = f1_score(y_itest_test, t_x_pred)\n",
        "best_smoothing_f1 = f1_score(y_itest_test, final_predictions)\n",
        "print(\"No window F1:\\t\", best_smoothing_f1)\n",
        "\n",
        "# test range of odd window sizes\n",
        "# for window_size in [3, 5, 7, 9, 11]:\n",
        "for window_size in range(window_min, window_max+1, 2):\n",
        "    # print(\"Testing window =\", window_size)\n",
        "    smoothed_preds = apply_smoothing(final_predictions, window_size=window_size)\n",
        "    f1 = f1_score(y_itest_test, smoothed_preds)\n",
        "    print(\"Window\", window_size, \"F1:\\t\", f1)\n",
        "\n",
        "    if f1 > best_smoothing_f1:\n",
        "        # print(\"F1 improved with smoothing!\")\n",
        "        best_smoothing_f1 = f1\n",
        "        best_window_size = window_size\n",
        "\n",
        "print(f\"Optimal window size: {best_window_size}\")\n",
        "print(f\"Best F1: {best_smoothing_f1}\")\n",
        "\n",
        "del window_min, window_max, f1, window_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "0f0d6983",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f0d6983",
        "outputId": "c3939f6a-1222-4830-b719-12be429a68ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model (0.5 threshold, no smoothing)\n",
            "F1:\t0.5619\n",
            "Acc:\t0.8560\n",
            "Pre:\t0.5218\n",
            "Rec:\t0.6087\n",
            "-----------------------------------\n",
            "Optmized threshold of 0.5148\n",
            "F1:\t0.5619\n",
            "Acc:\t0.8560\n",
            "Pre:\t0.5218\n",
            "Rec:\t0.6087\n",
            "-----------------------------------\n",
            "Windowed with 13\n",
            "F1:\t0.5624\n",
            "Acc:\t0.8569\n",
            "Pre:\t0.5245\n",
            "Rec:\t0.6061\n",
            "-----------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Final! 3 dec places\n",
        "# t_x_pred_f = t_tuner.predict(X_test)\n",
        "final_pred_y = final_model.predict_proba(X_test)[:,1]\n",
        "final_pred_y = (final_pred_y >= 0.5).astype(np.int32)\n",
        "\n",
        "print(\"Base model (0.5 threshold, no smoothing)\")\n",
        "\n",
        "print(\n",
        "    f\"F1:\\t{f1_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Acc:\\t{accuracy_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Pre:\\t{precision_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Rec:\\t{recall_score(y_test, final_pred_y):.4f}\",\n",
        "    \"-----------------------------------\",\n",
        "    sep=\"\\n\"\n",
        ")\n",
        "\n",
        "print(f\"Optmized threshold of {best_threshold:.4f}\")\n",
        "\n",
        "final_pred_y = (final_pred_y >= best_threshold).astype(np.int32)\n",
        "\n",
        "print(\n",
        "    f\"F1:\\t{f1_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Acc:\\t{accuracy_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Pre:\\t{precision_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Rec:\\t{recall_score(y_test, final_pred_y):.4f}\",\n",
        "    \"-----------------------------------\",\n",
        "    sep=\"\\n\"\n",
        ")\n",
        "\n",
        "# t_x_pred_f = t_tuner.predict(X_test)\n",
        "print(\"Windowed with\", best_window_size)\n",
        "\n",
        "final_pred_y = apply_smoothing(final_pred_y, window_size=best_window_size)\n",
        "\n",
        "print(\n",
        "    f\"F1:\\t{f1_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Acc:\\t{accuracy_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Pre:\\t{precision_score(y_test, final_pred_y):.4f}\",\n",
        "    f\"Rec:\\t{recall_score(y_test, final_pred_y):.4f}\",\n",
        "    \"-----------------------------------\",\n",
        "    sep=\"\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88e65531",
      "metadata": {
        "id": "88e65531"
      },
      "source": [
        "## drafting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61270f7f",
      "metadata": {
        "id": "61270f7f"
      },
      "outputs": [],
      "source": [
        "param_dist = {\n",
        "    'n_estimators': randint(50, 500), # early stopping control the actual number\n",
        "    'learning_rate': uniform(0.01, 0.29),\n",
        "    'max_depth': randint(3, 7),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    early_stopping_rounds=50,\n",
        "    objective='binary:logistic',\n",
        "    tree_method='hist',\n",
        "    n_jobs=-1,\n",
        "    eval_metric='logloss',\n",
        "    scale_pos_weight = (np.sum(y_train_inner == 0) / np.sum(y_train_inner == 1))\n",
        "    # scale_pos_weight = (y_sub_train.value_counts()[False] / y_sub_train.value_counts()[True]).item()\n",
        ")\n",
        "\n",
        "# Randomized search with efficient settings\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_dist,\n",
        "    # n_iter=20,                    # Start with a small number of iterations (e.g., 20-40)\n",
        "    n_iter=2,\n",
        "    scoring='roc_auc',\n",
        "    cv=tscv,                      # Use TimeSeriesSplit\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    return_train_score=True\n",
        "    # refit=True\n",
        ")\n",
        "\n",
        "# When you run the fit, ensure you pass early stopping parameters:\n",
        "# X_train, y_train, X_val, y_val = ... define your data ...\n",
        "# eval_set = [(X_train, y_train), (X_val, y_val)]\n",
        "#\n",
        "# random_search.fit(\n",
        "#     X_train, y_train,\n",
        "#     early_stopping_rounds=50, # Stop if validation metric doesn't improve for 50 rounds\n",
        "#     eval_set=eval_set,\n",
        "#     verbose=False # Set to True if you want to watch the early stopping logs\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14a97d07",
      "metadata": {
        "id": "14a97d07"
      },
      "outputs": [],
      "source": [
        "X_train_two, X_val, y_train_two, y_val = train_test_split(X_train_inner, y_train_inner, test_size = 0.2, shuffle=False)\n",
        "eval_set = [(X_train_two, y_train_two), (X_val, y_val)]\n",
        "\n",
        "# print(\"Starting hyperparameter tuning...\")\n",
        "# random_search.fit(X_sub_train, y_sub_train)\n",
        "# X_train_two = X_train_two.drop(i_to_drop, errors='ignore')\n",
        "# y_train_two = y_train_two.drop(i_to_drop, errors='ignore')\n",
        "# X_val = X_val.drop(i_to_drop, errors='ignore')\n",
        "# y_val = y_val.drop(i_to_drop, errors = 'ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a80eaf40",
      "metadata": {
        "id": "a80eaf40"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Check main training labels\n",
        "if y_train_two.isnull().any() or np.isinf(y_train_two).any():\n",
        "    print(\"ERROR: y_train contains NaN or Inf values!\")\n",
        "\n",
        "# Check validation labels (if you are using an eval_set)\n",
        "# Assuming y_val is the label portion of your validation set\n",
        "if y_val.isnull().any() or np.isinf(y_val).any():\n",
        "    print(\"ERROR: y_val contains NaN or Inf values!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75109175",
      "metadata": {
        "id": "75109175"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     if data_weir.empty == False:\n",
        "#         print(\"Data loaded, random sample shown below\")\n",
        "#         print(data_weir.sample(n=5))\n",
        "# except NameError:\n",
        "#     print(\"Data has not yet been read in, loading now...\")\n",
        "#     data_weir = pd.read_csv(\n",
        "#         \"data/bci_lutzweir_combined.csv\",\n",
        "#         usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
        "#         parse_dates=['datetime'],\n",
        "#         dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
        "#         date_format='%d/%m/%Y %H:%M:%S'\n",
        "#     )\n",
        "# import os\n",
        "# if os.path.exists(get_path('models/random_search_mini_spw.joblib', 'outputs')):\n",
        "#     continue\n",
        "# else:\n",
        "#     print(\"nope\")\n",
        "# os.path.exists(get_path('models/random_search_mini_spw2.joblib', 'outputs')) == False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9952c2f0",
      "metadata": {
        "id": "9952c2f0"
      },
      "outputs": [],
      "source": [
        "# def model_path(input_name):\n",
        "#     mod_loc = \"models/\"+input_name+\".joblib\"\n",
        "#     return get_path(mod_loc, 'outputs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147a80c6",
      "metadata": {
        "id": "147a80c6"
      },
      "outputs": [],
      "source": [
        "# os.path.exists(model_path(\"random_search_mini_spw\")) == False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6aaeaa4",
      "metadata": {
        "id": "d6aaeaa4"
      },
      "outputs": [],
      "source": [
        "# model_name = \"random_search_mini_inner\"\n",
        "model_name = \"random_search_mini_spw\"\n",
        "\n",
        "\n",
        "if os.path.exists(model_path(model_name)) == False:\n",
        "    print(\"Starting hyperparameter tuning...\")\n",
        "    # random_search.fit(\n",
        "    #     X_train_two, y_train_two,\n",
        "    #     # early_stopping_rounds=50, # Stop if validation metric doesn't improve for 50 rounds\n",
        "    #     eval_set=eval_set,\n",
        "    #     verbose=False # Set to True if you want to watch the early stopping logs\n",
        "    # )\n",
        "    random_search.fit(X_train_inner, y_train_inner)\n",
        "\n",
        "    # Save\n",
        "    joblib.dump(random_search, model_path(model_name))\n",
        "else:\n",
        "    print(\"Importing model from saved files...\")\n",
        "    random_search = joblib.load(model_path(model_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0c2af0",
      "metadata": {
        "id": "5a0c2af0"
      },
      "outputs": [],
      "source": [
        "# # Saving result\n",
        "# import joblib\n",
        "\n",
        "# filename = 'random_search_results.joblib'\n",
        "# joblib.dump(random_search, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1de8f3e",
      "metadata": {
        "id": "f1de8f3e"
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "# joblib.dump(random_search, get_path('models/random_search_mini_spw.joblib', 'outputs'))\n",
        "\n",
        "# Make a chime to indicate completion\n",
        "_ = playsound(get_path('completed.mp3', 'code'), block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3ed4348",
      "metadata": {
        "id": "a3ed4348"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(random_search.best_params_)\n",
        "print(f\"Best F1 Score (averaged across CV folds): {random_search.best_score_:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abd4e43",
      "metadata": {
        "id": "6abd4e43"
      },
      "source": [
        "### Saving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0129148",
      "metadata": {
        "id": "b0129148"
      },
      "outputs": [],
      "source": [
        "best_model = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d614dcc",
      "metadata": {
        "id": "4d614dcc"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ae4e7c0",
      "metadata": {
        "id": "3ae4e7c0"
      },
      "outputs": [],
      "source": [
        "feature_importances = best_model.feature_importances_\n",
        "# map scores to feature names\n",
        "# feature_importances\n",
        "feature_names = X_train.columns.tolist()\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feat': feature_names,\n",
        "    'importance': feature_importances\n",
        "})\n",
        "\n",
        "# sort importance\n",
        "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "# print(feature_importance_df)\n",
        "feature_importance_df\n",
        "\n",
        "# most important features\n",
        "# print(feature_importance_df.head(25))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd348692",
      "metadata": {
        "id": "fd348692"
      },
      "outputs": [],
      "source": [
        "threshold_importance = 0.95\n",
        "# calculate most important 90 percent of the importance\n",
        "feature_importance_df['cumulative_imp'] = feature_importance_df['importance'].cumsum()\n",
        "features_percent = feature_importance_df[feature_importance_df['cumulative_imp'] <= threshold_importance].shape[0] + 1\n",
        "features_percent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4517ba9a",
      "metadata": {
        "id": "4517ba9a"
      },
      "outputs": [],
      "source": [
        "# Most important features:\n",
        "print(round(threshold_importance*100), \"% (most important features):\", features_percent)\n",
        "feature_importance_df.head(features_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f820c002",
      "metadata": {
        "id": "f820c002"
      },
      "outputs": [],
      "source": [
        "# feature_importance_df.tail(1)\n",
        "# Least important features:\n",
        "print(\"Remaining\", round((1-threshold_importance)*100), \"% (least important features):\", len(feature_names)-features_percent)\n",
        "feature_importance_df.tail(len(feature_names)-features_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1eb8627",
      "metadata": {
        "id": "a1eb8627"
      },
      "outputs": [],
      "source": [
        "# Features with 0 importance:\n",
        "print(\"Features with 0 importance:\", len(feature_importance_df[feature_importance_df['importance']==0]))\n",
        "\n",
        "feature_importance_df[feature_importance_df['importance']==0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a0dc876",
      "metadata": {
        "id": "1a0dc876"
      },
      "source": [
        "Feature importance by type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d908cbbe",
      "metadata": {
        "id": "d908cbbe"
      },
      "outputs": [],
      "source": [
        "mapping_dict = {\n",
        "    'soil': '_deep|_shallow',\n",
        "    'runoff':'ro',\n",
        "    'rain':'rain',\n",
        "    'calibration':'_cal'\n",
        "}\n",
        "\n",
        "for col_name, pattern in mapping_dict.items():\n",
        "    feature_importance_df[col_name] = feature_importance_df['feat'].str.contains(pattern, case=False, regex=True)\n",
        "\n",
        "feature_importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c6b4b8",
      "metadata": {
        "id": "31c6b4b8"
      },
      "outputs": [],
      "source": [
        "feature_importance_df['most'] = (feature_importance_df['cumulative_imp'] <= threshold_importance)\n",
        "feature_importance_df['zero'] = (feature_importance_df['importance'] == 0)\n",
        "\n",
        "cat_cols = list(mapping_dict.keys())\n",
        "\n",
        "table_feature_cat_importance = pd.DataFrame({\n",
        "    'Total features': feature_importance_df[cat_cols].sum(),\n",
        "    'Above threshold': feature_importance_df[feature_importance_df['most']][cat_cols].sum(),\n",
        "    'Below threshold': feature_importance_df[~feature_importance_df['most']][cat_cols].sum(),\n",
        "    'Zero importance': feature_importance_df[feature_importance_df['zero']][cat_cols].sum()\n",
        "}).fillna(0).astype(int)\n",
        "\n",
        "del cat_cols, mapping_dict\n",
        "\n",
        "table_feature_cat_importance.index.name = 'Category'\n",
        "\n",
        "table_feature_cat_importance"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64fc7875",
      "metadata": {
        "id": "64fc7875"
      },
      "source": [
        "## Classification Threshold\n",
        "\n",
        "By default, a threshold of 0.5 will be selected for categorizing a point as `True` or `False`. However, in this context a model more sensitive to `True` may make final results more accurate.\n",
        "\n",
        "This measure can be found by finding the threshold that maximizes the F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6851e234",
      "metadata": {
        "id": "6851e234"
      },
      "outputs": [],
      "source": [
        "# classifier_tuned = TunedThresholdClassifierCV(best_model, scoring=\"balanced_accuracy\").fit(X_train_two, y_train_two)\n",
        "# print(f\"Cut-off point found at {classifier_tuned.best_threshold_:.3f}\")\n",
        "t_tuner = TunedThresholdClassifierCV(\n",
        "    estimator=best_model,\n",
        "    scoring=make_scorer(f1_score),\n",
        "    cv=\"prefit\",\n",
        "    thresholds=100,\n",
        "    refit=False\n",
        ")\n",
        "\n",
        "t_tuner.fit(X_test_inner, y_test_inner)\n",
        "\n",
        "print(\n",
        "    \"Threshold:\", t_tuner.best_threshold_,\n",
        "    \"F1:\", t_tuner.best_score_\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a31854c6",
      "metadata": {
        "id": "a31854c6"
      },
      "outputs": [],
      "source": [
        "t_x_pred = t_tuner.predict(X_test_inner)\n",
        "\n",
        "print(\n",
        "    f1_score(y_test_inner, t_x_pred),\n",
        "    accuracy_score(y_test_inner, t_x_pred),\n",
        "    precision_score(y_test_inner, t_x_pred),\n",
        "    recall_score(y_test_inner, t_x_pred),\n",
        "    sep=\"\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "349fefba",
      "metadata": {
        "id": "349fefba"
      },
      "outputs": [],
      "source": [
        "_ = playsound(get_path('completed.mp3', 'code'), block=False)\n",
        "# X_train_two, X_val, y_train_two, y_val = train_test_split(X_train, y_train, test_size = 0.2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ff6a31",
      "metadata": {
        "id": "41ff6a31"
      },
      "outputs": [],
      "source": [
        "all_f1 = []\n",
        "all_accuracy = []\n",
        "all_precision = []\n",
        "all_recall = []\n",
        "optimal_thresholds = []\n",
        "performance_df = {}\n",
        "# performance_df = DataFrame()\n",
        "\n",
        "for fold, (index_train, index_val) in enumerate(tscv.split(X_train)):\n",
        "    print(\"Split\", fold)\n",
        "    X_sub_train, X_sub_val = X_train.iloc[index_train].copy(), X_train.iloc[index_val].copy()\n",
        "    y_sub_train, y_sub_val = y_train.iloc[index_train].copy(), y_train.iloc[index_val].copy()\n",
        "\n",
        "    # y_sub_train = y_sub_train.drop(i_to_drop, errors='ignore')\n",
        "\n",
        "    # if len(y_sub_train.unique()) != 2:\n",
        "    #     print(\"Skipping fold\", fold)\n",
        "    #     continue\n",
        "\n",
        "    # model = xgb.XGBClassifier(\n",
        "    #     objective='binary:logistic',\n",
        "    #     eval_metric='logloss',\n",
        "    #     tree_method = \"hist\",\n",
        "    #     random_state = 42,\n",
        "    #     scale_pos_weight = (y_sub_train.value_counts()[False] / y_sub_train.value_counts()[True]).item()\n",
        "    # )\n",
        "\n",
        "    print(\"Fitting model...\")\n",
        "    best_model.fit(\n",
        "        X_sub_train, y_sub_train,\n",
        "        # Evaluation set\n",
        "        eval_set = [(X_sub_val, y_sub_val)],\n",
        "        # Weight of False vs True\n",
        "        # early_stopping_rounds = 50,\n",
        "        # Silence messages\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    print(\"Predicting probabilities...\")\n",
        "    # Get probabilities for the positive class (class 1)\n",
        "    y_pred_proba = best_model.predict_proba(X_sub_val)[:, 1]\n",
        "\n",
        "    # 1. Calculate precision, recall, and thresholds for the current fold\n",
        "    precision, recall, thresholds = precision_recall_curve(y_sub_val, y_pred_proba)\n",
        "\n",
        "    # 2. Find the optimal threshold based on F1-score (or whichever metric you prefer)\n",
        "    fscores = (2 * precision * recall) / (precision + recall)\n",
        "    fscores[np.isnan(fscores)] = 0\n",
        "    optimal_idx = np.argmax(fscores)\n",
        "\n",
        "    # Need to handle the fact that thresholds array is one element shorter than P/R/F1 arrays\n",
        "    # Best practice is often to use the threshold just after the optimal index is found in P/R/F1 arrays\n",
        "    best_threshold = thresholds[optimal_idx]\n",
        "    optimal_thresholds.append(best_threshold)\n",
        "\n",
        "    print(f\"Fold {fold} Optimal Threshold (Max F1): {best_threshold:.4f}\")\n",
        "\n",
        "    # 3. Apply the *optimal* threshold to the validation predictions for THIS fold\n",
        "    y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
        "\n",
        "    # 4. Calculate metrics using the *optimally thresholded* predictions\n",
        "    print(\"Getting metrics using optimal threshold...\")\n",
        "    fold_f1 = f1_score(y_sub_val, y_pred_optimal)\n",
        "    fold_accuracy = accuracy_score(y_sub_val, y_pred_optimal)\n",
        "    fold_precision = precision_score(y_sub_val, y_pred_optimal)\n",
        "    fold_recall = recall_score(y_sub_val, y_pred_optimal)\n",
        "\n",
        "    all_f1.append(fold_f1)\n",
        "    all_accuracy.append(fold_accuracy)\n",
        "    all_precision.append(fold_precision)\n",
        "    all_recall.append(fold_recall)\n",
        "\n",
        "    # You might want to use a more structured DataFrame for performance_df construction\n",
        "    performance_df[fold] = {\n",
        "        'Threshold': best_threshold,\n",
        "        'F1': fold_f1,\n",
        "        'Accuracy': fold_accuracy,\n",
        "        'Precision': fold_precision,\n",
        "        'Recall': fold_recall\n",
        "    }\n",
        "\n",
        "    print(f\"{fold}\\tOptimal F1: {fold_f1:.4f}\\tAcc: {fold_accuracy:.4f}\\tPrec: {fold_precision:.4f}\\tRec: {fold_recall:.4f}\")\n",
        "    # print(\"Predicting...\")\n",
        "    # y_pred = best_model.predict(X_sub_val)\n",
        "    # y_pred_proba = best_model.predict_proba(X_sub_val)[:, 1]\n",
        "\n",
        "    # # 2. Calculate precision, recall, and thresholds for the current fold\n",
        "    # precision, recall, thresholds = precision_recall_curve(y_sub_val, y_pred_proba)\n",
        "\n",
        "    # # 3. Find the optimal threshold based on F1-score (a common choice for balance)\n",
        "    # # Calculate F1-score for every possible threshold\n",
        "    # fscores = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "    # # Handle potential division by zero warnings if no positive predictions were made\n",
        "    # fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "    # # Locate the index of the highest F1-score\n",
        "    # optimal_idx = np.argmax(fscores)\n",
        "    # best_threshold = thresholds[optimal_idx] # Note: thresholds array is one element shorter than P/R arrays\n",
        "\n",
        "    # optimal_thresholds.append(best_threshold)\n",
        "\n",
        "    # print(f\"Fold {fold} Optimal Threshold (Max F1): {best_threshold:.4f}\")\n",
        "\n",
        "\n",
        "    # print(\"Getting metrics...\")\n",
        "    # fold_f1 = f1_score(y_sub_val, y_pred)\n",
        "    # fold_accuracy = accuracy_score(y_sub_val, y_pred)\n",
        "    # fold_precision = precision_score(y_sub_val, y_pred)\n",
        "    # fold_recall = recall_score(y_sub_val, y_pred)\n",
        "\n",
        "    # all_f1.append(fold_f1)\n",
        "    # all_accuracy.append(fold_accuracy)\n",
        "    # all_precision.append(fold_precision)\n",
        "    # all_recall.append(fold_recall)\n",
        "    # performance_df[fold] = {best_threshold, fold_f1, fold_accuracy, fold_precision, fold_recall}\n",
        "\n",
        "    # print(f\"{fold}\\tF1: {fold_f1:.4f}\\tAcc{fold_accuracy:.4f}\\tPrec{fold_precision:.4f}\\tRec: {fold_recall:.4f}\")\n",
        "\n",
        "print(performance_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e29f22",
      "metadata": {
        "id": "e5e29f22"
      },
      "outputs": [],
      "source": [
        "_ = playsound(get_path('completed.mp3', 'code'), block=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9585c2a0",
      "metadata": {
        "id": "9585c2a0"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(performance_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc23c8fa",
      "metadata": {
        "id": "dc23c8fa"
      },
      "source": [
        "# draft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1980a391",
      "metadata": {
        "id": "1980a391"
      },
      "outputs": [],
      "source": [
        "# Initialize\n",
        "optimal_thresholds = []\n",
        "\n",
        "# Calculate precision-recall curve info from predicted values of validation set\n",
        "precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
        "\n",
        "fscores = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "# fixies div by 0 errors\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# find index of highest F1\n",
        "optimal_idx = np.argmax(fscores)\n",
        "best_threshold = thresholds[optimal_idx] # thresholds array is one element shorter than P/R arrays\n",
        "\n",
        "optimal_thresholds.append(best_threshold)\n",
        "\n",
        "print(f\"Fold {fold} Optimal Threshold (Max F1): {best_threshold:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee0ea2d",
      "metadata": {
        "id": "6ee0ea2d"
      },
      "outputs": [],
      "source": [
        "best_params = random_search.best_params_\n",
        "\n",
        "# final model w optimized params\n",
        "final_optimized_model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='logloss',\n",
        "    # use_label_encoder=False,\n",
        "    tree_method='hist',\n",
        "    random_state=42,\n",
        "    **best_params # unpack best params\n",
        ")\n",
        "\n",
        "final_optimized_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497b35b3",
      "metadata": {
        "id": "497b35b3"
      },
      "outputs": [],
      "source": [
        "# Make a chime to indicate completion\n",
        "_ = playsound(get_path('completed.mp3', 'code'), block=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad3d368c",
      "metadata": {
        "id": "ad3d368c"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d575a7",
      "metadata": {
        "id": "99d575a7"
      },
      "outputs": [],
      "source": [
        "print(\"Predicting...\")\n",
        "y_pred = final_optimized_model.predict(X_test)\n",
        "y_pred_proba = final_optimized_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# current fold info\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "# # Find the optimal threshold\n",
        "# Calculate F1-score for every possible threshold\n",
        "fscores = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "# Handle potential division by zero warnings\n",
        "# if no positive predictions were made\n",
        "fscores[np.isnan(fscores)] = 0\n",
        "\n",
        "# index of highest F1\n",
        "optimal_idx = np.argmax(fscores)\n",
        "best_threshold = thresholds[optimal_idx] # Note: thresholds array is one element shorter than P/R arrays\n",
        "\n",
        "print(f\"Best threshold: {best_threshold:.4f}\")\n",
        "\n",
        "# print(f\"Fold {fold} Optimal Threshold (Max F1): {best_threshold:.4f}\")\n",
        "\n",
        "\n",
        "print(\"Getting metrics...\")\n",
        "print(\"F1\\tAcc\\tPre\\tRec\")\n",
        "print(\n",
        "    f1_score(y_test, y_pred),\n",
        "    accuracy_score(y_test, y_pred),\n",
        "    precision_score(y_test, y_pred),\n",
        "    recall_score(y_test, y_pred),\n",
        "    sep =\"\\t\"\n",
        ")\n",
        "\n",
        "# all_f1.append(fold_f1)\n",
        "# all_accuracy.append(fold_accuracy)\n",
        "# all_precision.append(fold_precision)\n",
        "# all_recall.append(fold_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa06f4be",
      "metadata": {
        "id": "aa06f4be"
      },
      "outputs": [],
      "source": [
        "# final_f1 = f1_score(y_val, y_test_pred)\n",
        "# final_accuracy = accuracy_score(y_val, y_test_pred)\n",
        "# final_precision = precision_score(y_val, y_test_pred)\n",
        "# final_recall = recall_score(y_val, y_test_pred)\n",
        "\n",
        "# print(f\"{fold}\\tF1: {final_f1:.4f}\\tAcc{final_accuracy:.4f}\\tPrec{final_precision:.4f}\\tRec: {final_recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e08a9dc",
      "metadata": {
        "id": "5e08a9dc"
      },
      "outputs": [],
      "source": [
        "# print(\"i\\tF1\\tAcc\\tPre\\tRec\")\n",
        "# for i in range(len(all_f1)):\n",
        "#     print(i, round(all_f1[i], 4), round(all_accuracy[i], 4), round(all_precision[i], 4), round(all_recall[i],4), sep=\"\\t\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}