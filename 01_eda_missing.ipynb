{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full:\n",
    "plot_between('2013-01-01 00:00:00', '2014-09-30 23:59:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_between('2013-01-01 00:00:01','2013-03-31 23:59:59')\n",
    "\n",
    "# data_combined['2013-01-01 00:00:01':'2013-03-31 23:59:59']\n",
    "\n",
    "# plot_between('2013-01-01 00:00:00', '2014-08-31 23:59:59')\n",
    "# Start\n",
    "data_combined['2013-01-01 00:00:01':'2013-01-31 23:59:59']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum stats\n",
    "print(\"From 2013-01-02 18:59:38 through 2014-08-22 10:21:32:\\n\")\n",
    "print(data_combined['2013-01-02 18:59:38':'2014-08-22 10:21:32'].groupby('source', dropna=False)['raw'].agg(['count', 'mean','std', 'min', 'max']).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_between('2013-01-02 18:59:38', '2014-08-22 10:21:32')\n",
    "data_combined['2014-08-01 00:00:00':'2014-08-31 23:59:59']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d372567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined['2013-01-01 00:00:01':'2013-01-31 23:59:59']\n",
    "# data_combined['2013-01-01 00:00:01':'2013-01-31 23:59:59'].groupby('source', dropna=False)['raw'].agg(['count', 'mean','std', 'min', 'max']).dropna()\n",
    "# data_combined['2013-01-02 18:59:38':'2014-08-22 10:21:32'].groupby('source', dropna=False)['raw'].agg(['count', 'mean','std', 'min', 'max']).dropna()\n",
    "# print(data_combined['2013-01-01 00:00:01':'2014-09-30 23:59:59'].groupby('source', dropna=False)['raw'].agg(['count', 'mean','std', 'min', 'max']).dropna())\n",
    "plot_between('2013-01-02 18:59:38', '2014-08-22 10:21:32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0daceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking old gap\n",
    "data_all_combined[data_all_combined['source'] == \"ISCO\"][date_gap_start:date_gap_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506aafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_start = data_all_combined[data_all_combined['source']==\"ISCO\"][\"2013-01-01 00:00:00\":\"2013-03-15 00:00:00\"]\n",
    "data_start = data_all_combined[data_all_combined['source']!=\"CHART\"][\"2013-01-01 00:00:00\":\"2013-01-30 23:59:59\"]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.axhline(y=0, color ='grey', linestyle = ':')\n",
    "# Plot the rain as a bar chart with a multiplier for visibility\n",
    "# ax.vlines(data_start.index, ymin=0, ymax=data_start['ra']*3, color = 'blue', label = \"Rain (x3)\")\n",
    "ax.plot(data_start.index, data_start['level'], color = 'red', label = \"Adjusted\", linestyle='none', marker='.')\n",
    "ax.plot(data_start.index, data_start['raw'], color = 'green', label = \"Raw\", linestyle='none', marker='.')\n",
    "# ax.plot(data_start.index, data_start['level'], color = 'red', label = \"Adjusted\")\n",
    "# ax.plot(data_start.index, data_start['raw'], color = 'green', label = \"Raw\")\n",
    "# # Include calibration points unless otherwise specified or unless there are none in the subset\n",
    "# if include_calibration == True and not data_subset_cal.empty:\n",
    "#     ax.plot(data_subset_cal.index, data_subset_cal['weir_level'], linestyle='none', marker='x', color='red', label = \"Calibration\")\n",
    "\n",
    "# Plot labels\n",
    "ax.set_xlabel(\"Date (YYYY-MM-DD)\")\n",
    "ax.set_ylabel(\"Level (mm)\")\n",
    "# ax.set_title('Simple Time Series Plot')\n",
    "# ax.set_title(\"Runoff time series from \" + input_date_start + \" through \" + input_date_end)\n",
    "# ax.set_ylim(bottom=0) \n",
    "# ax.grid(True)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "# Reverse the order of the legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles[::-1], labels[::-1], loc='upper right')\n",
    "# plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "del fig, ax, data_start, handles, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb4efdc",
   "metadata": {},
   "source": [
    "### CHART\n",
    "\n",
    "Only non-CHART values will be used for making the model.\n",
    "Prior to removing them, other missing values must also be dealt with, as they may relate to gaps within CHART-reliant ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf65f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying \n",
    "# Backup\n",
    "data_combined_backup = data_combined.copy()\n",
    "# Create a column which will forward fill the source--i.e., fill NAs with the most recent value reported in 'source'\n",
    "data_combined_backup['source_ffill'] = data_combined_backup['source'].ffill()\n",
    "# Create a column which will back fill the source--i.e., fill NAs with the next value reported in 'source'\n",
    "data_combined_backup['source_bfill'] = data_combined_backup['source'].bfill()\n",
    "\n",
    "# Filtering to remove CHART values and gap fills that rely on CHART values\n",
    "data_combined_backup_1 = data_combined_backup[\n",
    "    # Remove CHART values\n",
    "    (data_combined_backup[\"source\"] != \"CHART\") &\n",
    "    # and\n",
    "    (\n",
    "        # selecting values with NA sources where the most recent & next sources are the same\n",
    "        (data_combined_backup[\"source_ffill\"] == data_combined_backup[\"source_bfill\"]) |\n",
    "        # or\n",
    "        # selecting if there is no next value to fill\n",
    "        # (i.e., the source remains the same into the present)\n",
    "        (data_combined_backup[\"source_bfill\"].isnull())\n",
    "    ) &\n",
    "    # and\n",
    "    (((data_combined_backup[\"source_ffill\"] != \"CHART\")) &\n",
    "    ((data_combined_backup[\"source_bfill\"] != \"CHART\")))\n",
    "    # # remove NA values where the most recent source was CHART\n",
    "    # ((data_combined_backup[\"source_ffill\"] != \"CHART\") & data_combined_backup['source'].isnull()) &\n",
    "    # # and\n",
    "    # # remove NA-source values where the next source is CHART\n",
    "    # ((data_combined_backup[\"source_bfill\"] != \"CHART\") & data_combined_backup['source'].isnull())\n",
    "    ]\n",
    "\n",
    "data_combined_backup_2 = data_combined_backup[\n",
    "    (data_combined_backup['source'] != \"CHART\") &\n",
    "    (data_combined_backup['source_ffill'] != \"CHART\")\n",
    "    &\n",
    "    (data_combined_backup['source_bfill'] != \"CHART\")\n",
    "]\n",
    "\n",
    "print(len(data_combined_backup_1), \"vs\", len(data_combined_backup_2))\n",
    "print(data_combined_backup_2[~data_combined_backup_2.index.isin(data_combined_backup_1.index)])\n",
    "\n",
    "\n",
    "# mismatch: 2018-08-31 10:00:00 \n",
    "\n",
    "data_combined_backup_2[\"2018-08-31 09:00:00\":\"2018-09-30 23:59:59\"]\n",
    "\n",
    "del data_combined_backup_1, data_combined_backup_2, data_combined_backup\n",
    "\n",
    "# data_combined_backup[data_combined_backup['source'].isnull()]\n",
    "# 3,555,834\n",
    "# 3,134,121 \n",
    "# 3,111,793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f7247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del data_combined_backup_1, data_combined_backup_2, data_combined_backup\n",
    "data_combined[(data_combined['chk_fail'].str.contains(\"Gap Fill\")) & (data_combined['source'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1689e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying \n",
    "# Backup\n",
    "# data_combined_mod = data_combined.copy()\n",
    "data_combined_mod = data_all_combined.copy()\n",
    "data_combined_mod = data_combined_mod[date_weir_start:date_weir_end]\n",
    "\n",
    "# Create a column which will forward fill the source--i.e., fill NAs with the most recent value reported in 'source'\n",
    "data_combined_mod['source_ffill'] = data_combined_mod['source'].ffill()\n",
    "# Create a column which will back fill the source--i.e., fill NAs with the next value reported in 'source'\n",
    "data_combined_mod['source_bfill'] = data_combined_mod['source'].bfill()\n",
    "\n",
    "# Filtering to remove CHART values and gap fills that rely on CHART values\n",
    "data_combined_mod = data_combined_mod[\n",
    "    # Remove CHART values\n",
    "    (data_combined_mod[\"source\"] != \"CHART\") &\n",
    "    # and\n",
    "    (\n",
    "        # selecting values with NA sources where the most recent & next sources are the same\n",
    "        (data_combined_mod[\"source_ffill\"] == data_combined_mod[\"source_bfill\"]) |\n",
    "        # or\n",
    "        # selecting if there is no next value to fill\n",
    "        # (i.e., the source remains the same into the present)\n",
    "        (data_combined_mod[\"source_bfill\"].isnull())\n",
    "    ) &\n",
    "    # and\n",
    "    # remove NA values where the most recent source was CHART\n",
    "    (data_combined_mod[\"source_ffill\"] != \"CHART\") &\n",
    "    # and\n",
    "    # remove NA-source values where the next source is CHART\n",
    "    (data_combined_mod[\"source_bfill\"] != \"CHART\")\n",
    "    ]\n",
    "\n",
    "# data_combined_mod\n",
    "\n",
    "# 3,555,834 with removing gap\n",
    "# 3,557,018 without removing gap\n",
    "\n",
    "\n",
    "data_combined_mod_2 = data_combined.copy()\n",
    "# Create a column which will forward fill the source--i.e., fill NAs with the most recent value reported in 'source'\n",
    "data_combined_mod_2['source_ffill'] = data_combined_mod_2['source'].ffill()\n",
    "# Create a column which will back fill the source--i.e., fill NAs with the next value reported in 'source'\n",
    "data_combined_mod_2['source_bfill'] = data_combined_mod_2['source'].bfill()\n",
    "\n",
    "# Filtering to remove CHART values and gap fills that rely on CHART values\n",
    "data_combined_mod_2 = data_combined_mod_2[\n",
    "    # Remove CHART values\n",
    "    (data_combined_mod_2[\"source\"] != \"CHART\") &\n",
    "    # and\n",
    "    (\n",
    "        # selecting values with NA sources where the most recent & next sources are the same\n",
    "        (data_combined_mod_2[\"source_ffill\"] == data_combined_mod_2[\"source_bfill\"]) |\n",
    "        # or\n",
    "        # selecting if there is no next value to fill\n",
    "        # (i.e., the source remains the same into the present)\n",
    "        (data_combined_mod_2[\"source_bfill\"].isnull())\n",
    "    ) &\n",
    "    # and\n",
    "    # remove NA values where the most recent source was CHART\n",
    "    (data_combined_mod_2[\"source_ffill\"] != \"CHART\") &\n",
    "    # and\n",
    "    # remove NA-source values where the next source is CHART\n",
    "    (data_combined_mod_2[\"source_bfill\"] != \"CHART\")\n",
    "    ]\n",
    "\n",
    "# data_combined_mod\n",
    "\n",
    "# data_combined_mod.index.symmetric_difference(data_combined_mod_2.index)\n",
    "# Merge DataFrames on common columns, indicating source\n",
    "# merged_df = data_combined_mod.merge(data_combined_mod_2, on=['ID', 'Name'], how='outer', indicator=True)\n",
    "\n",
    "# Filter for rows not present in both DataFrames\n",
    "# diff_rows = merged_df[merged_df['_merge'] != 'both']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdfb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined_mod.index.symmetric_difference(data_combined_mod_2.index)\n",
    "# 3,555,834 with removing gap\n",
    "# 3,557,018 without removing gap\n",
    "merged_df = pd.merge(data_combined_mod, data_combined_mod_2, left_index=True, right_index=True, how='left', indicator=True)\n",
    "# merged_df[merged_df[\"_merge\"] == \"right_only\"]\n",
    "# merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge', 'value_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(abs(3555834 - 3557018))\n",
    "# len(merged_df[merged_df[\"_merge\"] == \"left_only\"])\n",
    "flag_index = merged_df[merged_df[\"_merge\"] == \"left_only\"].index\n",
    "# data_all_combined[date_gap_start:date_gap_end]\n",
    "data_flagged = data_all_combined.copy()\n",
    "\n",
    "data_flagged[\"flag\"] = False\n",
    "\n",
    "data_flagged.loc[data_flagged.index.isin(flag_index), \"flag\"]  = True\n",
    "\n",
    "# data_flagged[date_gap_start:date_gap_end]\n",
    "# data_flagged[date_gap_end:]\n",
    "data_flagged[data_flagged[\"flag\"]==True]\n",
    "\n",
    "# merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge', 'value_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5847770",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flagged_diff = data_flagged[data_flagged[\"flag\"]==True]\n",
    "full_date_range = pd.date_range(start = data_flagged_diff.index[0], end = data_flagged_diff.index[-1], freq=\"5min\")\n",
    "data_flagged_diff = data_flagged_diff.reindex(full_date_range)\n",
    "# data_flagged_diff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "## Line for 0\n",
    "plt.axhline(y=0, color = \"grey\", linestyle = \":\")\n",
    "# Mean\n",
    "ax.plot(data_flagged_diff.index, data_flagged_diff['level'], color = 'green')\n",
    "# ax.scatter(data_flagged_diff.index, data_flagged_diff['level'], color = 'green')\n",
    "# ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green', label = \"Mean\")\n",
    "# Ribbon for standard deviation\n",
    "# ax.fill_between(data_mixed_filtered_sumstats.index, data_mixed_filtered_sumstats['mean']-data_mixed_filtered_sumstats['std'], data_mixed_filtered_sumstats['mean']+data_mixed_filtered_sumstats['std'], color = 'aquamarine', label = \"std\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Level (mm)\")\n",
    "ax.set_title(\"Average raw values every 1mo\")\n",
    "# ax.set_ylim(bottom = 0)\n",
    "# ax.set_xlim(left = dt.date(1989, 1, 1), right = dt.date(2026, 1, 1))\n",
    "# ax.xaxis.set_major_locator(mdates.YearLocator(month = 1)) # Show ticks at start of year\n",
    "plt.xticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis = 'x', which = 'major')\n",
    "# plt.legend(loc = 'upper right')\n",
    "# Truncate plot\n",
    "# ax.set_ylim(bottom = 0, top = 250)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del fig, ax, data_flagged_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986391b3",
   "metadata": {},
   "source": [
    "### Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5356ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined['source'].value_counts(dropna=False)\n",
    "# data_combined['chk_note'].value_counts(dropna=False)\n",
    "data_combined.groupby(['chk_note', 'source'],dropna=False).size()\n",
    "# data_combined[data_combined['source'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdd5129",
   "metadata": {},
   "source": [
    "Other gaps of missing values occur and should be addressed.\n",
    "These can be identified by the `chk_note` of 'missing' with a `raw` values of -999.0.\n",
    "\n",
    "A `chk_note` of 'missing' differs from instances of where a `chk_fail` is a 'Gap Fill'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf6657",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined.groupby(['chk_note', 'chk_fail'],dropna=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined[(data_combined['chk_note'] == 'missing') & (data_combined['raw'] != -999.0)]\n",
    "# data_combined[data_combined['source'].isnull()]\n",
    "# data_combined['1997-01-01 00:00:00':'1997-01-01 23:59:59']\n",
    "# data_combined[data_combined['source']=='CHART']\n",
    "data_combined[(data_combined['chk_note'] == 'missing') & (data_combined['source'] == 'CHART')]\n",
    "# data_combined[(data_combined['chk_note'] == 'missing') & (data_combined['level'] != 0)]\n",
    "# data_combined['1993-03-08 00:00:00':'1993-03-08 23:59:59']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a995ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined[data_combined['source'] == 'CHART']\n",
    "data_chart = data_combined[data_combined['source'] == 'CHART'].resample('D').size().rename(\"n\")\n",
    "data_chart = data_chart.replace(0, np.nan)\n",
    "# data_chart = data_chart[data_chart > 0]\n",
    "# data_chart[data_chart[\"n\"] > 0]\n",
    "# data_chart.columns\n",
    "\n",
    "# data_chart[data_chart['0'] != 0]\n",
    "# data_chart.rename(columns={0: \"blah\"})\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.axhline(y=0, color ='grey', linestyle = ':')\n",
    "# plt.scatter(data_chart.index, data_chart, marker=\"x\")\n",
    "plt.plot(data_chart.index, data_chart)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35c6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data_combined.index isin data_chart.dropna().index\n",
    "# # data_chart.dropna()\n",
    "# data_tally = data_combined[\"source\"]\n",
    "# data_tally = pd.DataFrame(data_tally)\n",
    "# # data_tally['B'] = (~(data_combined[\"source\"] == \"CHART\")).cumsum()\n",
    "# # data_tally[\"2000-01-01 00:00:00\"]\n",
    "# # data_tally\n",
    "# # data_tally['B'] = (~df['A']).cumsum()\n",
    "# # data_tally['A'].sum()\n",
    "# # data_tally['C'] = data_tally.duplicated(['source', 'B'], keep='first')\n",
    "# # data_tally['C'].sum()\n",
    "\n",
    "# data_tally['A'] = (data_tally[\"source\"]==\"CHART\")\n",
    "# # data_tally['B'] = (~data_tally['A']).cumsum()\n",
    "# # data_tally['C'] = data_tally.duplicated(['A', 'B'], keep='first')\n",
    "# # data_tally['C'].sum()\n",
    "# # data_tally\n",
    "\n",
    "\n",
    "# (data_tally['A']&data_tally['A'].shift(fill_value=False)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_chart_days[\"chk_fail\"].str.contains(\"Gap Fill\").dropna()\n",
    "# data_chart_days[(data_chart_days[\"chk_fail\"] == \"Gap Fill\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42662d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_chart.dropna().index\n",
    "# data_combined.index.date\n",
    "# data_chart.dropna().index.date\n",
    "# data_combined.index.date\n",
    "dates_to_filter = data_chart.dropna().index.date\n",
    "# dates_to_filter.date\n",
    "data_chart_days = data_combined[data_combined.index.floor('D').isin(dates_to_filter)]\n",
    "# data_chart_days\n",
    "# data_chart_days[\"source\"].groupby(data_chart_days[\"source\"].ne(data_chart_days[\"source\"].shift()).cumsum()).cumcount()\n",
    "# data_chart_days[\"tally\"] = data_chart_days[\"source\"].ne(data_chart_days[\"source\"].shift()).cumsum()\n",
    "# condition_gap = (data_chart_days[\"raw\"] == -999.0) & (data_chart_days[\"chk_fail\"] == \"Gap Fill\") & (data_chart_days[\"source\"].isnull())\n",
    "# data_chart_days[condition_gap]\n",
    "\n",
    "# condition_gap = (data_chart_days[\"raw\"] == -999.0) & (data_chart_days[\"chk_fail\"].str.contains(\"Gap Fill\")) & (data_chart_days[\"source\"].isnull())\n",
    "# # data_chart_days[\"source_mod\"] = data_chart_days[\"source_mod\"].astype(str)\n",
    "# # data_chart_days.loc[condition_gap, \"source_mod\"] = \"NA\"\n",
    "\n",
    "# data_chart_days[\"source_mod\"] = data_chart_days[\"source\"]\n",
    "# data_chart_days.loc[condition_gap, \"source_mod\"] = \"CHART\"\n",
    "# data_chart_days.loc[(data_chart_days[\"chk_note\"] == \"missing\"), \"source_mod\"] = \"CHART\"\n",
    "\n",
    "##\n",
    "data_chart_days[\"source_mod\"] = data_chart_days[\"source\"]\n",
    "data_chart_days[\"source_mod\"] = data_chart_days[\"source_mod\"].ffill()\n",
    "##\n",
    "\n",
    "# data_chart_days[\"source_mod\"] = data_chart_days[]\n",
    "\n",
    "# data_chart_days = data_chart_days.drop(['chk_note', 'chk_fail', 'comment'],axis=1)\n",
    "\n",
    "# data_chart_days.loc[(data_chart_days[\"source_mod\"].isnull())]\n",
    "data_chart_days[\"group_tally\"] = data_chart_days[\"source_mod\"].ne(data_chart_days[\"source_mod\"].shift()).cumsum(skipna=False)\n",
    "data_chart_days[\"tally\"] = data_chart_days[\"source_mod\"].groupby(data_chart_days[\"source_mod\"].ne(data_chart_days[\"source_mod\"].shift()).cumsum(skipna=False)).cumcount()\n",
    "\n",
    "data_chart_days[\"tally\"] = data_chart_days[\"tally\"]+1\n",
    "# data_chart_days\n",
    "\n",
    "# data_chart_days.groupby('group_tally')['tally'].max()\n",
    "data_grouped_tally = data_chart_days.groupby('group_tally')['tally'].max()\n",
    "# data_grouped_tally[data_grouped_tally == 1]\n",
    "# data_grouped_tally == 1\n",
    "\n",
    "data_chart_days[data_chart_days[\"group_tally\"].isin(data_grouped_tally[data_grouped_tally == 1].index)]\n",
    "# 1996-11-12 01:25:00, 2007-10-01 09:46:00\n",
    "# data_chart_days[\"2007-10-01 00:00:00\":\"2007-10-01 23:59:59\"]\n",
    "# data_chart_days[\"group\"]\n",
    "# data_chart_days.loc[data_grouped_tally[\"tally\"], \"tally\"]\n",
    "\n",
    "# data_chart_days\n",
    "# data_grouped_tally[data_grouped_tally == 1].index\n",
    "# data_chart_days[\"tally\"] == 1\n",
    "\n",
    "# data_chart_days = data_chart_days.drop(['chk_note', 'chk_fail', 'comment'],axis=1)\n",
    "# data_chart_days[\"group_tally\"] = data_chart_days[\"source\"].ne(data_chart_days[\"source\"].shift()).cumsum()\n",
    "# data_chart_days[\"tally\"] = data_chart_days[\"source\"].groupby(data_chart_days[\"source\"].ne(data_chart_days[\"source\"].shift()).cumsum()).cumcount()\n",
    "# data_chart_days\n",
    "\n",
    "# plt.figure(figsize=(20, 6))\n",
    "# plt.axhline(y=0, color ='grey', linestyle = ':')\n",
    "# # plt.scatter(data_chart.index, data_chart, marker=\"x\")\n",
    "# for source in data_chart_days[\"source\"].unique():\n",
    "#     # plt.scatter(data_chart_days.index, (data_chart_days[\"source\"]==source))\n",
    "#     plt.scatter(range(len(data_chart_days)), (data_chart_days[\"source\"]==source), label=source, s=0.25)\n",
    "#     # plt.scatter(range(len(data_chart_days)), data_chart_days[data_chart_days[\"source\"]==source][\"level\"])\n",
    "# # plt.scatter(range(len(data_chart_days)), data_chart_days['raw'], hue=\"source\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# # data_combined[data_combined.index.isin(data_chart.dropna().index)]\n",
    "# # data_combined.loc[data_chart.dropna().index.date]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecbd096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined[(data_combined['chk_note']==\"missing\") & (data_combined['level']!= 0)]\n",
    "# data_combined[(data_combined['chk_note']!=\"missing\") & (data_combined['raw']== -999.0)]\n",
    "# data_combined[(data_combined['chk_note']==\"missing\") & (data_combined['raw']== -999.0)]\n",
    "# data_combined[(data_combined['chk_fail'].str.contains(\"Gap Fill\") == False) & (data_combined['chk_note']!=\"missing\") & (data_combined['raw']== -999.0)]\n",
    "# data_combined[(data_combined['chk_fail'].str.contains(\"Gap Fill\") == False) & (data_combined['raw']== -999.0)]\n",
    "# data_combined[(data_combined['raw']== -999.0) & (data_combined['level']!=0)]\n",
    "# data_combined[(data_combined['chk_note']==\"missing\") & (data_combined['raw']!= -999.0)]\n",
    "# print(len(data_combined[(data_combined['chk_note']!=\"missing\") & (data_combined['source']!= \"CHART\")]))\n",
    "# print(len(data_combined[(data_combined['chk_note']!= \"missing\")]))\n",
    "# print(len(data_combined[(data_combined['source']== \"CHART\")]))\n",
    "\n",
    "# print(len(data_combined[(data_combined['chk_note']!= \"missing\")]) - len(data_combined[(data_combined['source']== \"CHART\")]))\n",
    "\n",
    "# data_combined[(data_combined['chk_note']!=\"missing\") & (data_combined['source']== \"CHART\")]\n",
    "# dates_gaps = set(data_combined[(data_combined['chk_fail'].str.contains(\"Gap Fill\", na=False))].index.date)\n",
    "\n",
    "# data_combined[data_combined.index.floor('D').isin(dates_gaps)]\n",
    "\n",
    "data_mixed = data_combined.copy()\n",
    "data_mixed[\"source_ffill\"] = data_mixed[\"source\"].ffill()\n",
    "data_mixed[\"source_bfill\"] = data_mixed[\"source\"].bfill()\n",
    "# data_mixed[(data_mixed['chk_fail'].str.contains(\"Gap Fill\")) | (data_mixed['chk_note']==\"missing\") | (data_mixed['raw']== -999.0)]\n",
    "\n",
    "# data_mixed[(data_mixed['chk_fail'].str.contains(\"Gap Fill\")) & (data_mixed['source'].isnull()) & ((data_mixed['source_ffill'] != \"CHART\") | (data_mixed['source_bfill'] != \"CHART\"))]\n",
    "# 07-09\n",
    "# data_mixed[\"1997-07-17 00:00:00\":\"1997-07-21 23:59:59\"]\n",
    "# data_mixed[\"1997-03-19 00:00:00\":\"1997-03-19 23:59:59\"]\n",
    "# print(len(data_mixed[(data_mixed['source'] == \"CHART\")]),\n",
    "#     len(data_mixed[(data_mixed['source_bfill'] == \"CHART\") & (data_mixed['chk_fail'].str.contains(\"Gap Fill\", na=False))])\n",
    "# )\n",
    "\n",
    "data_mixed[(data_mixed[\"source_bfill\"] != data_mixed[\"source_ffill\"]) & ((data_mixed[\"source_bfill\"] != \"CHART\") | (data_mixed[\"source_ffill\"] != \"CHART\"))]\n",
    "# data_mixed[\"2002-12-27 07:00:00\":\"2002-12-27 10:00:00\"]\n",
    "\n",
    "# data_mixed[data_mixed['chk_']]\n",
    "# data_combined[(data_combined['chk_fail'].str.contains(\"Gap Fill\", na=False))]\n",
    "# len(data_combined[(data_combined['chk_note']!=\"missing\")]) + len(data_combined[(data_combined['source']!= \"CHART\")])\n",
    "\n",
    "# set(data_combined[data_combined['raw'] == -999.0].index.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_mixed_filtered = data_mixed[\n",
    "    (data_mixed[\"source\"] != \"CHART\") &\n",
    "    ((data_mixed[\"source_ffill\"] == data_mixed[\"source_bfill\"]) | data_mixed[\"source_bfill\"].isnull()) &\n",
    "    (data_mixed[\"source_ffill\"] != \"CHART\") &\n",
    "    (data_mixed[\"source_bfill\"] != \"CHART\")\n",
    "    ]#[\"2002-12-26 00:00:00\":\"2002-12-26 23:59:59\"]\n",
    "\n",
    "# data_mixed_filtered[~data_mixed_filtered[\"chk_fail\"].isnull()][\"chk_fail\"].unique()\n",
    "# data_mixed_filtered[data_mixed_filtered[\"chk_fail\"].str.contains(\"Gap Fill\", na=False)][\"chk_note\"].unique()\n",
    "# data_mixed_filtered[data_mixed_filtered[\"raw\"] == -999.0]\n",
    "\n",
    "# data_mixed_filtered[data_mixed_filtered[\"chk_note\"] == \"missing\"]\n",
    "# data_mixed_filtered[(data_mixed_filtered[\"raw\"] == -999.0)][\"chk_fail\"].unique()\n",
    "# data_mixed_filtered[(data_mixed_filtered[\"raw\"] == -999.0) & (data_mixed_filtered[\"level\"] != 0)]#[\"chk_fail\"].unique()\n",
    "data_mixed_filtered[(data_mixed_filtered[\"raw\"] < 0) & (data_mixed_filtered[\"raw\"] != -999.0) & (data_mixed_filtered[\"level\"] > 0)]\n",
    "# data_mixed_filtered[(data_mixed_filtered[\"raw\"] == -999.0) & (data_mixed_filtered[\"chk_fail\"].isnull())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined[data_combined[\"chk_fail\"].str.contains(\",\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11908e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mixed_filtered_sumstats = data_mixed_filtered['raw'].dropna().resample('1ME').agg(['count', 'mean','std', 'min', 'max'])\n",
    "\n",
    "# data_mixed[\n",
    "#     # (data_mixed[\"source\"] == \"CHART\") |\n",
    "#     ((data_mixed[\"source_ffill\"] != data_mixed[\"source_bfill\"]))\n",
    "#     # data_mixed[\"source\"].isnull()\n",
    "#     ]\n",
    "\n",
    "# data_mixed[((data_mixed[\"source_ffill\"] != data_mixed[\"source_bfill\"]))]\n",
    "# data_mixed[\"2002-12-26 00:00:00\":\"2002-12-26 23:59:59\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 3))\n",
    "## Line for 0\n",
    "plt.axhline(y=0, color = \"grey\", linestyle = \":\")\n",
    "# Mean\n",
    "ax.plot(data_mixed_filtered_sumstats.index, data_mixed_filtered_sumstats['mean'], color = 'green')\n",
    "# ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green', label = \"Mean\")\n",
    "# Ribbon for standard deviation\n",
    "# ax.fill_between(data_mixed_filtered_sumstats.index, data_mixed_filtered_sumstats['mean']-data_mixed_filtered_sumstats['std'], data_mixed_filtered_sumstats['mean']+data_mixed_filtered_sumstats['std'], color = 'aquamarine', label = \"std\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Level (mm)\")\n",
    "ax.set_title(\"Average raw values every 1mo\")\n",
    "# ax.set_ylim(bottom = 0)\n",
    "ax.set_xlim(left = dt.date(1989, 1, 1), right = dt.date(2026, 1, 1))\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month = 1)) # Show ticks at start of year\n",
    "plt.xticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis = 'x', which = 'major')\n",
    "# plt.legend(loc = 'upper right')\n",
    "# Truncate plot\n",
    "# ax.set_ylim(bottom = 0, top = 250)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a716b1",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nochart = data_combined.copy()\n",
    "data_nochart['source_ffill'] = data_nochart['source'].ffill()\n",
    "data_nochart['source_bfill'] = data_nochart['source'].bfill()\n",
    "data_nochart = data_nochart[\n",
    "    (data_nochart['source'] != \"CHART\") &\n",
    "    (data_nochart['source_ffill'] != \"CHART\") &\n",
    "    (data_nochart['source_bfill'] != \"CHART\")\n",
    "]\n",
    "\n",
    "# data_mixed_filtered_sumstats = data_mixed_filtered['raw'].dropna().resample('1ME').agg(['count', 'mean','std', 'min', 'max'])\n",
    "data_mixed_filtered_sumstats = data_nochart['raw'].dropna().resample('1W').agg(['count', 'mean','std', 'min', 'max'])\n",
    "# data_mixed_filtered_sumstats = data_nochart['raw'].dropna().resample('1ME').agg(['count', 'mean','std', 'min', 'max'])\n",
    "\n",
    "# data_mixed[\n",
    "#     # (data_mixed[\"source\"] == \"CHART\") |\n",
    "#     ((data_mixed[\"source_ffill\"] != data_mixed[\"source_bfill\"]))\n",
    "#     # data_mixed[\"source\"].isnull()\n",
    "#     ]\n",
    "\n",
    "# data_mixed[((data_mixed[\"source_ffill\"] != data_mixed[\"source_bfill\"]))]\n",
    "# data_mixed[\"2002-12-26 00:00:00\":\"2002-12-26 23:59:59\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 3))\n",
    "## Line for 0\n",
    "plt.axhline(y=0, color = \"grey\", linestyle = \":\")\n",
    "# Mean\n",
    "ax.plot(data_mixed_filtered_sumstats.index, data_mixed_filtered_sumstats['mean'], color = 'green')\n",
    "# ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green', label = \"Mean\")\n",
    "# Ribbon for standard deviation\n",
    "# ax.fill_between(data_mixed_filtered_sumstats.index, data_mixed_filtered_sumstats['mean']-data_mixed_filtered_sumstats['std'], data_mixed_filtered_sumstats['mean']+data_mixed_filtered_sumstats['std'], color = 'aquamarine', label = \"std\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Level (mm)\")\n",
    "ax.set_title(\"Average raw values every 1mo\")\n",
    "# ax.set_ylim(bottom = 0)\n",
    "ax.set_xlim(left = dt.date(1989, 1, 1), right = dt.date(2026, 1, 1))\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month = 1)) # Show ticks at start of year\n",
    "plt.xticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis = 'x', which = 'major')\n",
    "# plt.legend(loc = 'upper right')\n",
    "# Truncate plot\n",
    "# ax.set_ylim(bottom = 0, top = 250)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aad5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_nochart[data_nochart['raw'] < 0]\n",
    "data_nochart[data_nochart['raw'] < 0]['raw'].dropna().resample('1ME').agg(['count', 'mean','std', 'min', 'max']).dropna()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
