{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36f3e2c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa7a4c",
   "metadata": {},
   "source": [
    "## Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e391302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5133f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.10.6\n",
       "numpy               2.3.3\n",
       "pandas              2.3.2\n",
       "session_info        v1.0.1\n",
       "-----\n",
       "IPython             9.5.0\n",
       "jupyter_client      8.6.3\n",
       "jupyter_core        5.8.1\n",
       "-----\n",
       "Python 3.13.7 (v3.13.7:bcee1c32211, Aug 14 2025, 19:10:51) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
       "macOS-15.6.1-x86_64-i386-64bit-Mach-O\n",
       "-----\n",
       "Session information updated at 2025-10-01 15:46\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## (Optional chunk)\n",
    "# Current session information\n",
    "import session_info\n",
    "session_info.show(dependencies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de25f7",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Files of interest:\n",
    "- `weir_calibration.csv` includes calibration points for the weir\n",
    "- `bci_lutzweir_combined.csv` includes raw runoff measurement, corrected runoff measurement, data source (*Chart measurements can be removed)\n",
    "- `bci_cl_ra_elect2.CSV` has corrected rainfall (`ra`) in mm with measurements of `0` as `NA`s (`bci_cl_ra_elect.csv` has `0`s)\n",
    "- `bci_lutz_deep_gsm_man.csv`, `bci_lutz_shallow_gsm_man.csv` have soil moisture measurements (water by wet weight and water by dry weight; one can be chosen for analysis as they are linearly related)\n",
    "<!-- `bci_cl_ra_elect.csv` has corrected rainfall (`ra`) in mm, contains `0`s (large file) -->\n",
    "\n",
    "All values level values are in mm, and datetime is in UTC-5 (Panama time zone).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671e55e",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f5d3909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6465 entries, 1994-01-03 08:46:00 to 2025-09-02 08:50:00\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   weir_level  6465 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 101.0 KB\n"
     ]
    }
   ],
   "source": [
    "## Calibrations dataset\n",
    "data_calibrations = pd.read_csv(\n",
    "    \"data/weir_calibration.csv\",\n",
    "    usecols = ['datetime', 'weir_level'], # weir_hour is a repeat of the time in datetime and can be skipped\n",
    "    parse_dates=['datetime'],\n",
    "    date_format='%d/%m/%Y %H:%M:%S',\n",
    "    index_col='datetime'\n",
    ")\n",
    "\n",
    "data_calibrations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19382df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3951119 entries, 1972-01-01 01:00:00 to 1977-03-06 23:45:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype   \n",
      "---  ------    -----   \n",
      " 0   level     float64 \n",
      " 1   raw       float64 \n",
      " 2   chk_note  category\n",
      " 3   chk_fail  object  \n",
      " 4   comment   object  \n",
      " 5   source    category\n",
      "dtypes: category(2), float64(2), object(2)\n",
      "memory usage: 158.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Combined data\n",
    "\n",
    "data_all_combined = pd.read_csv(\n",
    "    \"data/bci_lutzweir_combined.csv\",\n",
    "    usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "    parse_dates=['datetime'],\n",
    "    dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
    "    date_format='%d/%m/%Y %H:%M:%S',\n",
    "    index_col='datetime'\n",
    ")\n",
    "\n",
    "# # This variation checks first if the dataset is already loaded into the workspace\n",
    "# try:\n",
    "#     if data_combined.empty == False:\n",
    "#         print(\"Data loaded, random sample shown below\")\n",
    "#         print(data_combined.sample(n=5))\n",
    "# except NameError:\n",
    "#     print(\"Data has not yet been read in, loading now...\")\n",
    "#     data_combined = pd.read_csv(\n",
    "#         \"data/bci_lutzweir_combined.csv\",\n",
    "#         usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "#         parse_dates=['datetime'],\n",
    "#         dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
    "#         date_format='%d/%m/%Y %H:%M:%S'\n",
    "#     )\n",
    "\n",
    "data_all_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49b35292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 179640 entries, 1929-01-02 08:00:00 to 2025-08-04 11:55:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype   \n",
      "---  ------    --------------   -----   \n",
      " 0   ra        179640 non-null  float64 \n",
      " 1   raw       179640 non-null  float64 \n",
      " 2   chk_note  179640 non-null  category\n",
      " 3   chk_fail  29 non-null      object  \n",
      "dtypes: category(1), float64(2), object(1)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Rainfall dataset\n",
    "\n",
    "# This data set skips the 0 readings (therefore much smaller):\n",
    "data_all_rainfall = pd.read_csv(\n",
    "    \"data/bci_elect_cl_ra/bci_cl_ra_elect2.CSV\",\n",
    "    parse_dates=['datetime'],\n",
    "    dtype = {'chk_note':'category', 'chk_fail':'str'},\n",
    "    date_format='%d/%m/%Y %H:%M:%S',\n",
    "    index_col='datetime'\n",
    ")\n",
    "\n",
    "# This data set includes the 0 readings:\n",
    "# data_rainfall_zeroes = pd.read_csv(\n",
    "#         \"data/bci_elect_cl_ra/bci_cl_ra_elect.csv\",\n",
    "#         usecols = ['datetime', 'ra', 'raw', 'chk_note', 'chk_fail'],\n",
    "#         # \"data/bci_elect_cl_ra/bci_cl_ra_elect2.CSV\",\n",
    "#         # usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "#         parse_dates=['datetime'],\n",
    "#         dtype = {'chk_note':'category', 'chk_fail':'str'},\n",
    "#         # dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
    "#         date_format='%d/%m/%Y %H:%M:%S'\n",
    "#     )\n",
    "\n",
    "data_all_rainfall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4db0e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 18556 entries, 1972-03-03 to 2025-06-26\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   depth       18556 non-null  category\n",
      " 1   sample      18556 non-null  category\n",
      " 2   h2o_by_wet  18556 non-null  float64 \n",
      " 3   chk_note    18556 non-null  category\n",
      " 4   chk_fail    178 non-null    object  \n",
      "dtypes: category(3), float64(1), object(1)\n",
      "memory usage: 490.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15637 entries, 1972-03-03 to 2025-06-26\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   depth       15637 non-null  category\n",
      " 1   sample      15637 non-null  category\n",
      " 2   h2o_by_wet  15637 non-null  float64 \n",
      " 3   chk_note    15637 non-null  category\n",
      " 4   chk_fail    20 non-null     object  \n",
      "dtypes: category(3), float64(1), object(1)\n",
      "memory usage: 413.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Soil datasets\n",
    "\n",
    "# Shallow\n",
    "data_all_soil_shallow = pd.read_csv(\n",
    "    \"data/bci_manual_soilh/bci_lutz_shallow_gsm_man.csv\",\n",
    "    parse_dates=['date'],\n",
    "    usecols = ['date', 'depth', 'sample', 'h2o_by_wet', 'chk_note', 'chk_fail'],\n",
    "    dtype = {'depth':'category', 'sample':'category', 'chk_note':'category', 'chk_fail':'str'},\n",
    "    date_format='%d/%m/%Y',\n",
    "    index_col='date'\n",
    ")\n",
    "\n",
    "# Deep\n",
    "data_all_soil_deep = pd.read_csv(\n",
    "    \"data/bci_manual_soilh/bci_lutz_deep_gsm_man.csv\",\n",
    "    parse_dates=['date'],\n",
    "    usecols = ['date', 'depth', 'sample', 'h2o_by_wet', 'chk_note', 'chk_fail'],\n",
    "    dtype = {'depth':'category', 'sample':'category', 'chk_note':'category', 'chk_fail':'str'},\n",
    "    date_format='%d/%m/%Y',\n",
    "    index_col='date'\n",
    ")\n",
    "\n",
    "data_all_soil_shallow.info()\n",
    "data_all_soil_deep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d1280",
   "metadata": {},
   "source": [
    "*A note about the soil datasets:\n",
    "\n",
    "Both `h2o_by_wet` and `h2o_by_dry` are available in the datasets.\n",
    "Because they are linearly related to each other, only one of them is necessary for modelling.\n",
    "Arbitrarily, `h2o_by_wet` has been chosen for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059eaebd",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb06ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest \t     Latest \t\t Source\n",
      "1972-01-01 01:00:00  2015-03-18 14:15:00 CHART\n",
      "1972-09-16 00:15:00  2025-08-01 13:00:00 nan\n",
      "1989-07-19 11:55:00  1996-10-01 23:55:00 CHART+AF\n",
      "1996-10-02 00:00:00  2013-01-13 05:50:00 ISCO\n",
      "2012-04-23 08:30:00  2012-04-24 08:35:00 ESTIMATED\n",
      "2014-08-22 10:30:00  2021-05-19 09:40:00 RADAR\n",
      "2018-08-31 10:05:00  2018-09-05 12:55:00 TROLL\n"
     ]
    }
   ],
   "source": [
    "# Get earliest and latest dates of sources\n",
    "\n",
    "cat_source = data_all_combined.sort_index()['source'].unique().tolist()\n",
    "# Header for printed table\n",
    "print(\"Earliest\", \"\\t    \", \"Latest\", \"\\t\\t\", \"Source\")\n",
    "# Iterate across each source type\n",
    "for cat in cat_source:\n",
    "    # If the source is NaN\n",
    "    if pd.isna(cat) == True:\n",
    "        temp_subset = data_all_combined[data_all_combined['source'].isnull()]\n",
    "    else:\n",
    "        temp_subset = data_all_combined[data_all_combined['source'] == cat]\n",
    "    # Sort index\n",
    "    temp_subset = temp_subset.sort_index()\n",
    "    # Print\n",
    "    print(temp_subset.index[0], \"\", temp_subset.index[-1], cat)\n",
    "\n",
    "# Save space, remove no longer needed items\n",
    "del cat_source, cat, temp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a09732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data sets for relevant dates\n",
    "\n",
    "# Exclude old chart data\n",
    "# data_combined = data_all_combined[~data_all_combined['source'].str.contains(\"CHART\", na=False)]\n",
    "# data_combined = data_all_combined[~data_all_combined['source']==\"CHART\"]\n",
    "\n",
    "# Filter the dataset to only be non-CHART values\n",
    "data_combined = data_all_combined[data_all_combined['source'] != 'CHART']\n",
    "\n",
    "# Remove missing values\n",
    "# data_combined = data_combined[data_combined['chk_note'] != 'missing']\n",
    "## Note- not all -999 values are tagged as missing...\n",
    "\n",
    "# Arrange\n",
    "data_combined = data_combined.sort_index()\n",
    "# Remove a few extra points\n",
    "data_combined = data_combined['1978-01-01 00:00:01':]\n",
    "\n",
    "# Get earliest and latest dates\n",
    "date_weir_start = data_combined.index[0]\n",
    "date_weir_end = data_combined.index[-1]\n",
    "\n",
    "# Create function to filter dates\n",
    "def filter_dates(input_dataset, input_date_start = date_weir_start, input_date_end = date_weir_end):\n",
    "    # Sort the dataframe\n",
    "    data_subset = input_dataset.sort_index()\n",
    "    # Filter between dates\n",
    "    data_subset = data_subset.loc[input_date_start:input_date_end]\n",
    "    return data_subset\n",
    "\n",
    "# Apply filter\n",
    "data_rainfall = filter_dates(data_all_rainfall)\n",
    "data_soil_deep = filter_dates(data_all_soil_deep)\n",
    "data_soil_shallow = filter_dates(data_all_soil_shallow)\n",
    "# data_nochart_soil_shallow[~data_nochart_soil_shallow['sample'].isin([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1473fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "level",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "raw",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chk_note",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "chk_fail",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "comment",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "4fbc4b8d-03d0-4a87-a6de-c2cecba73b7c",
       "rows": [
        [
         "2015-04-09 09:35:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 09:40:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 09:45:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 09:50:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 09:55:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 10:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 10:05:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 10:10:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 10:15:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill, Gap Fill",
         null,
         null
        ],
        [
         "2015-04-09 10:20:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2015-08-03 12:50:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2015-08-03 12:55:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2015-08-03 13:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2015-08-03 13:05:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2015-08-03 13:10:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2016-02-29 15:20:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2019-03-08 13:20:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2019-03-08 13:25:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2019-03-08 13:30:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2019-03-08 13:35:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2019-03-08 13:40:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2019-03-08 13:45:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2019-03-08 13:50:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-05 11:30:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-05 11:35:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-05 11:40:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-05 11:45:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-05 12:15:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-05 12:20:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-12 11:45:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-12 11:50:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-12 11:55:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-12 12:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-12 12:05:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-03-19 12:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-04-09 12:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-04-16 12:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-04-26 12:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ],
        [
         "2024-05-09 12:00:00",
         "0.0",
         "-999.0",
         "adjusted",
         "Gap Fill",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 39
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>raw</th>\n",
       "      <th>chk_note</th>\n",
       "      <th>chk_fail</th>\n",
       "      <th>comment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-09 09:35:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 09:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 09:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 09:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 09:55:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 10:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 10:05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 10:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 10:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill, Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09 10:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-03 12:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-03 12:55:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-03 13:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-03 13:05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-03 13:10:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-29 15:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08 13:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08 13:25:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08 13:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08 13:35:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08 13:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08 13:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08 13:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-05 11:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-05 11:35:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-05 11:40:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-05 11:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-05 12:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-05 12:20:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 11:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 11:50:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 11:55:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12 12:05:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-19 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-09 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-16 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-26 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>adjusted</td>\n",
       "      <td>Gap Fill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     level    raw  chk_note            chk_fail comment source\n",
       "datetime                                                                      \n",
       "2015-04-09 09:35:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 09:40:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 09:45:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 09:50:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 09:55:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 10:00:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 10:05:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 10:10:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 10:15:00    0.0 -999.0  adjusted  Gap Fill, Gap Fill     NaN    NaN\n",
       "2015-04-09 10:20:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2015-08-03 12:50:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2015-08-03 12:55:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2015-08-03 13:00:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2015-08-03 13:05:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2015-08-03 13:10:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2016-02-29 15:20:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2019-03-08 13:20:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2019-03-08 13:25:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2019-03-08 13:30:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2019-03-08 13:35:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2019-03-08 13:40:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2019-03-08 13:45:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2019-03-08 13:50:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-05 11:30:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-05 11:35:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-05 11:40:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-05 11:45:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-05 12:15:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-05 12:20:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-12 11:45:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-12 11:50:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-12 11:55:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-12 12:00:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-12 12:05:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-03-19 12:00:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-04-09 12:00:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-04-16 12:00:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-04-26 12:00:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN\n",
       "2024-05-09 12:00:00    0.0 -999.0  adjusted            Gap Fill     NaN    NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_combined[data_combined['chk_note'] == 'missing']\n",
    "# data_combined[((data_combined['level'] == 0.0) & (data_combined['raw'] <= -990))]\n",
    "data_combined[((data_combined['level'] == 0.0) & (data_combined['raw'] <= -990) & (data_combined['chk_note'] != 'missing'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea89ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old stuff\n",
    "del data_all_combined, data_all_rainfall, data_all_soil_shallow, data_all_soil_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shallow_all = pd.read_csv(\n",
    "    \"data/bci_manual_soilh/bci_lutz_shallow_gsm_man.csv\",\n",
    "    parse_dates=['date'],\n",
    "    # nrows=100,\n",
    "    usecols = ['date', 'depth', 'sample', 'h2o_by_wet', 'h2o_by_dry', 'chk_note', 'chk_fail'],\n",
    "    dtype = {'depth':'category', 'sample':'category', 'chk_note':'category', 'chk_fail':'str'},\n",
    "    date_format='%d/%m/%Y',\n",
    "    index_col='date'\n",
    ")\n",
    "\n",
    "# shallow_all = shallow_all.sort_index().loc[date_weir_start:date_weir_end]\n",
    "shallow_all = filter_dates(shallow_all)\n",
    "# shallow_all = shallow_all.reset_index()\n",
    "\n",
    "# # Deep\n",
    "deep_all = pd.read_csv(\n",
    "    \"data/bci_manual_soilh/bci_lutz_deep_gsm_man.csv\",\n",
    "    parse_dates=['date'],\n",
    "    usecols = ['date', 'depth', 'sample', 'h2o_by_wet', 'h2o_by_dry', 'chk_note', 'chk_fail'],\n",
    "    dtype = {'depth':'category', 'sample':'category', 'chk_note':'category', 'chk_fail':'str'},\n",
    "    date_format='%d/%m/%Y',\n",
    "    index_col='date'\n",
    ")\n",
    "\n",
    "deep_all = filter_dates(deep_all)\n",
    "deep_all = deep_all[deep_all[\"depth\"] != \"30-40\"]#.reset_index()\n",
    "\n",
    "# Filter set to only be of dates where deep set has shallow values\n",
    "shallow_all = shallow_all[shallow_all.index.isin(deep_all.index)]\n",
    "shallow_all.reset_index()\n",
    "\n",
    "match_all = pd.merge(deep_all.reset_index(), shallow_all.reset_index(), on=[\"date\", \"sample\"], suffixes=(\"_deep\", \"_shallow\"), how=\"inner\")\n",
    "match_all[\"match_wet\"] = (match_all[\"h2o_by_wet_deep\"] == match_all[\"h2o_by_wet_shallow\"])\n",
    "match_all[\"match_dry\"] = (match_all[\"h2o_by_dry_deep\"] == match_all[\"h2o_by_dry_shallow\"])\n",
    "match_all[\"sample\"] = match_all[\"sample\"].astype('int')\n",
    "match_all = match_all.sort_values(by=['date', 'sample'])\n",
    "match_all = match_all.drop(['chk_fail_shallow', 'chk_fail_deep'], axis=1)\n",
    "# match_all[match_all[\"match_wet\"] & match_all[\"match_dry\"]]\n",
    "match_all = match_all[((match_all[\"match_wet\"]==False) | (match_all[\"match_wet\"]==False))]\n",
    "match_all = match_all[['date', 'depth_shallow', 'depth_deep', 'sample', 'h2o_by_wet_shallow', 'h2o_by_wet_deep', 'h2o_by_dry_shallow', 'h2o_by_dry_deep', 'chk_note_shallow', 'chk_note_deep']]\n",
    "# match_all = match_all.drop([\"depth_deep\", \"depth_shallow\"],axis=1)\n",
    "# match_all = match_all[['date', 'sample', 'h2o_by_wet_shallow', 'h2o_by_wet_deep', 'h2o_by_dry_shallow', 'h2o_by_dry_deep', 'chk_note_shallow', 'chk_note_deep']]\n",
    "\n",
    "# match_all = match_all[['date', 'sample', 'h2o_by_wet_shallow', 'h2o_by_wet_deep', 'match_wet', 'h2o_by_dry_shallow', 'h2o_by_dry_deep', 'match_dry', 'chk_note_shallow', 'chk_note_deep']]\n",
    "# # data_deep_match = data_soil_deep[data_soil_deep[\"depth\"] == \"0-10\"].sort_index().drop('depth', axis=1)\n",
    "# # data_deep_match = data_deep_match.reset_index()\n",
    "# # dates_deep = data_deep_match.index\n",
    "# # data_shallow_match = data_soil_shallow[data_soil_shallow.sort_index().index.isin(data_deep_match.index)].drop('depth', axis=1)\n",
    "# data_shallow_match = data_shallow_match.reset_index()\n",
    "\n",
    "# # data_deep_match\n",
    "# # pd.merge(data_deep_match, data_shallow_match, on=[\"date\", \"sample\"], suffixes=(\"_deep\", \"_shallow\"), how=\"inner\")\n",
    "# match_result = pd.merge(data_deep_match, data_soil_shallow.reset_index().drop('depth', axis=1), on=[\"date\", \"sample\"], suffixes=(\"_deep\", \"_shallow\"), how=\"inner\")\n",
    "# match_result[\"match\"] = (match_result[\"h2o_by_wet_deep\"] == match_result[\"h2o_by_wet_shallow\"])\n",
    "# match_result[\"sample\"] = match_result[\"sample\"].astype('int')\n",
    "# match_result = match_result.sort_values(by=['date', 'sample'])\n",
    "# match_result = match_result.drop(['chk_fail_shallow', 'chk_fail_deep'], axis=1)\n",
    "# match_result[match_result[\"match\"]==False]\n",
    "# # match_result[[\"date\", \"match\"]]\n",
    "match_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1044b",
   "metadata": {},
   "source": [
    "## General Variable Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore weir combined data, comments, etc.\n",
    "\n",
    "# print(\n",
    "#     data_nochart_combined.dtypes,\n",
    "#     # \"\\n\\n\", \"Source:\", data_nochart_combined['source'].cat.categories.tolist(),\n",
    "#     # \"\\n\\n\", \"Notes:\", data_nochart_combined['chk_note'].cat.categories.tolist(),\n",
    "#     \"\\n\\n\", \"Source:\", data_nochart_combined['source'].unique(),\n",
    "#     \"\\n\\n\", \"Notes:\", data_nochart_combined['chk_note'].unique(),\n",
    "#     \"\\n\\n\", \"Comments:\", data_nochart_combined['comment'].unique(),\n",
    "#     \"\\n\\n\", \"Fail mode:\", data_nochart_combined['chk_fail'].unique()\n",
    "# )\n",
    "\n",
    "# Counts of each 'source' type\n",
    "print(\n",
    "    data_combined['source'].value_counts(dropna = False),\n",
    "    data_combined['chk_note'].value_counts(dropna = False),\n",
    "    data_combined['comment'].value_counts(dropna=False),\n",
    "    data_combined['chk_fail'].unique(),\n",
    "    sep=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# soil info\n",
    "\n",
    "# print(data_nochart_soil_shallow['sample'].value_counts(dropna = False),\n",
    "#       data_nochart_soil_shallow['depth'].value_counts(dropna = False),\n",
    "#       data_nochart_soil_deep['sample'].value_counts(dropna = False),\n",
    "#       data_nochart_soil_deep['depth'].value_counts(dropna = False),\n",
    "#       sep = \"\\n\\n\"\n",
    "#       )\n",
    "\n",
    "# print(data_nochart_soil_deep[~data_nochart_soil_deep['depth'].str.contains(\"30-40\", na=False)])\n",
    "\n",
    "# # data_soil_deep[~data_soil_deep['sample'].str.contains(\"1|2|3|4|5|6|7|8|9|10\", na=False)]\n",
    "# data_nochart_soil_shallow[~data_nochart_soil_shallow['sample'].isin([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])]\n",
    "\n",
    "# # print(data_soil_deep['sample'].value_counts(dropna = False))\n",
    "# # print(data_soil_deep['depth'].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c98742",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16f3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_between(input_date_start, input_date_end):\n",
    "    data_subset = data_combined.loc[input_date_start:input_date_end]\n",
    "\n",
    "    data_subset_rain = data_rainfall.sort_index()\n",
    "    data_subset_rain = data_subset_rain.loc[input_date_start:input_date_end]\n",
    "\n",
    "    data_subset_cal = data_calibrations.sort_index()\n",
    "    data_subset_cal = data_subset_cal.loc[input_date_start:input_date_end]\n",
    "    # plt.figure(figsize = (10,6))\n",
    "    # plt.plot(data_subset.index, data_subset['raw'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # ax.figure(figsize=(10, 6))\n",
    "    plt.axhline(y=0, color = \"grey\", linestyle = \":\")\n",
    "    ax.vlines(data_subset_rain.index, ymin=0, ymax=data_subset_rain['ra']*3, color = \"blue\", label = \"Rain (x3)\")\n",
    "    ax.plot(data_subset.index, data_subset['level'], color = \"red\", label = \"Adjusted\")\n",
    "    ax.plot(data_subset.index, data_subset['raw'], color = \"green\", label = \"Raw\")\n",
    "    ax.plot(data_subset_cal.index, data_subset_cal['weir_level'], linestyle='none', marker='x', color=\"red\", label = \"Calibration\")\n",
    "    # plt.plot(data_subset_rain.index, data_subset_rain['ra']*3, color = \"blue\", linestyle='none', marker='o')\n",
    "    # plt.plot(data_calibrations.index, data_calibrations['level'], color = \"red\")\n",
    "    ax.set_xlabel('Date (YYYY-MM-DD)')\n",
    "    ax.set_ylabel('Level (mm)')\n",
    "    # ax.set_title('Simple Time Series Plot')\n",
    "    # ax.set_ylim(bottom=0) \n",
    "    # ax.grid(True)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc = 'upper right')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_between('2010-05-20 00:00:01','2010-05-25 23:59:59')\n",
    "plot_between('2020-05-31 00:00:01','2020-06-16 23:59:59')\n",
    "# plot_between('2023-05-14 00:00:01','2023-06-15 23:59:59')\n",
    "# plot_between('2002-07-30 00:00:01','2002-08-02 23:59:59')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('chk_note:', data_combined_sources['chk_note'].cat.categories.tolist())\n",
    "# print('chk_fail:', data_combined_sources['chk_fail'].cat.categories.tolist())\n",
    "# print('source:', data_combined_sources['source'].cat.categories.tolist())\n",
    "\n",
    "# data_combined_sources[data_combined_sources['source']=='TROLL']\n",
    "# data_combined_sources.T['source']\n",
    "# data_combined_sources.sample(10)[\"source\"]\n",
    "\n",
    "# counts of each 'source' type\n",
    "print(data_combined['chk_note'].value_counts(dropna = False))\n",
    "print(data_combined['comment'].value_counts(dropna=False))\n",
    "print(data_combined['source'].value_counts(dropna = False))\n",
    "\n",
    "# data_combined.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe875b",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139970fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dec_explore = data_all_combined.sort_index()['1989-01-01 00:00:01':'1989-12-12 23:59:59']\n",
    "# data_dec_explore = data_dec_explore[data_dec_explore['source']!='CHART']\n",
    "# data_dec_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136102f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series = pd.Series(data_combined, index='datetime')\n",
    "# time_series\n",
    "# pd.DatetimeIndex.to_series(data_combined)\n",
    "# time_series = pd.to_datetime(data_combined.index())\n",
    "\n",
    "# data_combined.index.year\n",
    "# data_mini = data_combined['2010-05-20 00:00:01':'2010-05-25 23:59:59']\n",
    "# data_mini = data_combined['2010-05-01 00:00:01':'2010-10-31 23:59:59']\n",
    "# data_mini['raw'].resample('1ME').agg(['mean','std'])\n",
    "\n",
    "# data_mini.rolling(2, on='raw').sum()\n",
    "# data_mini.rolling('1D', on='raw').sum()\n",
    "# data_mini['raw'].rolling('1D').mean()\n",
    "# data_mini['raw'].rolling('1D', closed='left').mean()\n",
    "# data_mini['raw'].resample('1D').mean()\n",
    "\n",
    "# data_mini['raw'].resample('1ME').mean()\n",
    "# data_combined['raw'].dropna()\n",
    "# data_combined['raw'].resample('YE').agg(['mean','std'])\n",
    "# data_mini = data_combined['raw'].dropna()\n",
    "# data_combined['1972-01-01 00:00:01':'1973-12-31 23:59:59']\n",
    "\n",
    "# # Remove missing values\n",
    "# data_mini = data_combined[data_combined['chk_note']!='missing']\n",
    "# # Remove a few extra points\n",
    "# data_mini = data_mini['1978-01-01 00:00:01':]\n",
    "# data_mini.resample('YE').agg(['mean','std'])\n",
    "\n",
    "# data_sumstats = data_mini['1989-01-01 00:00:01':'1989-12-31 23:59:59']\n",
    "data_sumstats = data_combined['raw'].dropna().resample('6ME').agg(['mean','std']).dropna()\n",
    "data_sumstats\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(data_sumstats.index, data_sumstats['mean'])\n",
    "# plt.plot(data_sumstats.index, data_sumstats['std'])\n",
    "# plt.show()\n",
    "\n",
    "# print(data_mini['source'].value_counts(dropna = False))\n",
    "# data_mini.rolling('1D').sum()\n",
    "# data_mini.rolling(5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # ax.figure(figsize=(10, 6))\n",
    "plt.axhline(y=0, color = \"grey\", linestyle = \":\")\n",
    "# ax.vlines(data_subset_rain.index, ymin=0, ymax=data_subset_rain['ra']*3, color = \"blue\", label = \"Rain (x3)\")\n",
    "ax.plot(data_sumstats.index, data_sumstats['mean'], color = \"red\", label = \"Mean\", marker = 'x')\n",
    "# ax.plot(data_sumstats.index, data_sumstats['std'], color = \"green\", label = \"std\")\n",
    "ax.fill_between(data_sumstats.index, data_sumstats['mean']-data_sumstats['std'], data_sumstats['mean']+data_sumstats['std'], color = \"pink\", label = \"std\")\n",
    "# ax.plot(data_subset_cal.index, data_subset_cal['weir_level'], linestyle='none', marker='x', color=\"red\", label = \"Calibration\")\n",
    "# plt.plot(data_subset_rain.index, data_subset_rain['ra']*3, color = \"blue\", linestyle='none', marker='o')\n",
    "# plt.plot(data_calibrations.index, data_calibrations['level'], color = \"red\")\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Level (mm)')\n",
    "ax.set_title('Average raw values every 6mo')\n",
    "# ax.set_title('Simple Time Series Plot')\n",
    "# ax.set_ylim(bottom=0) \n",
    "ax.set_xlim(left = dt.date(1989, 1, 1), right=dt.date(2026, 1, 1))\n",
    "# ax.grid(True)\n",
    "# ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6)) # Show ticks every month\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month=1)) # Show ticks every month\n",
    "ax.xaxis.set_minor_locator(mdates.YearLocator(month=7)) # Show ticks every month\n",
    "# plt.xticks(np.arange(min(data_sumstats.index), max(data_sumstats.index)+1, 1.0),rotation=45, ha='right')\n",
    "plt.xticks(rotation=90)\n",
    "# ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "plt.tight_layout()\n",
    "plt.legend(loc = 'upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
