{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36f3e2c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa7a4c",
   "metadata": {},
   "source": [
    "## Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e391302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For data importing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5133f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Optional chunk)\n",
    "# Current session information\n",
    "import session_info\n",
    "session_info.show(dependencies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de25f7",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Files of interest:\n",
    "- `weir_calibration.csv` includes calibration points for the weir\n",
    "- `bci_lutzweir_combined.csv` includes raw runoff measurement, corrected runoff measurement, data source (*Chart measurements can be removed)\n",
    "- `bci_cl_ra_elect2.CSV` has corrected rainfall (`ra`) in mm with measurements of `0` as `NA`s (`bci_cl_ra_elect.csv` has `0`s)\n",
    "- `bci_lutz_deep_gsm_man.csv`, `bci_lutz_shallow_gsm_man.csv` have soil moisture measurements (water by wet weight and water by dry weight; one can be chosen for analysis as they are linearly related)\n",
    "<!-- `bci_cl_ra_elect.csv` has corrected rainfall (`ra`) in mm, contains `0`s (large file) -->\n",
    "\n",
    "All values level values are in mm, and datetime is in UTC-5 (Panama time zone).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671e55e",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calibrations dataset\n",
    "data_calibrations = pd.read_csv(\n",
    "    \"data/weir_calibration.csv\",\n",
    "    # nrows = 10000,\n",
    "    usecols = ['datetime', 'weir_level'], # weir_hour is a repeat of the time in datetime and can be skipped\n",
    "    parse_dates=['datetime'],\n",
    "    date_format='%d/%m/%Y %H:%M:%S'\n",
    "    # dtype = {'datetime': 'datetime', 'weir_level': 'int'}\n",
    ")\n",
    "\n",
    "data_calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"data/bci_lutzweir_combined.csv\", nrows=2)\n",
    "\n",
    "# # Dataframe to filter out CHART sources\n",
    "# data_combined_sources = pd.read_csv(\n",
    "#     \"data/bci_lutzweir_combined.csv\",\n",
    "#     usecols = ['datetime', 'source', 'chk_note', 'chk_fail'],\n",
    "#     parse_dates=['datetime'],\n",
    "#     date_format='%d/%m/%Y %H:%M:%S',\n",
    "#     dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'category'}\n",
    "#     # nrows = 2000000\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataframe to filter out CHART sources\n",
    "# data_combined_sources = pd.read_csv(\n",
    "#     \"data/bci_lutzweir_combined.csv\",\n",
    "#     usecols = ['datetime', 'source', 'chk_note', 'chk_fail'],\n",
    "#     parse_dates=['datetime'],\n",
    "#     date_format='%d/%m/%Y %H:%M:%S',\n",
    "#     dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'category'}\n",
    "#     # nrows = 2000000\n",
    "# )\n",
    "\n",
    "# print(data_combined_sources)\n",
    "# print(data_combined_sources['chk_note'].cat.categories.tolist())\n",
    "# print(data_combined_sources['chk_fail'].cat.categories.tolist())\n",
    "# print(data_combined_sources['source'].cat.categories.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c080661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bci_lutzweir_combined.csv\n",
    "# # ['CHART', 'CHART+AF', 'ISCO']\n",
    "\n",
    "# data_combined = pd.read_csv(\n",
    "#     \"data/bci_lutzweir_combined.csv\",\n",
    "#     # nrows = 300000,\n",
    "#     usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "#     parse_dates=['datetime'],\n",
    "#     dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
    "#     date_format='%d/%m/%Y %H:%M:%S'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf20cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, random sample shown below\n",
      "                   datetime  level    raw chk_note chk_fail comment source\n",
      "3646952 2022-09-10 09:55:00  51.65  51.65       nc      NaN     NaN    NaN\n",
      "3718538 2023-05-16 23:25:00   7.80   7.80       nc      NaN     NaN    NaN\n",
      "1839449 2005-05-05 03:40:00  31.00  31.00     good      NaN     NaN   ISCO\n",
      "2272098 2009-06-16 20:40:00   9.10   9.10     good      NaN     NaN   ISCO\n",
      "1816806 2005-02-15 12:45:00  26.80  26.80     good      NaN     NaN   ISCO\n"
     ]
    }
   ],
   "source": [
    "# Checking if the dataset is already loaded into the workspace\n",
    "try:\n",
    "    if data_combined.empty == False:\n",
    "        print(\"Data loaded, random sample shown below\")\n",
    "        print(data_combined.sample(n=5))\n",
    "except NameError:\n",
    "    print(\"Data has not yet been read in, loading now...\")\n",
    "    data_combined = pd.read_csv(\n",
    "        \"data/bci_lutzweir_combined.csv\",\n",
    "        usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "        parse_dates=['datetime'],\n",
    "        dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
    "        date_format='%d/%m/%Y %H:%M:%S'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb06ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1972-01-01 01:00:00  2015-03-18 14:15:00 CHART\n",
      "1972-09-16 00:15:00  2025-08-01 13:00:00 nan\n",
      "1989-07-19 11:55:00  1996-10-01 23:55:00 CHART+AF\n",
      "1996-10-02 00:00:00  2013-01-13 05:50:00 ISCO\n",
      "2012-04-23 08:30:00  2012-04-24 08:35:00 ESTIMATED\n",
      "2014-08-22 10:30:00  2021-05-19 09:40:00 RADAR\n",
      "2018-08-31 10:05:00  2018-09-05 12:55:00 TROLL\n"
     ]
    }
   ],
   "source": [
    "# Get earliest and latest dates of sources\n",
    "cat_source = data_combined['source'].unique().tolist()\n",
    "# print(cat_source)\n",
    "for cat in cat_source:\n",
    "    if pd.isna(cat) == True:\n",
    "        temp_subset = data_combined[data_combined[\"source\"].isnull()]\n",
    "    else:\n",
    "        temp_subset = data_combined[data_combined[\"source\"]==cat]\n",
    "    print(min(temp_subset['datetime']), \"\", max(temp_subset['datetime']), cat)\n",
    "\n",
    "# Save space, remove no longer needed items\n",
    "del cat_source, cat, temp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453b61c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime    datetime64[ns]\n",
      "level              float64\n",
      "raw                float64\n",
      "chk_note          category\n",
      "chk_fail            object\n",
      "comment             object\n",
      "source            category\n",
      "dtype: object\n",
      "                   datetime  level     raw  chk_note  \\\n",
      "702829  1994-05-19 09:55:00  13.10   13.10      good   \n",
      "607151  1993-06-17 03:20:00  25.70   25.70      good   \n",
      "2505769 2011-09-07 03:40:00  63.60   63.60      good   \n",
      "2692083 2013-07-16 09:57:49  38.32   38.32      good   \n",
      "2755691 2014-03-18 18:45:00   7.19    5.98  adjusted   \n",
      "368860  1991-03-05 16:05:00  75.20   75.20      good   \n",
      "458178  1992-01-09 19:20:00  33.30   33.30      good   \n",
      "1636447 2003-05-31 06:50:00  16.40   16.40      good   \n",
      "2115081 2007-12-19 21:15:00  47.20   47.20      good   \n",
      "3822535 2024-05-12 01:50:00   0.00 -133.40  adjusted   \n",
      "2537630 2011-12-26 18:40:00  72.40   72.40      good   \n",
      "2465957 2011-04-21 14:15:00   9.90    9.90      good   \n",
      "3485065 2021-02-25 07:20:00  28.00   32.00  adjusted   \n",
      "3452688 2020-11-04 21:15:00  72.61   87.80  adjusted   \n",
      "727465  1994-08-12 22:55:00  57.30   57.30      good   \n",
      "754349  1994-11-14 09:00:00  52.00   52.00      good   \n",
      "3839130 2024-07-08 16:45:00  44.36   44.36        nc   \n",
      "685423  1994-03-19 21:25:00  14.70   14.70      good   \n",
      "838647  1995-09-04 15:35:00  57.10   57.10      good   \n",
      "2120545 2008-01-07 20:35:00  45.20   45.20      good   \n",
      "2644771 2013-01-03 23:28:09  63.00 -999.00  adjusted   \n",
      "304819  1990-07-26 07:20:00  65.40   65.40      good   \n",
      "2144128 2008-03-29 17:50:00   9.50    9.50      good   \n",
      "3708598 2023-04-12 11:05:00   0.00  -61.28  adjusted   \n",
      "575947  1993-02-22 16:05:00  19.10   19.10      good   \n",
      "\n",
      "                         chk_fail comment    source  \n",
      "702829                        NaN     NaN  CHART+AF  \n",
      "607151                        NaN     NaN  CHART+AF  \n",
      "2505769                       NaN     NaN      ISCO  \n",
      "2692083                       NaN     NaN     CHART  \n",
      "2755691               Obstruction     NaN     CHART  \n",
      "368860                        NaN     NaN  CHART+AF  \n",
      "458178                        NaN     NaN  CHART+AF  \n",
      "1636447                       NaN     NaN      ISCO  \n",
      "2115081                       NaN     NaN      ISCO  \n",
      "3822535               Calibration     NaN       NaN  \n",
      "2537630                       NaN     NaN      ISCO  \n",
      "2465957                       NaN     NaN      ISCO  \n",
      "3485065               Calibration     NaN     RADAR  \n",
      "3452688  Obstruction, Calibration     NaN     RADAR  \n",
      "727465                        NaN     NaN  CHART+AF  \n",
      "754349                        NaN     NaN  CHART+AF  \n",
      "3839130                       NaN     NaN       NaN  \n",
      "685423                        NaN     NaN  CHART+AF  \n",
      "838647                        NaN     NaN  CHART+AF  \n",
      "2120545                       NaN     NaN      ISCO  \n",
      "2644771                  Gap Fill     NaN       NaN  \n",
      "304819                        NaN     NaN  CHART+AF  \n",
      "2144128                       NaN     NaN      ISCO  \n",
      "3708598                       NaN     NaN       NaN  \n",
      "575947                        NaN     NaN  CHART+AF  \n",
      "Source: ['CHART', 'CHART+AF', 'ISCO', 'ESTIMATED', 'RADAR', 'TROLL']\n",
      "Notes: ['adjusted', 'good', 'missing', 'nc', 'bad']\n",
      "Fail mode: [nan 'Gap Fill' 'Obstruction' 'Calibration' 'Spike'\n",
      " 'Calibration, Calibration' 'Gap Fill, Gap Fill'\n",
      " 'Obstruction, Obstruction' 'Obstruction, Calibration' 'Spike, Spike'\n",
      " 'Gap Fill, Gap Fill, Gap Fill' 'Gap Fill, Gap Fill, Gap Fill, Gap Fill'\n",
      " 'Obstruction, Step' 'Step' 'Spike, Obstruction'\n",
      " 'Calibration, Spike, Obstruction' 'Calibration, Obstruction'\n",
      " 'Obstruction, Calibration, Obstruction'\n",
      " 'Calibration, Calibration, Obstruction'\n",
      " 'Calibration, Calibration, Calibration' 'Calibration, Spike'\n",
      " 'Obstruction, Obstruction, Calibration'\n",
      " 'Obstruction, Obstruction, Obstruction, Calibration' 'Spike, Calibration'\n",
      " 'Obstruction, Spike, Calibration' 'Weir Cleaning, Calibration'\n",
      " 'Weir Cleaning, Weir Cleaning, Weir Cleaning, Weir,'\n",
      " 'Weir Cleaning, Weir Cleaning, Weir Cleaning, Calib'\n",
      " 'Weir Cleaning, Weir Cleaning, Calibration' 'Gap Fill, Calibration'\n",
      " 'Obstruction, Obstruction, Obstruction' 'Weir Cleaning'\n",
      " 'Obstruction, Weir Cleaning' 'Obstruction, Obstruction, Weir Cleaning'\n",
      " 'Calibration, Weir Cleaning' 'Range' 'Weir Cleaning, Weir Cleaning']\n",
      "Comments: [nan 'Data missing'\n",
      " 'Original data missing. Copied from 17/07/2013 (had a similar rain event)'\n",
      " 'Original data missing. Copied from 22/09/2013 (had a similar rain event)']\n"
     ]
    }
   ],
   "source": [
    "print(data_combined.dtypes)\n",
    "print(data_combined.sample(n=25))\n",
    "print(\"Source:\", data_combined['source'].cat.categories.tolist())\n",
    "print(\"Notes:\", data_combined['chk_note'].cat.categories.tolist())\n",
    "print(\"Fail mode:\", data_combined['chk_fail'].unique())\n",
    "print(\"Comments:\", data_combined['comment'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1044b",
   "metadata": {},
   "source": [
    "## General Variable Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chk_note\n",
      "good        2730307\n",
      "adjusted     867014\n",
      "nc           336129\n",
      "missing       17668\n",
      "bad               1\n",
      "Name: count, dtype: int64\n",
      "comment\n",
      "NaN                                                                         3950937\n",
      "Original data missing. Copied from 17/07/2013 (had a similar rain event)        103\n",
      "Original data missing. Copied from 22/09/2013 (had a similar rain event)         63\n",
      "Data missing                                                                     16\n",
      "Name: count, dtype: int64\n",
      "source\n",
      "ISCO         1656120\n",
      "CHART+AF      752435\n",
      "RADAR         702704\n",
      "NaN           525298\n",
      "CHART         312844\n",
      "TROLL           1428\n",
      "ESTIMATED        290\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3951119 entries, 0 to 3951118\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Dtype         \n",
      "---  ------    -----         \n",
      " 0   datetime  datetime64[ns]\n",
      " 1   level     float64       \n",
      " 2   raw       float64       \n",
      " 3   chk_note  category      \n",
      " 4   chk_fail  object        \n",
      " 5   comment   object        \n",
      " 6   source    category      \n",
      "dtypes: category(2), datetime64[ns](1), float64(2), object(2)\n",
      "memory usage: 158.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# print('chk_note:', data_combined_sources['chk_note'].cat.categories.tolist())\n",
    "# print('chk_fail:', data_combined_sources['chk_fail'].cat.categories.tolist())\n",
    "# print('source:', data_combined_sources['source'].cat.categories.tolist())\n",
    "\n",
    "# data_combined_sources[data_combined_sources['source']=='TROLL']\n",
    "# data_combined_sources.T['source']\n",
    "# data_combined_sources.sample(10)[\"source\"]\n",
    "\n",
    "# counts of each 'source' type\n",
    "print(data_combined['chk_note'].value_counts(dropna = False))\n",
    "print(data_combined['comment'].value_counts(dropna=False))\n",
    "print(data_combined['source'].value_counts(dropna = False))\n",
    "\n",
    "# data_combined.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c99e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get IDs of data points to filter out\n",
    "data_combined_sources.sample(n=10)[\"source\"==\"CHART\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246603e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# block to test if the item is already loaded\n",
    "hello_world = 2\n",
    "\n",
    "try:\n",
    "    if hello_world:\n",
    "    # if hello_world.empty == False:\n",
    "        print(\"data loaded\")\n",
    "except NameError:\n",
    "    print(\"data NOT loaded\")\n",
    "# data_combined_sources.empty\n",
    "# assert(len(data_combined_sources) == 0)\n",
    "\n",
    "# try:\n",
    "#     if len(data_combined) >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84326b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = data_combined_sources.sample(n=100)\n",
    "data_subset[data_subset['source'] == 'CHART']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_combined.loc[data_combined['source']='CHART']\n",
    "# print(data_combined.loc[data_combined['source'] == 'CHART']) # Selects rows where column 'A' is greater than 1\n",
    "# data_combined.loc[data_combined['source'].isin(['CHART', 'CHART+AF'])]\n",
    "# len(data_combined['source'].isin(['CHART', 'CHART+AF']).index.tolist())\n",
    "# data_combined['source']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
