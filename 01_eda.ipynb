{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36f3e2c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Author: Gillian A. McGinnis, final-semester M.S. Information Science - Machine Learning  \n",
    "The University of Arizona College of Information  \n",
    "INFO 698 - Capstone  \n",
    "Start date: 24 September 2025  \n",
    "Last updated: 04 October 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f4c138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModule providing supporting code and generating all images/tables for EDA.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Module providing supporting code and generating all images/tables for EDA.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa7a4c",
   "metadata": {},
   "source": [
    "## Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e391302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5133f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.10.6\n",
       "numpy               2.3.3\n",
       "pandas              2.3.2\n",
       "session_info        v1.0.1\n",
       "-----\n",
       "IPython             9.5.0\n",
       "jupyter_client      8.6.3\n",
       "jupyter_core        5.8.1\n",
       "-----\n",
       "Python 3.13.7 (v3.13.7:bcee1c32211, Aug 14 2025, 19:10:51) [Clang 16.0.0 (clang-1600.0.26.6)]\n",
       "macOS-15.6.1-x86_64-i386-64bit-Mach-O\n",
       "-----\n",
       "Session information updated at 2025-10-13 11:45\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## (Optional chunk)\n",
    "# Current session information\n",
    "import session_info\n",
    "session_info.show(dependencies=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de25f7",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Files of interest:\n",
    "- `weir_calibration.csv` includes calibration points for the weir\n",
    "- `bci_lutzweir_combined.csv` includes raw runoff measurement, corrected runoff measurement, data source (*Chart measurements can be removed)\n",
    "- `bci_cl_ra_elect2.CSV` has corrected rainfall (`ra`) in mm with measurements of `0` as `NA`s (`bci_cl_ra_elect.csv` has `0`s)\n",
    "- `bci_lutz_deep_gsm_man.csv`, `bci_lutz_shallow_gsm_man.csv` have soil moisture measurements (water by wet weight and water by dry weight; one can be chosen for analysis as they are linearly related)\n",
    "<!-- `bci_cl_ra_elect.csv` has corrected rainfall (`ra`) in mm, contains `0`s (large file) -->\n",
    "\n",
    "All values level values are in mm, and datetime is in UTC-5 (Panama time zone).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671e55e",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f5d3909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 6465 entries, 1994-01-03 08:46:00 to 2025-09-02 08:50:00\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   weir_level  6465 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 101.0 KB\n"
     ]
    }
   ],
   "source": [
    "## Calibrations dataset\n",
    "data_all_calibration = pd.read_csv(\n",
    "    # Location of the dataset in the repo\n",
    "    \"data/weir_calibration.csv\",\n",
    "    # Specify columns to load\n",
    "    ## note- weir_hour is a repeat of the time in datetime and can be skipped\n",
    "    usecols = ['datetime', 'weir_level'],\n",
    "    # Convert datetime stamp strings to datetime objects\n",
    "    parse_dates = ['datetime'],\n",
    "    # Specify the string formatting of the datetime stamps\n",
    "    date_format = \"%d/%m/%Y %H:%M:%S\",\n",
    "    # Use datetime stamp as index\n",
    "    index_col = 'datetime'\n",
    ")\n",
    "\n",
    "# Arrange chronologically\n",
    "data_all_calibration = data_all_calibration.sort_index()\n",
    "\n",
    "data_all_calibration.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19382df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3951119 entries, 1972-01-01 01:00:00 to 2025-08-01 13:00:00\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Dtype   \n",
      "---  ------    -----   \n",
      " 0   level     float64 \n",
      " 1   raw       float64 \n",
      " 2   chk_note  category\n",
      " 3   chk_fail  object  \n",
      " 4   comment   object  \n",
      " 5   source    category\n",
      "dtypes: category(2), float64(2), object(2)\n",
      "memory usage: 158.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Combined data\n",
    "\n",
    "data_all_combined = pd.read_csv(\n",
    "    # Location of the dataset in the repo\n",
    "    \"data/bci_lutzweir_combined.csv\",\n",
    "    # Specify columns to load\n",
    "    usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "    # Specify the types for specific columns\n",
    "    dtype = {\n",
    "        'chk_note':'category',\n",
    "        'chk_fail':'str',\n",
    "        'comment':'str',\n",
    "        'source':'category'\n",
    "    },\n",
    "    # Convert datetime stamp strings to datetime objects\n",
    "    parse_dates = ['datetime'],\n",
    "    # Specify the string formatting of the datetime stamps\n",
    "    date_format = \"%d/%m/%Y %H:%M:%S\",\n",
    "    # Use datetime stamp as index\n",
    "    index_col = 'datetime'\n",
    ")\n",
    "\n",
    "## This variation checks first if the dataset is already loaded into the workspace\n",
    "# try:\n",
    "#     if data_combined.empty == False:\n",
    "#         print(\"Data loaded, random sample shown below\")\n",
    "#         print(data_combined.sample(n=5))\n",
    "# except NameError:\n",
    "#     print(\"Data has not yet been read in, loading now...\")\n",
    "#     data_combined = pd.read_csv(\n",
    "#         \"data/bci_lutzweir_combined.csv\",\n",
    "#         usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "#         parse_dates=['datetime'],\n",
    "#         dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
    "#         date_format='%d/%m/%Y %H:%M:%S'\n",
    "#     )\n",
    "\n",
    "# Arrange chronologically\n",
    "data_all_combined = data_all_combined.sort_index()\n",
    "\n",
    "data_all_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b35292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 179640 entries, 1929-01-02 08:00:00 to 2025-08-04 11:55:00\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype   \n",
      "---  ------    --------------   -----   \n",
      " 0   ra        179640 non-null  float64 \n",
      " 1   raw       179640 non-null  float64 \n",
      " 2   chk_note  179640 non-null  category\n",
      " 3   chk_fail  29 non-null      object  \n",
      "dtypes: category(1), float64(2), object(1)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Rainfall dataset\n",
    "\n",
    "# This data set skips the 0 readings (therefore much smaller):\n",
    "data_all_rainfall = pd.read_csv(\n",
    "    # Location of the dataset in the repo\n",
    "    \"data/bci_elect_cl_ra/bci_cl_ra_elect2.CSV\",\n",
    "    # Specify the types for specific columns\n",
    "    dtype = {\n",
    "        'chk_note':'category',\n",
    "        'chk_fail':'str'\n",
    "    },\n",
    "    # Convert datetime stamp strings to datetime objects\n",
    "    parse_dates = ['datetime'],\n",
    "    # Specify the string formatting of the datetime stamps\n",
    "    date_format = \"%d/%m/%Y %H:%M:%S\",\n",
    "    # Use datetime stamp as index\n",
    "    index_col = 'datetime'\n",
    ")\n",
    "\n",
    "# Arrange chronologically\n",
    "data_all_rainfall = data_all_rainfall.sort_index()\n",
    "\n",
    "## This data set includes the 0 readings:\n",
    "# data_all_rainfall_zeroes = pd.read_csv(\n",
    "#         \"data/bci_elect_cl_ra/bci_cl_ra_elect.csv\",\n",
    "#         usecols = ['datetime', 'ra', 'raw', 'chk_note', 'chk_fail'],\n",
    "#         # \"data/bci_elect_cl_ra/bci_cl_ra_elect2.CSV\",\n",
    "#         # usecols = ['datetime', 'level', 'raw', 'chk_note', 'chk_fail', 'comment', 'source'],\n",
    "#         parse_dates=['datetime'],\n",
    "#         dtype = {'chk_note':'category', 'chk_fail':'str'},\n",
    "#         # dtype = {'source':'category', 'chk_note':'category', 'chk_fail':'str', 'comment':'str'},\n",
    "#         date_format='%d/%m/%Y %H:%M:%S'\n",
    "#     )\n",
    "# # Arrange chronologically\n",
    "# data_all_rainfall_zeroes = data_all_rainfall_zeroes.sort_index()\n",
    "\n",
    "data_all_rainfall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4db0e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 18556 entries, 1972-03-03 to 2025-06-26\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   depth       18556 non-null  category\n",
      " 1   sample      18556 non-null  category\n",
      " 2   h2o_by_wet  18556 non-null  float64 \n",
      " 3   chk_note    18556 non-null  category\n",
      " 4   chk_fail    178 non-null    object  \n",
      "dtypes: category(3), float64(1), object(1)\n",
      "memory usage: 490.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15637 entries, 1972-03-03 to 2025-06-26\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype   \n",
      "---  ------      --------------  -----   \n",
      " 0   depth       15637 non-null  category\n",
      " 1   sample      15637 non-null  category\n",
      " 2   h2o_by_wet  15637 non-null  float64 \n",
      " 3   chk_note    15637 non-null  category\n",
      " 4   chk_fail    20 non-null     object  \n",
      "dtypes: category(3), float64(1), object(1)\n",
      "memory usage: 413.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Soil datasets\n",
    "\n",
    "# Shallow\n",
    "data_all_soil_shallow = pd.read_csv(\n",
    "    # Location of the dataset in the repo\n",
    "    \"data/bci_manual_soilh/bci_lutz_shallow_gsm_man.csv\",\n",
    "    # Specify columns to load\n",
    "    usecols = ['date', 'depth', 'sample', 'h2o_by_wet', 'chk_note', 'chk_fail'],\n",
    "    # Specify the types for specific columns\n",
    "    dtype = {\n",
    "        'depth':'category',\n",
    "        'sample':'category',\n",
    "        'chk_note':'category',\n",
    "        'chk_fail':'str'\n",
    "    },\n",
    "    # Convert date stamp strings to date objects\n",
    "    parse_dates = ['date'],\n",
    "    # Specify the string formatting of the date stamps\n",
    "    date_format = \"%d/%m/%Y\",\n",
    "    # Use date stamp as index\n",
    "    index_col = 'date'\n",
    ")\n",
    "\n",
    "# Deep\n",
    "data_all_soil_deep = pd.read_csv(\n",
    "    # Location of the dataset in the repo\n",
    "    \"data/bci_manual_soilh/bci_lutz_deep_gsm_man.csv\",\n",
    "    # Specify columns to load\n",
    "    usecols = ['date', 'depth', 'sample', 'h2o_by_wet', 'chk_note', 'chk_fail'],\n",
    "    # Specify the types for specific columns\n",
    "    dtype = {\n",
    "        'depth':'category',\n",
    "        'sample':'category',\n",
    "        'chk_note':'category',\n",
    "        'chk_fail':'str'\n",
    "    },\n",
    "    # Convert date stamp strings to date objects\n",
    "    parse_dates = ['date'],\n",
    "    # Specify the string formatting of the date stamps\n",
    "    date_format = \"%d/%m/%Y\",\n",
    "    # Use date stamp as index\n",
    "    index_col = 'date'\n",
    ")\n",
    "\n",
    "# Arrange chronologically\n",
    "data_all_soil_shallow = data_all_soil_shallow.sort_index()\n",
    "data_all_soil_deep = data_all_soil_deep.sort_index()\n",
    "\n",
    "data_all_soil_shallow.info()\n",
    "data_all_soil_deep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d1280",
   "metadata": {},
   "source": [
    "*A note about the soil datasets:\n",
    "\n",
    "Both `h2o_by_wet` and `h2o_by_dry` are available in the datasets.\n",
    "Because they are linearly related to each other, only one of them is necessary for modelling.\n",
    "Arbitrarily, `h2o_by_wet` has been chosen for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059eaebd",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "Data cleanup is necessary to ensure ease of uniting the sets, conducting a test/train split, and creation of & fitting of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114972b0",
   "metadata": {},
   "source": [
    "### Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2e3b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest \t     Latest \t\t Source\n",
      "1972-01-01 01:00:00  2015-03-18 14:15:00 CHART\n",
      "1972-09-16 00:15:00  2025-08-01 13:00:00 nan\n",
      "1989-07-19 11:55:00  1996-10-01 23:55:00 CHART+AF\n",
      "1996-10-02 00:00:00  2013-01-13 05:50:00 ISCO\n",
      "2012-04-23 08:30:00  2012-04-24 08:35:00 ESTIMATED\n",
      "2014-08-22 10:30:00  2021-05-19 09:40:00 RADAR\n",
      "2018-08-31 10:05:00  2018-09-05 12:55:00 TROLL\n"
     ]
    }
   ],
   "source": [
    "# Explore: Get earliest and latest dates of sources\n",
    "\n",
    "cat_source = data_all_combined['source'].unique().tolist()\n",
    "# Header for printed table\n",
    "print(\"Earliest\", \"\\t    \", \"Latest\", \"\\t\\t\", \"Source\")\n",
    "# Iterate across each source type\n",
    "for cat in cat_source:\n",
    "    # If the source is NaN\n",
    "    if pd.isna(cat) == True:\n",
    "        temp_subset = data_all_combined[data_all_combined['source'].isnull()]\n",
    "    else:\n",
    "        temp_subset = data_all_combined[data_all_combined['source'] == cat]\n",
    "    # Sort index\n",
    "    temp_subset = temp_subset\n",
    "    # Print\n",
    "    print(temp_subset.index[0], \"\", temp_subset.index[-1], cat)\n",
    "\n",
    "# Save space, remove no longer needed items\n",
    "del cat_source, cat, temp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ceb06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Explore: Get earliest and latest dates of sources\n",
    "\n",
    "# cat_source = data_all_combined.sort_index()['source'].unique().tolist()\n",
    "# # Header for printed table\n",
    "# print(\"Earliest\", \"\\t    \", \"Latest\", \"\\t\\t\", \"Source\")\n",
    "# # Iterate across each source type\n",
    "# for cat in cat_source:\n",
    "#     # If the source is NaN\n",
    "#     if pd.isna(cat) == True:\n",
    "#         temp_subset = data_all_combined[data_all_combined['source'].isnull()]\n",
    "#     else:\n",
    "#         temp_subset = data_all_combined[data_all_combined['source'] == cat]\n",
    "#     # Sort index\n",
    "#     temp_subset = temp_subset.sort_index()\n",
    "#     # Print\n",
    "#     print(temp_subset.index[0], \"\", temp_subset.index[-1], cat)\n",
    "\n",
    "# # Save space, remove no longer needed items\n",
    "# del cat_source, cat, temp_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d938c",
   "metadata": {},
   "source": [
    "#### Removing CHART Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b191d88",
   "metadata": {},
   "source": [
    "Only values that are not solely reliant on CHART will be evaluated (i.e., after 1989)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a22e4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-CHART values: 1989-07-19 11:55:00 through 2025-08-01 13:00:00\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset to start once values stopped by being recorded by CHART\n",
    "# date_weir_start = data_all_combined[data_all_combined['source'] == 'CHART+AF'].index[0]\n",
    "date_weir_start = data_all_combined[\n",
    "    # Remove CHART values\n",
    "    # and\n",
    "    (data_all_combined['source'] != 'CHART') &\n",
    "    # Remove values without indicated source\n",
    "    (~data_all_combined['source'].isnull())\n",
    "    # Pull earliest timestamp\n",
    "    ].index[0]\n",
    "# Get latest data point timestamp\n",
    "date_weir_end = data_all_combined.index[-1]\n",
    "\n",
    "# Sanity check\n",
    "# it is expected that the start timestamp will be CHART+AF source\n",
    "if date_weir_start != data_all_combined[data_all_combined['source'] == 'CHART+AF'].index[0]:\n",
    "    print(\"-----!! Warning: Check start date !!-----\",\n",
    "          \"Calculated:\\t\", date_weir_start, \"\\n\"\n",
    "          \"Actual:\\t\\t\", data_all_combined[data_all_combined['source'] == 'CHART+AF'].index[0], \"\\n\")\n",
    "\n",
    "print(\"Non-CHART values:\", date_weir_start, \"through\", date_weir_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ffcf91",
   "metadata": {},
   "source": [
    "#### 2-Year Failure\n",
    "\n",
    "The ISCO sensor failed in early 2013, and there was no backup.\n",
    "Values were recording using the CHART resource, and gap filled accordingly.\n",
    "Electronic recording resumed with RADAR in late 2014.\n",
    "\n",
    "The model cannot be trained on this gap of data, as it is using `CHART` values, and all `raw` values report `-999.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b502b071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two year gap: 2013-01-13 05:54:01 through 2014-08-22 10:21:32\n"
     ]
    }
   ],
   "source": [
    "# data_gap = data_all_combined['2013-01-01 00:00:00':'2014-08-22 23:59:59']\n",
    "data_gap = data_all_combined['2013-01-13 05:00:00':'2014-08-22 23:59:59']\n",
    "\n",
    "# Get the earliest date of gap filling\n",
    "date_gap_start = data_gap[data_gap['source'] == 'CHART'].index[0]\n",
    "\n",
    "# Get the latest date of gap filling\n",
    "date_gap_end = data_gap[data_gap['source'] != 'RADAR'].index[-1]\n",
    "\n",
    "print(\"Two year gap:\", date_gap_start, \"through\", date_gap_end)\n",
    "## OLD EXPECTED -- 2013-01-02 18:54:38 through 2014-08-22 10:21:32\n",
    "## ADJ EXPECTED -- 2013-01-13 05:54:01 through 2014-08-22 10:21:32\n",
    "del data_gap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fdc059",
   "metadata": {},
   "source": [
    "#### Applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4157eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to filter dates\n",
    "def filter_dates(input_dataset, input_date_start, input_date_end, drop_dates = False):\n",
    "# def filter_dates(input_dataset, input_date_start = date_weir_start, input_date_end = date_weir_end, drop_dates = False):\n",
    "    \"\"\"Filter data set to specified start and end dates.\n",
    "    \n",
    "    Args:\n",
    "        input_dataset (pd.DataFrame): Data indexed by datetime.\n",
    "        input_date_start (Timestamp): The start date, defaults to the earliest from the combined data set.\n",
    "        input_date_end (Timestamp): The end date, defaults to the earliest from the combined data set.\n",
    "        drop_dates (bool): Whether to remove the values between the specified dates.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame sorted and filtered to or without the specified range.\n",
    "    \"\"\"\n",
    "    # Sort the dataframe\n",
    "    data_filtered = input_dataset.copy().sort_index()\n",
    "    # Filter between dates\n",
    "    if drop_dates == False:\n",
    "        # data_subset = data_subset.loc[input_date_start:input_date_end]\n",
    "        data_filtered = data_filtered[input_date_start:input_date_end]\n",
    "    # Drop between the defined dates, if specified\n",
    "    else:\n",
    "        data_filtered = data_filtered.drop(data_filtered.loc[input_date_start:input_date_end].index)\n",
    "    return data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "694211f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_window(input_dataset, input_timestamp_start, input_timestamp_end):\n",
    "#     \"\"\"Remove window in data set between specified start and end dates.\n",
    "    \n",
    "#     Args:\n",
    "#         input_dataset (pd.DataFrame): Data indexed and sorted by datetime.\n",
    "#         input_timestamp_start (Timestamp): The timestamp for which to start removal.\n",
    "#         input_timestamp_end (Timestamp): The final timestamp to removal.\n",
    "    \n",
    "#     Returns:\n",
    "#         pd.DataFrame sorted and filtered without the specified range.\n",
    "#     \"\"\"\n",
    "#     ## Sort the dataframe\n",
    "#     # data_subset = input_dataset.sort_index()\n",
    "#     # Remove the specified time window by dropping indices within the range\n",
    "#     data_filtered = input_dataset.drop(input_dataset.loc[input_timestamp_start:input_timestamp_end].index)\n",
    "#     return data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3c676b",
   "metadata": {},
   "source": [
    "For large gaps, it may still be useful for the model to keep predictor variables in the time leading up to the useful weir data.\n",
    "\n",
    "Thus, the rainfall and soil moisture data up to one month prior to any hard cutoff will be kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58c3284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify data removal\n",
    "def apply_filter_dates(input_dataset, input_adj = '0 D'):\n",
    "    \"\"\"Apply pre-defined date filters.\n",
    "    \n",
    "    Args:\n",
    "        input_dataset (pd.DataFrame): Data indexed by datetime.\n",
    "        input_adj (str): String argument to account for time leading up to weir data, defaults to none.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame filtered to the weir range and without the 2-year gap window.\n",
    "    \"\"\"\n",
    "    # data_subset = input_dataset[(date_weir_start - pd.Timedelta(input_adj)):date_weir_end]\n",
    "    # data_subset = remove_window(input_dataset = data_subset, input_timestamp_start = date_gap_start, input_timestamp_end = (date_gap_end - pd.Timedelta(input_adj)))\n",
    "    data_adj = filter_dates(\n",
    "        input_dataset = input_dataset,\n",
    "        input_date_start = (date_weir_start - pd.Timedelta(input_adj)),\n",
    "        input_date_end = date_weir_end,\n",
    "        drop_dates = False\n",
    "    )\n",
    "    data_adj = filter_dates(\n",
    "        input_dataset = data_adj,\n",
    "        input_date_start = date_gap_start,\n",
    "        input_date_end = (date_gap_end - pd.Timedelta(input_adj)),\n",
    "        drop_dates = True\n",
    "    )\n",
    "    # data_subset = input_dataset[date_weir_start:date_weir_end]\n",
    "    # data_subset = remove_window(input_dataset = data_subset, input_timestamp_start = date_gap_start, input_timestamp_end = date_gap_end)\n",
    "    return data_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d3fb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filter\n",
    "gap_adj = '4 W'\n",
    "\n",
    "data_combined = apply_filter_dates(data_all_combined)\n",
    "data_calibration = apply_filter_dates(data_all_calibration)\n",
    "# Include data leading up to the weir values\n",
    "data_rainfall = apply_filter_dates(data_all_rainfall, gap_adj)\n",
    "data_soil_shallow = apply_filter_dates(data_all_soil_shallow, gap_adj)\n",
    "data_soil_deep = apply_filter_dates(data_all_soil_deep, gap_adj)\n",
    "\n",
    "del gap_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ed6d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply filter\n",
    "# data_combined = filter_dates(data_all_combined, date_weir_start, date_weir_end)\n",
    "# data_combined = filter_dates(data_combined, date_gap_start, date_gap_end, drop_dates = True)\n",
    "\n",
    "# data_calibration = filter_dates(data_all_calibration, date_weir_start, date_weir_end)\n",
    "# data_calibration = filter_dates(data_calibration, date_gap_start, date_gap_end, drop_dates = True)\n",
    "\n",
    "# data_rainfall = filter_dates(data_all_rainfall, date_weir_start, date_weir_end)\n",
    "# data_rainfall = filter_dates(data_rainfall, date_gap_start, date_gap_end, drop_dates = True)\n",
    "\n",
    "# data_soil_deep = filter_dates(data_all_soil_deep, date_weir_start, date_weir_end)\n",
    "# data_soil_deep = filter_dates(data_soil_deep, date_gap_start, date_gap_end, drop_dates = True)\n",
    "\n",
    "# data_soil_shallow = filter_dates(data_all_soil_shallow, date_weir_start, date_weir_end)\n",
    "# data_soil_shallow = filter_dates(data_soil_shallow, date_gap_start, date_gap_end, drop_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ea89ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old stuff to save space\n",
    "del data_all_calibration, data_all_combined, data_all_rainfall, data_all_soil_shallow, data_all_soil_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef07c2d",
   "metadata": {},
   "source": [
    "### Soil depths\n",
    "There are some duplicated records between the \"shallow\" and \"deep\" data set. Most are identical, but there were two dates with differing records.\n",
    "It was concluded that those values from the \"deep\" set with a depth of \"0â€“10\" may be eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2887432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "depth_shallow",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "depth_deep",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "sample",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "h2o_by_wet_shallow",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "h2o_by_wet_deep",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chk_note_shallow",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "chk_note_deep",
         "rawType": "category",
         "type": "unknown"
        }
       ],
       "ref": "e00f73b7-8178-4ad0-9184-1b4d56b226b2",
       "rows": [
        [
         "0",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "1",
         "34.7",
         "35.5",
         "good",
         "good"
        ],
        [
         "1",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "1",
         "35.4",
         "35.5",
         "good",
         "good"
        ],
        [
         "27",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "1",
         "35.4",
         "34.7",
         "good",
         "good"
        ],
        [
         "42",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "1",
         "34.7",
         "36.3",
         "good",
         "good"
        ],
        [
         "43",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "1",
         "35.4",
         "36.3",
         "good",
         "good"
        ],
        [
         "19",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "2",
         "40.4",
         "36.4",
         "good",
         "good"
        ],
        [
         "29",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "2",
         "40.4",
         "36.4",
         "good",
         "good"
        ],
        [
         "44",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "2",
         "36.4",
         "35.5",
         "good",
         "good"
        ],
        [
         "45",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "2",
         "40.4",
         "35.5",
         "good",
         "good"
        ],
        [
         "2",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "3",
         "35.9",
         "35.1",
         "good",
         "good"
        ],
        [
         "3",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "3",
         "35.3",
         "35.1",
         "good",
         "good"
        ],
        [
         "31",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "3",
         "35.3",
         "35.9",
         "good",
         "good"
        ],
        [
         "46",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "3",
         "35.9",
         "34.6",
         "good",
         "good"
        ],
        [
         "47",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "3",
         "35.3",
         "34.6",
         "good",
         "good"
        ],
        [
         "4",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "4",
         "36.1",
         "34.0",
         "good",
         "good"
        ],
        [
         "5",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "4",
         "37.1",
         "34.0",
         "good",
         "good"
        ],
        [
         "33",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "4",
         "37.1",
         "36.1",
         "good",
         "good"
        ],
        [
         "48",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "4",
         "36.1",
         "35.2",
         "good",
         "good"
        ],
        [
         "49",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "4",
         "37.1",
         "35.2",
         "good",
         "good"
        ],
        [
         "8",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "5",
         "40.0",
         "40.1",
         "good",
         "good"
        ],
        [
         "9",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "5",
         "41.0",
         "40.1",
         "good",
         "good"
        ],
        [
         "35",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "5",
         "41.0",
         "40.0",
         "good",
         "good"
        ],
        [
         "50",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "5",
         "40.0",
         "38.3",
         "good",
         "good"
        ],
        [
         "51",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "5",
         "41.0",
         "38.3",
         "good",
         "good"
        ],
        [
         "10",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "6",
         "31.0",
         "32.1",
         "good",
         "good"
        ],
        [
         "11",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "6",
         "35.2",
         "32.1",
         "good",
         "good"
        ],
        [
         "21",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "6",
         "35.2",
         "31.0",
         "good",
         "good"
        ],
        [
         "52",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "6",
         "31.0",
         "32.2",
         "good",
         "good"
        ],
        [
         "53",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "6",
         "35.2",
         "32.2",
         "good",
         "good"
        ],
        [
         "12",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "7",
         "39.4",
         "34.0",
         "good",
         "good"
        ],
        [
         "13",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "7",
         "44.5",
         "34.0",
         "good",
         "good"
        ],
        [
         "37",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "7",
         "44.5",
         "39.4",
         "good",
         "good"
        ],
        [
         "54",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "7",
         "39.4",
         "36.1",
         "good",
         "good"
        ],
        [
         "55",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "7",
         "44.5",
         "36.1",
         "good",
         "good"
        ],
        [
         "14",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "8",
         "42.3",
         "32.5",
         "good",
         "good"
        ],
        [
         "15",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "8",
         "44.6",
         "32.5",
         "good",
         "good"
        ],
        [
         "41",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "8",
         "44.6",
         "42.3",
         "good",
         "good"
        ],
        [
         "56",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "8",
         "42.3",
         "36.3",
         "good",
         "good"
        ],
        [
         "57",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "8",
         "44.6",
         "36.3",
         "good",
         "good"
        ],
        [
         "16",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "9",
         "32.2",
         "31.6",
         "good",
         "good"
        ],
        [
         "17",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "9",
         "33.2",
         "31.6",
         "good",
         "good"
        ],
        [
         "22",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "9",
         "32.2",
         "31.5",
         "good",
         "good"
        ],
        [
         "23",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "9",
         "33.2",
         "31.5",
         "good",
         "good"
        ],
        [
         "39",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "9",
         "33.2",
         "32.2",
         "good",
         "good"
        ],
        [
         "6",
         "1989-06-23 00:00:00",
         "10-20",
         "40-50",
         "10",
         "36.0",
         "29.9",
         "good",
         "good"
        ],
        [
         "7",
         "1989-06-23 00:00:00",
         "1-10",
         "40-50",
         "10",
         "32.3",
         "29.9",
         "good",
         "good"
        ],
        [
         "24",
         "1989-06-23 00:00:00",
         "10-20",
         "20-30",
         "10",
         "36.0",
         "31.4",
         "good",
         "good"
        ],
        [
         "25",
         "1989-06-23 00:00:00",
         "1-10",
         "20-30",
         "10",
         "32.3",
         "31.4",
         "good",
         "good"
        ],
        [
         "59",
         "1989-06-23 00:00:00",
         "1-10",
         "10-20",
         "10",
         "32.3",
         "36.0",
         "good",
         "good"
        ],
        [
         "189",
         "2005-06-16 00:00:00",
         "1-10",
         "0-10",
         "1",
         "43.0",
         "40.8",
         "good",
         "good"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 60
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>depth_shallow</th>\n",
       "      <th>depth_deep</th>\n",
       "      <th>sample</th>\n",
       "      <th>h2o_by_wet_shallow</th>\n",
       "      <th>h2o_by_wet_deep</th>\n",
       "      <th>chk_note_shallow</th>\n",
       "      <th>chk_note_deep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>1</td>\n",
       "      <td>34.7</td>\n",
       "      <td>35.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>1</td>\n",
       "      <td>35.4</td>\n",
       "      <td>35.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>1</td>\n",
       "      <td>35.4</td>\n",
       "      <td>34.7</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>1</td>\n",
       "      <td>34.7</td>\n",
       "      <td>36.3</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>1</td>\n",
       "      <td>35.4</td>\n",
       "      <td>36.3</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>2</td>\n",
       "      <td>40.4</td>\n",
       "      <td>36.4</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>2</td>\n",
       "      <td>40.4</td>\n",
       "      <td>36.4</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>2</td>\n",
       "      <td>36.4</td>\n",
       "      <td>35.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>2</td>\n",
       "      <td>40.4</td>\n",
       "      <td>35.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>3</td>\n",
       "      <td>35.9</td>\n",
       "      <td>35.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>35.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>35.9</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>3</td>\n",
       "      <td>35.9</td>\n",
       "      <td>34.6</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>3</td>\n",
       "      <td>35.3</td>\n",
       "      <td>34.6</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>4</td>\n",
       "      <td>36.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>4</td>\n",
       "      <td>37.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>4</td>\n",
       "      <td>37.1</td>\n",
       "      <td>36.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>4</td>\n",
       "      <td>36.1</td>\n",
       "      <td>35.2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>4</td>\n",
       "      <td>37.1</td>\n",
       "      <td>35.2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>6</td>\n",
       "      <td>35.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>7</td>\n",
       "      <td>39.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>7</td>\n",
       "      <td>44.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>7</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.4</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>7</td>\n",
       "      <td>39.4</td>\n",
       "      <td>36.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>7</td>\n",
       "      <td>44.5</td>\n",
       "      <td>36.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>8</td>\n",
       "      <td>42.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>8</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>8</td>\n",
       "      <td>44.6</td>\n",
       "      <td>42.3</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>8</td>\n",
       "      <td>42.3</td>\n",
       "      <td>36.3</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>8</td>\n",
       "      <td>44.6</td>\n",
       "      <td>36.3</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>9</td>\n",
       "      <td>32.2</td>\n",
       "      <td>31.6</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>9</td>\n",
       "      <td>33.2</td>\n",
       "      <td>31.6</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>9</td>\n",
       "      <td>32.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>9</td>\n",
       "      <td>33.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>9</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>40-50</td>\n",
       "      <td>10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>40-50</td>\n",
       "      <td>10</td>\n",
       "      <td>32.3</td>\n",
       "      <td>29.9</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>10-20</td>\n",
       "      <td>20-30</td>\n",
       "      <td>10</td>\n",
       "      <td>36.0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>20-30</td>\n",
       "      <td>10</td>\n",
       "      <td>32.3</td>\n",
       "      <td>31.4</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1989-06-23</td>\n",
       "      <td>1-10</td>\n",
       "      <td>10-20</td>\n",
       "      <td>10</td>\n",
       "      <td>32.3</td>\n",
       "      <td>36.0</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>2</td>\n",
       "      <td>37.8</td>\n",
       "      <td>36.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>3</td>\n",
       "      <td>36.1</td>\n",
       "      <td>36.4</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>4</td>\n",
       "      <td>38.4</td>\n",
       "      <td>38.6</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>5</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>37.5</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>7</td>\n",
       "      <td>32.7</td>\n",
       "      <td>34.1</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>8</td>\n",
       "      <td>28.1</td>\n",
       "      <td>28.8</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>9</td>\n",
       "      <td>34.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2005-06-16</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>10</td>\n",
       "      <td>32.1</td>\n",
       "      <td>32.2</td>\n",
       "      <td>good</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2006-03-24</td>\n",
       "      <td>1-10</td>\n",
       "      <td>0-10</td>\n",
       "      <td>6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>duplicate</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date depth_shallow depth_deep  sample  h2o_by_wet_shallow  \\\n",
       "0   1989-06-23         10-20      40-50       1                34.7   \n",
       "1   1989-06-23          1-10      40-50       1                35.4   \n",
       "27  1989-06-23          1-10      10-20       1                35.4   \n",
       "42  1989-06-23         10-20      20-30       1                34.7   \n",
       "43  1989-06-23          1-10      20-30       1                35.4   \n",
       "19  1989-06-23          1-10      40-50       2                40.4   \n",
       "29  1989-06-23          1-10      10-20       2                40.4   \n",
       "44  1989-06-23         10-20      20-30       2                36.4   \n",
       "45  1989-06-23          1-10      20-30       2                40.4   \n",
       "2   1989-06-23         10-20      40-50       3                35.9   \n",
       "3   1989-06-23          1-10      40-50       3                35.3   \n",
       "31  1989-06-23          1-10      10-20       3                35.3   \n",
       "46  1989-06-23         10-20      20-30       3                35.9   \n",
       "47  1989-06-23          1-10      20-30       3                35.3   \n",
       "4   1989-06-23         10-20      40-50       4                36.1   \n",
       "5   1989-06-23          1-10      40-50       4                37.1   \n",
       "33  1989-06-23          1-10      10-20       4                37.1   \n",
       "48  1989-06-23         10-20      20-30       4                36.1   \n",
       "49  1989-06-23          1-10      20-30       4                37.1   \n",
       "8   1989-06-23         10-20      40-50       5                40.0   \n",
       "9   1989-06-23          1-10      40-50       5                41.0   \n",
       "35  1989-06-23          1-10      10-20       5                41.0   \n",
       "50  1989-06-23         10-20      20-30       5                40.0   \n",
       "51  1989-06-23          1-10      20-30       5                41.0   \n",
       "10  1989-06-23         10-20      40-50       6                31.0   \n",
       "11  1989-06-23          1-10      40-50       6                35.2   \n",
       "21  1989-06-23          1-10      10-20       6                35.2   \n",
       "52  1989-06-23         10-20      20-30       6                31.0   \n",
       "53  1989-06-23          1-10      20-30       6                35.2   \n",
       "12  1989-06-23         10-20      40-50       7                39.4   \n",
       "13  1989-06-23          1-10      40-50       7                44.5   \n",
       "37  1989-06-23          1-10      10-20       7                44.5   \n",
       "54  1989-06-23         10-20      20-30       7                39.4   \n",
       "55  1989-06-23          1-10      20-30       7                44.5   \n",
       "14  1989-06-23         10-20      40-50       8                42.3   \n",
       "15  1989-06-23          1-10      40-50       8                44.6   \n",
       "41  1989-06-23          1-10      10-20       8                44.6   \n",
       "56  1989-06-23         10-20      20-30       8                42.3   \n",
       "57  1989-06-23          1-10      20-30       8                44.6   \n",
       "16  1989-06-23         10-20      40-50       9                32.2   \n",
       "17  1989-06-23          1-10      40-50       9                33.2   \n",
       "22  1989-06-23         10-20      20-30       9                32.2   \n",
       "23  1989-06-23          1-10      20-30       9                33.2   \n",
       "39  1989-06-23          1-10      10-20       9                33.2   \n",
       "6   1989-06-23         10-20      40-50      10                36.0   \n",
       "7   1989-06-23          1-10      40-50      10                32.3   \n",
       "24  1989-06-23         10-20      20-30      10                36.0   \n",
       "25  1989-06-23          1-10      20-30      10                32.3   \n",
       "59  1989-06-23          1-10      10-20      10                32.3   \n",
       "189 2005-06-16          1-10       0-10       1                43.0   \n",
       "188 2005-06-16          1-10       0-10       2                37.8   \n",
       "187 2005-06-16          1-10       0-10       3                36.1   \n",
       "186 2005-06-16          1-10       0-10       4                38.4   \n",
       "185 2005-06-16          1-10       0-10       5                37.7   \n",
       "184 2005-06-16          1-10       0-10       6                37.9   \n",
       "183 2005-06-16          1-10       0-10       7                32.7   \n",
       "182 2005-06-16          1-10       0-10       8                28.1   \n",
       "181 2005-06-16          1-10       0-10       9                34.2   \n",
       "180 2005-06-16          1-10       0-10      10                32.1   \n",
       "194 2006-03-24          1-10       0-10       6                38.0   \n",
       "\n",
       "     h2o_by_wet_deep chk_note_shallow chk_note_deep  \n",
       "0               35.5             good          good  \n",
       "1               35.5             good          good  \n",
       "27              34.7             good          good  \n",
       "42              36.3             good          good  \n",
       "43              36.3             good          good  \n",
       "19              36.4             good          good  \n",
       "29              36.4             good          good  \n",
       "44              35.5             good          good  \n",
       "45              35.5             good          good  \n",
       "2               35.1             good          good  \n",
       "3               35.1             good          good  \n",
       "31              35.9             good          good  \n",
       "46              34.6             good          good  \n",
       "47              34.6             good          good  \n",
       "4               34.0             good          good  \n",
       "5               34.0             good          good  \n",
       "33              36.1             good          good  \n",
       "48              35.2             good          good  \n",
       "49              35.2             good          good  \n",
       "8               40.1             good          good  \n",
       "9               40.1             good          good  \n",
       "35              40.0             good          good  \n",
       "50              38.3             good          good  \n",
       "51              38.3             good          good  \n",
       "10              32.1             good          good  \n",
       "11              32.1             good          good  \n",
       "21              31.0             good          good  \n",
       "52              32.2             good          good  \n",
       "53              32.2             good          good  \n",
       "12              34.0             good          good  \n",
       "13              34.0             good          good  \n",
       "37              39.4             good          good  \n",
       "54              36.1             good          good  \n",
       "55              36.1             good          good  \n",
       "14              32.5             good          good  \n",
       "15              32.5             good          good  \n",
       "41              42.3             good          good  \n",
       "56              36.3             good          good  \n",
       "57              36.3             good          good  \n",
       "16              31.6             good          good  \n",
       "17              31.6             good          good  \n",
       "22              31.5             good          good  \n",
       "23              31.5             good          good  \n",
       "39              32.2             good          good  \n",
       "6               29.9             good          good  \n",
       "7               29.9             good          good  \n",
       "24              31.4             good          good  \n",
       "25              31.4             good          good  \n",
       "59              36.0             good          good  \n",
       "189             40.8             good          good  \n",
       "188             36.5             good          good  \n",
       "187             36.4             good          good  \n",
       "186             38.6             good          good  \n",
       "185             37.5             good          good  \n",
       "184             37.5             good          good  \n",
       "183             34.1             good          good  \n",
       "182             28.8             good          good  \n",
       "181             33.2             good          good  \n",
       "180             32.2             good          good  \n",
       "194             38.5        duplicate          good  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the values in the deep data set that have the shallower depth\n",
    "data_deep_subset = data_soil_deep[data_soil_deep[\"depth\"] != \"30-40\"]\n",
    "\n",
    "# Filter set to only be of dates where deep set has shallow values\n",
    "data_shallow_subset = data_soil_shallow[data_soil_shallow.index.isin(data_deep_subset.index)]\n",
    "\n",
    "# Inner merge based on date and sample number\n",
    "data_soil_mismatch = pd.merge(\n",
    "    data_deep_subset.reset_index(),\n",
    "    data_shallow_subset.reset_index(),\n",
    "    on = [\"date\", \"sample\"],\n",
    "    suffixes = (\"_deep\", \"_shallow\"),\n",
    "    how = \"inner\"\n",
    "    )\n",
    "\n",
    "# Create a variable to indicate if the values match\n",
    "data_soil_mismatch[\"match_wet\"] = (data_soil_mismatch[\"h2o_by_wet_deep\"] == data_soil_mismatch[\"h2o_by_wet_shallow\"])\n",
    "\n",
    "## The dry var was not loaded in this analysis, but the exact same issue occurred in it (i.e., the same dates had mismatching values)\n",
    "# match_all[\"match_dry\"] = (match_all[\"h2o_by_dry_deep\"] == match_all[\"h2o_by_dry_shallow\"])\n",
    "\n",
    "# Set the sample var to be an integer, for sorting purposes\n",
    "data_soil_mismatch[\"sample\"] = data_soil_mismatch[\"sample\"].astype('int')\n",
    "\n",
    "# Sort by date and sample for readability\n",
    "data_soil_mismatch = data_soil_mismatch.sort_values(by = ['date', 'sample'])\n",
    "\n",
    "# Remove unneeded columns\n",
    "data_soil_mismatch = data_soil_mismatch.drop(['chk_fail_shallow', 'chk_fail_deep'], axis=1)\n",
    "\n",
    "# Filter where there is a mismatch\n",
    "data_soil_mismatch = data_soil_mismatch[(data_soil_mismatch[\"match_wet\"] == False)]\n",
    "\n",
    "# Reordering vars for readability\n",
    "data_soil_mismatch = data_soil_mismatch[['date', 'depth_shallow', 'depth_deep', 'sample', 'h2o_by_wet_shallow', 'h2o_by_wet_deep', 'chk_note_shallow', 'chk_note_deep']]\n",
    "\n",
    "# Print result\n",
    "data_soil_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd774997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "del data_shallow_subset, data_deep_subset, data_soil_mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a101b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the duplicated samples\n",
    "data_soil_deep = data_soil_deep[data_soil_deep[\"depth\"] != \"0-10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4aa6cc",
   "metadata": {},
   "source": [
    "### CHART Removals\n",
    "\n",
    "Only non-CHART values will be used for making the model.\n",
    "Prior to removing them, other missing values must also be dealt with, as they may relate to gaps within CHART-reliant ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fc94bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup\n",
    "data_combined_nochart = data_combined.copy()\n",
    "# data_combined_nochart = data_all_combined.copy()\n",
    "\n",
    "# Create a column which will forward fill the source--i.e., fill NAs with the most recent value reported in 'source'\n",
    "data_combined_nochart['source_ffill'] = data_combined_nochart['source'].ffill()\n",
    "\n",
    "# Create a column which will back fill the source--i.e., fill NAs with the next value reported in 'source'\n",
    "data_combined_nochart['source_bfill'] = data_combined_nochart['source'].bfill()\n",
    "\n",
    "# Filtering to remove CHART values and gap fills that rely on CHART values\n",
    "data_combined_nochart = data_combined_nochart[\n",
    "    # Remove CHART values\n",
    "    (data_combined_nochart['source'] != \"CHART\") &\n",
    "    # Remove NA values where the most recent source was CHART\n",
    "    (data_combined_nochart['source_ffill'] != \"CHART\") &\n",
    "    # Remove NA values where the next source is CHART\n",
    "    (data_combined_nochart['source_bfill'] != \"CHART\")\n",
    "]\n",
    "\n",
    "# Remove extra variables\n",
    "data_combined_nochart = data_combined_nochart.drop(['source_ffill', 'source_bfill'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e75c9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combi_backup = data_combined.copy()\n",
    "\n",
    "data_combi_backup = data_combi_backup.drop(data_combined_nochart.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_weir_start\n",
    "# ## EXPECTED -- 2013-01-02 18:54:38 - 2014-08-22 10:21:32\n",
    "# ## ADJ EXPECTED -- 2013-01-13 05:54:01 through 2014-08-22 10:21:32\n",
    "# data_all_soil_deep['1989-06-01 00:00:00':'1989-07-19 11:55:00']\n",
    "# gap_dates = set()\n",
    "# for dt_stamp in data_combined_nochart['2013-01-02 18:54:38':'2014-08-22 10:21:32'].index.unique():\n",
    "# # for dt_stamp in data_combined_nochart[date_gap_start:date_gap_end].index.unique():\n",
    "#     date_stamp = dt_stamp.date()\n",
    "#     gap_dates.add(date_stamp)\n",
    "\n",
    "# gap_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9895b11",
   "metadata": {},
   "source": [
    "### Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1252b75",
   "metadata": {},
   "source": [
    "Other gaps of missing values occur and should be addressed.\n",
    "These can be identified by the `chk_note` of 'missing' with a `raw` values of -999.0.\n",
    "\n",
    "A `chk_note` of 'missing' differs from instances of where a `chk_fail` is a 'Gap Fill'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e5db3",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1044b",
   "metadata": {},
   "source": [
    "### General Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949a0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore weir combined data, comments, etc.\n",
    "print(\n",
    "    \"-----Data types-----\", data_combined.dtypes,\n",
    "    \"\\n-----Source-----\", data_combined['source'].value_counts(dropna = False),\n",
    "    \"\\n-----Notes-----\", data_combined['chk_note'].value_counts(dropna = False),\n",
    "    \"\\n-----Comments-----\", data_combined['comment'].value_counts(dropna = False),\n",
    "    \"\\n-----Fail mode-----\", data_combined['chk_fail'].value_counts(dropna = False),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c98742",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a16f3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_between(input_date_start, input_date_end, include_calibration=True):\n",
    "    \"\"\"Plot values between two dates in the style of the Visual FoxPro interface.\n",
    "\n",
    "    Args:\n",
    "        input_date_start (Timestamp): The start date.\n",
    "        input_date_end (Timestamp): The end date.\n",
    "        include_calibration (boolean): Include X-markers for the calibration points.\n",
    "    \n",
    "    Returns:\n",
    "        Time series plot.\n",
    "    \"\"\"\n",
    "    # Filter the data sets\n",
    "    data_subset = data_combined.loc[input_date_start:input_date_end]\n",
    "    data_subset_rain = data_rainfall.loc[input_date_start:input_date_end]\n",
    "    data_subset_cal = data_calibration.loc[input_date_start:input_date_end]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.axhline(y=0, color ='grey', linestyle = ':')\n",
    "    # Plot the rain as a bar chart with a multiplier for visibility\n",
    "    ax.vlines(data_subset_rain.index, ymin=0, ymax=data_subset_rain['ra']*3, color = 'blue', label = \"Rain (x3)\")\n",
    "    ax.plot(data_subset.index, data_subset['level'], color = 'red', label = \"Adjusted\")\n",
    "    ax.plot(data_subset.index, data_subset['raw'], color = 'green', label = \"Raw\")\n",
    "    # Include calibration points unless otherwise specified or unless there are none in the subset\n",
    "    if include_calibration == True and not data_subset_cal.empty:\n",
    "        ax.plot(data_subset_cal.index, data_subset_cal['weir_level'], linestyle='none', marker='x', color='red', label = \"Calibration\")\n",
    "\n",
    "    # Plot labels\n",
    "    ax.set_xlabel(\"Date (YYYY-MM-DD)\")\n",
    "    ax.set_ylabel(\"Level (mm)\")\n",
    "    # ax.set_title('Simple Time Series Plot')\n",
    "    ax.set_title(\"Runoff time series from \" + input_date_start + \" through \" + input_date_end)\n",
    "    # ax.set_ylim(bottom=0) \n",
    "    # ax.grid(True)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    # Reverse the order of the legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], loc='upper right')\n",
    "    # plt.legend(loc = 'upper right')\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2865ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_between('2010-05-20 00:00:00','2010-05-25 23:59:59')\n",
    "# plot_between('2020-05-31 00:00:00','2020-06-16 23:59:59')\n",
    "plot_between('2023-05-14 00:00:00','2023-06-15 23:59:59')\n",
    "# plot_between('2002-07-30 00:00:00','2002-08-02 23:59:59')\n",
    "\n",
    "# plot_between('2013-01-02 18:59:38', '2014-08-22 10:21:32', include_calibration=False)\n",
    "# plot_between('2012-12-15 00:00:00', '2013-01-02 23:59:59', include_calibration=False)\n",
    "# data_combined['2012-12-25 00:00:00':'2012-12-28 23:59:59']\n",
    "plot_between('2023-03-01 00:00:00','2023-06-01 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fe875b",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e575bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source insights\n",
    "print(data_combined['1978-01-01 00:00:00':].groupby('source', dropna=False, observed=True)['raw'].agg(['count','mean', 'min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136102f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series = pd.Series(data_combined, index='datetime')\n",
    "# time_series\n",
    "# pd.DatetimeIndex.to_series(data_combined)\n",
    "# time_series = pd.to_datetime(data_combined.index())\n",
    "\n",
    "# data_sumstats = data_combined['raw'].dropna().resample('1YE').agg(['mean','std', 'min', 'max']).dropna()\n",
    "# data_sumstats\n",
    "\n",
    "# Removing values below 0\n",
    "data_sumstats = data_combined[data_combined['raw'] >= 0]\n",
    "# Get yearly averages and std\n",
    "data_sumstats_yr = data_sumstats['raw'].dropna().resample('1YE').agg(['count', 'mean','std', 'min', 'max'])\n",
    "# Get monthly averages and std\n",
    "data_sumstats = data_sumstats['raw'].dropna().resample('1ME').agg(['mean','std'])\n",
    "\n",
    "# Simplifying datetime to the year for readability\n",
    "data_sumstats_yr = data_sumstats_yr.reset_index()\n",
    "data_sumstats_yr['year'] = data_sumstats_yr['datetime'].dt.year\n",
    "data_sumstats_yr = data_sumstats_yr.set_index('year').drop('datetime', axis=1)\n",
    "print(data_sumstats_yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running avg plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "## Line for 0\n",
    "# plt.axhline(y=0, color = \"grey\", linestyle = \":\")\n",
    "# Mean\n",
    "ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green')\n",
    "# ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green', label = \"Mean\")\n",
    "# Ribbon for standard deviation\n",
    "# ax.fill_between(data_sumstats.index, data_sumstats['mean']-data_sumstats['std'], data_sumstats['mean']+data_sumstats['std'], color = 'aquamarine', label = \"std\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Level (mm)\")\n",
    "ax.set_title(\"Average raw values every 1mo\")\n",
    "ax.set_ylim(bottom = 0)\n",
    "ax.set_xlim(left = dt.date(1989, 1, 1), right = dt.date(2026, 1, 1))\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month = 1)) # Show ticks at start of year\n",
    "plt.xticks(rotation = 90)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis = 'x', which = 'major')\n",
    "# plt.legend(loc = 'upper right')\n",
    "# Truncate plot\n",
    "# ax.set_ylim(bottom = 0, top = 250)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1dc52",
   "metadata": {},
   "source": [
    "## Uniting\n",
    "\n",
    "The calibration, combined (runoff), and rainfall data can be united into a single data frame.\n",
    "Soil samples do not have the same granularity, so can be stored separately from these so as to avoid duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6aca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TSTING UNIFICATION WITH SMALL SUBSET\n",
    "# # data_united = data_combined['2010-01-01 00:00:00':'2010-12-31 23:59:59']\n",
    "# # data_united = data_united.add_suffix(\"_runoff\")\n",
    "# mini_start = '2010-01-01 00:00:00'\n",
    "# mini_end = '2010-12-31 23:59:59'\n",
    "# mini_calibration = data_calibration[mini_start:mini_end]\n",
    "# mini_combined = data_combined[mini_start:mini_end]\n",
    "# mini_rain = data_rainfall[mini_start:mini_end]\n",
    "\n",
    "# # pd.merge(mini_calibration, mini_combined, left_index=True, right_index=True, how='outer', suffixes=('_cal', '_runoff'))\n",
    "# mini_united = pd.merge(mini_calibration.add_suffix(\"_cal\"), mini_combined.add_suffix(\"_ro\"), left_index=True, right_index=True, how='outer')\n",
    "# mini_united = pd.merge(mini_rain.add_suffix(\"_rain\"), mini_united, left_index=True, right_index=True, how='outer')\n",
    "# # mini_united.rename(columns={'weir_level'})\n",
    "# # mini_united.dropna(subset=['weir_level_cal'])\n",
    "\n",
    "# # Checking to make sure sources match\n",
    "# # mini_united[\"match_source\"] = (mini_united[\"source_ro\"] == mini_united[\"source_rain\"]) | (mini_united[\"source_ro\"].isnull() & mini_united[\"source_rain\"].isnull())\n",
    "# # mini_united[(mini_united[\"match_source\"]==False)]\n",
    "# # mini_united\n",
    "\n",
    "# # mini_united = mini_united.drop(\"source_rain\",axis=1)\n",
    "# # mini_united.rename(columns={\"source_ro\":\"source\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another\n",
    "# pd.merge(data_soil_deep.add_suffix(\"_shallow\"), data_soil_deep.add_suffix(\"_deep\"), left_index=True, right_index=True, how='outer')\n",
    "united_soil = pd.merge(data_soil_shallow.reset_index(), data_soil_deep.reset_index(), on=[\"date\", \"sample\"], suffixes=(\"_shallow\", \"_deep\"), how=\"outer\")\n",
    "united_soil = united_soil.set_index('date')\n",
    "# Modifying sample to int for sorting\n",
    "united_soil[\"sample\"] = united_soil[\"sample\"].astype('int')\n",
    "# Sorting for readability\n",
    "united_soil = united_soil.sort_values(by=['date', 'sample'])\n",
    "# Reset to category\n",
    "united_soil[\"sample\"] = united_soil[\"sample\"].astype('category')\n",
    "# Moving sample to front of data frame\n",
    "soil_samples = united_soil.pop('sample')\n",
    "united_soil.insert(0, 'sample', soil_samples)\n",
    "del soil_samples\n",
    "#\n",
    "united_soil\n",
    "\n",
    "# Missing values:\n",
    "# united_soil[united_soil['h2o_by_wet_shallow'].isnull() | united_soil['h2o_by_wet_deep'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking column matching\n",
    "# Checking to make sure sources match\n",
    "def check_cols(input_df, input_col_left, input_col_right, find_mismatch=True):\n",
    "    input_df[\"match\"] = (input_df[input_col_left] == input_df[input_col_right]) | (input_df[input_col_left].isnull() & input_df[input_col_right].isnull())\n",
    "    if find_mismatch == True:\n",
    "        input_df = input_df[(input_df[\"match\"]==False)]\n",
    "    return input_df\n",
    "\n",
    "# check_cols(mini_united, \"source_ro\", \"source_rain\")\n",
    "# check_cols(mini_united, \"chk_note_rain\", \"chk_note_ro\")\n",
    "# check_cols(mini_united, \"comment_rain\", \"comment_ro\")\n",
    "\n",
    "# check_cols(mini_united, 'chk_note_rain', 'chk_note_ro')\n",
    "# mini_united.dropna(subset=\"chk_note_rain\")\n",
    "# check_cols(mini_united, 'chk_fail_rain', 'chk_fail_rain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3ec1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "united_water = pd.merge(data_rainfall.add_suffix(\"_rain\"), data_combined.add_suffix(\"_ro\"), left_index=True, right_index=True, how='outer')\n",
    "united_water = pd.merge(data_calibration.add_suffix(\"_cal\"), united_water, left_index=True, right_index=True, how='outer')\n",
    "united_water.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another\n",
    "united_soil = pd.merge(data_soil_shallow.reset_index(), data_soil_deep.reset_index(), on=[\"date\", \"sample\"], suffixes=(\"_shallow\", \"_deep\"), how=\"outer\")\n",
    "united_soil = united_soil.set_index('date')\n",
    "# Modifying sample to int for sorting\n",
    "united_soil[\"sample\"] = united_soil[\"sample\"].astype('int')\n",
    "# Sorting for readability\n",
    "united_soil = united_soil.sort_values(by=['date', 'sample'])\n",
    "# Reset to category\n",
    "united_soil[\"sample\"] = united_soil[\"sample\"].astype('category')\n",
    "# Moving sample to front of data frame\n",
    "soil_samples = united_soil.pop('sample')\n",
    "united_soil.insert(0, 'sample', soil_samples)\n",
    "#\n",
    "united_soil.info()\n",
    "\n",
    "# Missing values:\n",
    "# united_soil[united_soil['h2o_by_wet_shallow'].isnull() | united_soil['h2o_by_wet_deep'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2048217",
   "metadata": {},
   "outputs": [],
   "source": [
    "united_soil_mini = united_soil[['sample', 'h2o_by_wet_shallow', 'h2o_by_wet_deep']]\n",
    "united_soil_mini = united_soil_mini.groupby('sample').resample('1ME').mean().reset_index().set_index('date')\n",
    "# united_soil_mini = united_soil[['h2o_by_wet_shallow', 'h2o_by_wet_deep']]\n",
    "# united_soil_mini = united_soil_mini.resample('1ME').mean()#.reset_index().set_index('date')\n",
    "\n",
    "united_soil_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040951b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running avg plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "## Line for 0\n",
    "# plt.axhline(y=0, color = \"grey\", linestyle = \":\")\n",
    "# Mean\n",
    "# ax.plot(united_soil_mini.index, united_soil_mini['h2o_by_wet_shallow'], color = 'pink')\n",
    "# ax.plot(united_soil_mini.index, united_soil_mini['h2o_by_wet_deep'], color = 'purple')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "# zord = 1\n",
    "for category, group_df in united_soil_mini.groupby('sample'):\n",
    "    # ax2.plot(group_df.index, group_df['h2o_by_wet_shallow'], label=category, alpha=0.5, color='orange', linewidth = 0.25, zord = 1)\n",
    "    ax2.plot(group_df.index, group_df['h2o_by_wet_shallow'], label=category, alpha=0.75, color='orange', linewidth = 0.25)\n",
    "    # zord += 1\n",
    "# for category, group_df in united_soil_mini.groupby('sample'):\n",
    "    ax2.plot(group_df.index, group_df['h2o_by_wet_deep'], label=category, alpha=0.75, color='purple', linewidth = 0.25)\n",
    "    # zord += 1\n",
    "# ax.plot(united_soil_mini.index, united_soil_mini['h2o_by_wet_shallow'], label=\"Shallow\", color='orange', linewidth = 0.5)\n",
    "# ax.plot(united_soil_mini.index, united_soil_mini['h2o_by_wet_deep'], label=\"Deep\", color='purple', linewidth = 0.5)\n",
    "\n",
    "# ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green', zorder = zord)\n",
    "ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green')\n",
    "\n",
    "# ax.plot(data_sumstats.index, data_sumstats['mean'], color = 'green', label = \"Mean\")\n",
    "# Ribbon for standard deviation\n",
    "# ax.fill_between(data_sumstats.index, data_sumstats['mean']-data_sumstats['std'], data_sumstats['mean']+data_sumstats['std'], color = 'aquamarine', label = \"std\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Level (mm)\")\n",
    "ax.set_title(\"Average raw values every 1mo\")\n",
    "# ax.set_ylim(bottom = 0)\n",
    "ax.set_xlim(left = dt.date(1989, 1, 1), right = dt.date(2026, 1, 1))\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator(month = 1)) # Show ticks at start of year\n",
    "plt.xticks(rotation = 90)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis = 'x', which = 'major')\n",
    "# plt.legend(loc = 'upper right')\n",
    "# Truncate plot\n",
    "# ax.set_ylim(bottom = 0, top = 250)\n",
    "\n",
    "# Set moisture plot to back\n",
    "ax2.set_zorder(1)\n",
    "# Set mean line to be in front\n",
    "ax.set_zorder(2)\n",
    "# Change background of mean line plot transparent\n",
    "ax.patch.set_visible(False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del fig, ax#, zord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# united_soil[('h2o_by_wet_shallow', 'h2o_by_wet_deep')]#.resample('1YE').agg(['mean', 'std'])\n",
    "# united_sumstats_soil = pd.DataFrame()\n",
    "# united_sumstats_soil = united_soil['h2o_by_wet_shallow'].dropna().resample('1YE').mean()\n",
    "# united_sumstats_soil['h2o_by_wet_deep'] = united_soil['h2o_by_wet_deep'].dropna().resample('1YE').mean()\n",
    "# united_sumstats_soil\n",
    "# united_soil.groupby('sample')\n",
    "# united_soil['h2o_by_wet_shallow'].dropna().resample('1YE').mean()\n",
    "# united_soil\n",
    "# united_soil_test = united_soil.groupby('sample')\n",
    "united_soil_test = united_soil[['sample', 'h2o_by_wet_shallow']]\n",
    "# united_soil.resample('1YE')['h2o_by_wet_shallow'].dropna().mean()\n",
    "# united_soil_test.groupby('sample').resample('1YE').mean()#.dropna().mean()\n",
    "print(united_soil_test.groupby('sample').resample('1YE').mean())\n",
    "\n",
    "# # Removing values below 0\n",
    "# data_sumstats = data_combined[data_combined['raw'] >= 0]\n",
    "# # Get yearly averages and std\n",
    "# data_sumstats_yr = data_sumstats['raw'].dropna().resample('1YE').agg(['count', 'mean','std', 'min', 'max'])\n",
    "# # Get monthly averages and std\n",
    "# data_sumstats = data_sumstats['raw'].dropna().resample('1ME').agg(['mean','std'])\n",
    "\n",
    "# # Simplifying datetime to the year for readability\n",
    "# data_sumstats_yr = data_sumstats_yr.reset_index()\n",
    "# data_sumstats_yr['year'] = data_sumstats_yr['datetime'].dt.year\n",
    "# data_sumstats_yr = data_sumstats_yr.set_index('year').drop('datetime', axis=1)\n",
    "# print(data_sumstats_yr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
